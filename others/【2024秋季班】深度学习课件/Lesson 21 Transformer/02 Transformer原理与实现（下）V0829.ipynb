{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dbf366-7a84-4c76-bcd6-466feaa51a7b",
   "metadata": {},
   "source": [
    "# Transformer（下）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eef42a-f6f1-4756-a325-1e7fd59813a5",
   "metadata": {},
   "source": [
    "**0 前言**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;0.1 Transformer模型的地位与发展历程<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;0.2 序列模型的基本思路与根本诉求<br>\n",
    "\n",
    "**1 注意力机制**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1.1 注意力机制的本质<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1.2 Transformer中的自注意力机制运算流程<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1.3 Multi-Head Attention 多头注意力机制<br>\n",
    "\n",
    "**2 Transformer的基本结构**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2.1 Embedding层与位置编码技术<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2.2 Encoder结构解析<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2.1 残差连接<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2.2 Layer Normalization层归一化<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2.3 Feed-Forward Networks前馈网络<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2.3 Decoder结构解析<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.1 完整Transformer与Decoder-Only结构的数据流<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2 Encoder-Decoder结构中的Decoder<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2.1 输入与teacher forcing<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2.2 掩码注意力机制<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2.3 普通掩码与前馈掩码<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2.4 编码器-解码器注意力层<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.3 Decoder-Only结构中的Decoder<br>\n",
    "\n",
    "===================以上内容见Transformer（上）=====================\n",
    "\n",
    "**3 Transformer的PyTorch实战**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3.1 PyTorch中的Transformer层<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3.2 Encoder-Only任务下的Trnasformer实战<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.1 Encoder-Only任务下的Transformer架构<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.1.1 Embedding层与Encoder数据输入<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.1.2 位置编码的实现与技巧<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.1.3 从0实现编码器Only架构<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.2 【实战】Transformer的情感分类案例<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3.3 Decoder-Only任务下的Trnasformer实战<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.3.1 Decoder-Only任务下的Transformer架构<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.3.2 Transformer的文字生成实战<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83059ce5-9532-4f4a-b775-bc1667be8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235a8f7-1473-4190-98f9-7c414d9f6f0f",
   "metadata": {},
   "source": [
    "# 3 PyTorch中与Huggingface中的Transformer实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804304e-9d44-4b94-9830-1ea51d58bfcb",
   "metadata": {},
   "source": [
    "## 3.1 PyTorch中的Transformer层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78113b0-a597-4076-96cd-dba71e9a0951",
   "metadata": {},
   "source": [
    "在之前的课程当中，我们已经认识了PyTorch框架的基本结构，整个PyTorch框架可以大致被分Torch和成熟AI领域两大板块，其中Torch包含各类神经网络组成元素、用于构建各类神经网络，各类AI领域中则包括Torchvision、Torchtext、Torchaudio等辅助完成图像、文字、语音方面各类任务的领域模块。\n",
    "\n",
    "在PyTorch中，Transformer算法是属于“构建循环神经网络的元素”，而非“成熟神经网络”，因此Transformer是位于PyTorch.nn这个基本模块下。为什么PyTorch中的Transformer结构是位于nn，而不是属于成熟神经网络呢？**事实上，在PyTorch中并没有完整的Transformer架构，只有用于构建Transformer的各个层**。我们一起来看一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e09587-f1e4-4ee5-b65a-4145d687cb4e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-1.png\" alt=\"描述文字\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb36ca-381d-415f-b91e-0a06e33c1706",
   "metadata": {},
   "source": [
    "在torch.nn模块下，存在**服务于Transformer架构的各类神经网络层和模型**，我们来看一下——\n",
    "\n",
    "| 类名称                     | 作用                                          |\n",
    "|--------------------------|---------------------------------------------|\n",
    "| `nn.Transformer`          | 不带输入与输出层的 Transformer 模型，同时具备编码器和解码器                       |\n",
    "| `nn.TransformerEncoder`   | Transformer 编码器的堆叠层，可以控制Nx的N的具体数字                    |\n",
    "| `nn.TransformerDecoder`   | Transformer 解码器的堆叠层，可以控制Nx的N的具体数字                    |\n",
    "| `nn.TransformerEncoderLayer` | Transformer 编码器层，由自注意力和前馈网络组成   |\n",
    "| `nn.TransformerDecoderLayer` | Transformer 解码器层，由自注意力、编码器-解码器注意力和前馈网络组成 |\n",
    "| `nn.MultiheadAttention`   | 多头注意力机制                               |\n",
    "| `nn.LayerNorm`            | 层归一化层                                   |\n",
    "| `nn.Embedding`            | 嵌入层，用于将输入序列转换为嵌入表示          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87619a3-4fe3-4531-a563-fd8c13a06ebb",
   "metadata": {},
   "source": [
    "- **nn.Transformer**\n",
    "\n",
    "`nn.Transformer`封装了完整的Transformer结构。如下图所示，它对Encoder和Decoder两部分的包装，它并没有实现输入中的Embedding和Positional Encoding和最后输出的Linear+softmax部分。\n",
    "\n",
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-37.png\" alt=\"描述文字\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d164d-27c3-4581-9b51-be6ef3b909cc",
   "metadata": {},
   "source": [
    "- **分割的编码器与解码器**\n",
    "\n",
    "`nn.TransformerEncoderLayer`与`nn.TransformerDecoderLayer`: 这两个类表示Transformer单一的编码器和单一的解码器（他们代表了架构图中展示的结构，而不包括Nx的部分）。他们都包含了自注意力机制（self-attention）、多头注意力机制（Multi-head Attention）和前馈网络（feedforward network），以及必要的归一化和残差连接。这两个层的区别在于：\n",
    "> - DecoderLayer默认带有teacher forcing机制，而Encoder layer则没有这个机制。<br><br>\n",
    "> - DecoderLayer带有的Multi-head Attention层可以用来处理编码器-解码器注意力层中的运算，但是EncoderLayer中带有的多头注意力层却没有这个机制。\n",
    "\n",
    "`nn.TransformerEncoder`与`nn.TransformerDecoder`: 这两个类是将单一解码器和单一编码器堆叠后构成的解码器、编码器串，其中`nn.TransformerEncoder`包含了多个nn.TransformerEncoderLayer层的堆叠，`nn.TransformerDecoder`包含了多个nn.TransformerDecoderLayer层的堆叠。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4aab82-1c43-451f-a1b5-eef89e89dda3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-38.png\" alt=\"描述文字\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b67853-5cd4-40fd-a1e1-a7917cfcd6ee",
   "metadata": {},
   "source": [
    "除此之外，我们还有：\n",
    "\n",
    "`nn.MultiheadAttention`: 这个模块实现了多头注意力机制，这是Transformer模型的核心组件之一。多头注意力允许模型在不同的位置同时处理来自序列不同部分的信息，这有助于捕捉序列内的复杂依赖关系。\n",
    "\n",
    "`nn.LayerNorm`: 层归一化（Layer Normalization）通常用在Transformer的各个子层的输出上，有助于稳定训练过程，并且提高了训练的速度和效果。\n",
    "\n",
    "`nn.Embedding`：一个预训练好的语义空间，它将每个标记（如单词、字符等）映射到一个高维空间的向量。这使得模型能够处理文本数据，并为每个唯一的标记捕获丰富的语义属性。嵌入层通常是自然语言处理模型的第一层，用于将离散的文本数据转化为连续的向量表示。其输入是索引列表，输出是对应的嵌入向量。\n",
    "\n",
    "`nn.Transformer.generate_square_subsequent_mask`：掩码函数。用于生成一个方形矩阵，用作Transformer模型中自注意力机制的上三角遮罩。这个遮罩确保在序列生成任务中，例如语言模型中，任何给定的元素只会考虑到序列中先于它的元素（即它只能看到过去的信息，不能看到未来的信息）。这种掩码通常在解码器部分使用，防止在预测下一个输出时“作弊”。具体来说，该函数创建了一个方阵，其中对角线及其以下的元素为0（表示可以“看到”这些位置的元素），其余元素为负无穷大（在softmax之前应用，表示位置被屏蔽，不应该有注意力权重）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6ee8d1-f55d-4410-8e61-3d07fc90df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0971a1-7050-48dd-b862-1c4e9a566b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Transformer.generate_square_subsequent_mask(5) # 5指的是target的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f80490-0ff6-4826-a5ae-6a07354a9947",
   "metadata": {},
   "source": [
    "| 类名称                     | 作用                                          |\n",
    "|--------------------------|---------------------------------------------|\n",
    "| `nn.Transformer`          | 不带输入与输出层的 Transformer 模型，同时具备编码器和解码器                       |\n",
    "| `nn.TransformerEncoder`   | Transformer 编码器的堆叠层，可以控制Nx的N的具体数字                    |\n",
    "| `nn.TransformerDecoder`   | Transformer 解码器的堆叠层，可以控制Nx的N的具体数字                    |\n",
    "| `nn.TransformerEncoderLayer` | Transformer 编码器层，由自注意力和前馈网络组成   |\n",
    "| `nn.TransformerDecoderLayer` | Transformer 解码器层，由自注意力、编码器-解码器注意力和前馈网络组成 |\n",
    "| `nn.MultiheadAttention`   | 多头注意力机制                               |\n",
    "| `nn.LayerNorm`            | 层归一化层                                   |\n",
    "| `nn.Embedding`            | 嵌入层，用于将输入序列转换为嵌入表示          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f6504-8f93-4965-8a1b-56bfcd11709c",
   "metadata": {},
   "source": [
    "**在这些所有类中，我们最应该关注的是nn.TransformerEncoderLayer与nn.TransformerDecoderLayer**。这两个层赋予Transformer架构极高的灵活性，大部分时候我们也是会通过这两个层来自定义各种各样丰富的Transformer结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33bf27-c108-4420-87f5-e67bb7a75e15",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**CLASS`torch.nn.TransformerEncoderLayer`(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\\<function relu\\><function relu>, layer_norm_eps=1e-05, batch_first=False, norm_first=False, bias=True, device=None, dtype=None)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7587b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(batch_size, seq_len, input_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8cbf6e-6233-4cd2-8aeb-818e6382261c",
   "metadata": {},
   "source": [
    "| 实例化前-参数名称           | 说明                                                                                     |\n",
    "|--------------------|------------------------------------------------------------------------------------------|\n",
    "| `d_model`          | 输入的嵌入维度（Embedding过程中规定的特征维度），数学公式中的$d_k$                          |\n",
    "| `nhead`            | 多头注意力机制中的头数，在代码中通常表示为num_heads                                           |\n",
    "| `dim_feedforward`  | 前馈网络的隐藏层维度，默认值为 2048。                                                    |\n",
    "| `dropout`          | Dropout 概率，默认值为 0.1。在Transformer架构图中虽然没有展现dropout层，但现在业内习惯于将Dropout层放置在每一个复杂结构之后，在Encoder中，Dropout出现在自注意力层后、残差链接之前，也出现在前馈神经网络后、残差链接之前|\n",
    "| `activation`       | 激活函数，默认值为 `relu`。                                                              |\n",
    "| `layer_norm_eps`   | 层归一化的 epsilon 值，默认值为 1e-05。                                                  |\n",
    "| `batch_first`      | 如果为 `True`，则输入和输出张量的形状为 `(batch_size, seq_len, feature)`，否则为 `(seq_len, batch_size, feature)`。默认值为 `False`。 |\n",
    "| `norm_first`       | 如果为 `True`，则执行前馈网络之前进行层归一化。默认值为 `False`。                        |\n",
    "| `bias`             | 如果为 `True`，则在线性层中使用偏置。默认值为 `True`。                                  |\n",
    "| `device`           | 指定层的设备，默认值为 `None`。                                                         |\n",
    "| `dtype`            | 指定层的数据类型，默认值为 `None`。                                                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911fb0e7-7b78-429b-aa3d-f2989455f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)\n",
    "src = torch.rand(32, 10, 512)\n",
    "out = encoder_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b677e2fb-5c6c-44b0-a282-0908afe8c00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape #经过多头注意力机制、残差链接、前馈网络、层归一化，但完全不改变数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "前瞻 - 上三角(seq_len, seq_len)\n",
    "填充 - 每张表会有不同的掩码 (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb50939-6f2f-4aeb-b5bd-f41cb4eb5d29",
   "metadata": {},
   "source": [
    "`torch.nn.TransformerEncoderLayer`实例化后可以输入的内容有：\n",
    "\n",
    "| 实例化后-参数名称              | 说明                                                                                                                         |\n",
    "|------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `src`                        | 输入到编码器层的序列（必填）。                                                                                                 |\n",
    "| `src_mask`                   | 输入序列的掩码矩阵（可选），默认接收形状为(seq_len, seq_len)的二维矩阵，通常该参数默认是执行前瞻掩码，在encoder中很少使用。                                                                                                       |\n",
    "| `src_key_padding_mask`       | 输入序列的填充掩码矩阵（可选），默认接收形状为(batch_size, seq_len)的二维矩阵，这个参数只提供给填充掩码使用。                                                                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561a65d3-6dfa-47df-96b0-d7e3ab313ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len, embedding_dim)\n",
    "    # 检查填充值位置\n",
    "    padding_mask = (seq == pad_token).all(dim=-1)  # (batch_size, seq_len)\n",
    "    padding_mask = padding_mask.float() * -1e9\n",
    "    \n",
    "    return padding_mask\n",
    "\n",
    "def create_look_ahead_mask(seq_len, start_seq=1):\n",
    "    mask = torch.triu(torch.ones((seq_len, seq_len)), diagonal=start_seq)  # 上三角矩阵\n",
    "    mask = mask.float() * -1e9  # 将未来的位置设置为负无穷大\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab221f26-5008-44cb-bf3f-8bde17f02566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c43599a-d678-4da9-af18-096c3e4dc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = create_padding_mask(src,pad_token=0)\n",
    "src_mask = create_look_ahead_mask(10,start_seq=1) #其实一般对于encoder中的数据并不会去使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b41a1a-e434-4ce9-a293-65cc46a3c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_key_padding_mask.shape #batch_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ea9190-b8e2-4155-b1b6-882c19c7a311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.shape #seq_len, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09710d4-cd07-4190-a785-5b42e0e3ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer(src\n",
    "              ,src_mask = src_mask\n",
    "              , src_key_padding_mask = src_key_padding_mask).shape #结构不变，但数值是增加了掩码的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b910d6-8ce6-4be1-9f0f-65ff9197e665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6185,  0.9043,  0.2690,  ..., -0.7528, -2.6922, -0.0568],\n",
       "        [ 0.2093, -0.3952, -0.3863,  ..., -1.9490, -1.0719, -0.1734],\n",
       "        [-0.8843, -0.0294, -1.2462,  ..., -1.0629, -0.4550, -0.0064],\n",
       "        ...,\n",
       "        [-0.7402, -1.7728,  0.7999,  ..., -0.9688, -0.4042, -0.5975],\n",
       "        [ 0.0606,  0.5342,  0.0650,  ...,  0.2278, -0.4304,  1.4630],\n",
       "        [-1.1481,  0.0796, -1.1551,  ..., -1.1815, -1.2460, -0.9036]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer(src,src_mask = src_mask, src_key_padding_mask = src_key_padding_mask)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64beca0e-e6cf-43c4-a505-bbcd60c794b7",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**CLASS`torch.nn.TransformerDecoderLayer`(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\\<function relu\\>, layer_norm_eps=1e-05, batch_first=False, norm_first=False, bias=True, device=None, dtype=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53c993-3d2c-417e-aaad-840056dfafa2",
   "metadata": {},
   "source": [
    "不难发现，TransformerDecoderLayer的参数与TransformerEncoderLayer的参数完全一致——"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605100e-142b-44b2-b401-98bd0d7c7faf",
   "metadata": {},
   "source": [
    "| 实例化前-参数名称           | 说明                                                                                     |\n",
    "|--------------------|------------------------------------------------------------------------------------------|\n",
    "| `d_model`          | 输入的嵌入维度（Embedding过程中规定的特征维度），数学公式中的$d_k$                          |\n",
    "| `nhead`            | 多头注意力机制中的头数，在代码中通常表示为num_heads                                           |\n",
    "| `dim_feedforward`  | 前馈网络的隐藏层维度，默认值为 2048。                                                    |\n",
    "| `dropout`          | Dropout 概率，默认值为 0.1。在Transformer架构图中虽然没有展现dropout层，但现在业内习惯于将Dropout层放置在每一个复杂结构之后，在Encoder中，Dropout出现在自注意力层后、残差链接之前，也出现在前馈神经网络后、残差链接之前|\n",
    "| `activation`       | 激活函数，默认值为 `relu`。                                                              |\n",
    "| `layer_norm_eps`   | 层归一化的 epsilon 值，默认值为 1e-05。                                                  |\n",
    "| `batch_first`      | 如果为 `True`，则输入和输出张量的形状为 `(batch_size, seq_len, feature)`，否则为 `(seq_len, batch_size, feature)`。默认值为 `False`。 |\n",
    "| `norm_first`       | 如果为 `True`，则执行前馈网络之前进行层归一化。默认值为 `False`。                        |\n",
    "| `bias`             | 如果为 `True`，则在线性层中使用偏置。默认值为 `True`。                                  |\n",
    "| `device`           | 指定层的设备，默认值为 `None`。                                                         |\n",
    "| `dtype`            | 指定层的数据类型，默认值为 `None`。                                                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ca6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder - inputs + 掩码 ==> memory/system/conditions\n",
    "decoder - outputs、memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 这 是 最好的 时代\n",
    "outputs = it was the best of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d988ff-a488-4bb3-96c3-a11b3d951b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8, batch_first=True)\n",
    "#需要输入的结构为来自Encoder的信息Memory，以及直接输入给Decoder的信息target\n",
    "memory = torch.rand(32, 10, 512)\n",
    "tgt = torch.rand(32, 20, 512)\n",
    "out = decoder_layer(tgt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d46227c-9a7f-41c2-8833-41e07a22ee76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape #经过自注意力机制、编码-解码器注意力机制和前馈神经网络，输出结构与tgt一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbaa0f3-56c1-4f22-99e8-e046c70834eb",
   "metadata": {},
   "source": [
    "`torch.nn.TransformerDecoderLayer`实例化后可以输入的内容有：\n",
    "\n",
    "| 实例化后-参数名称              | 说明                                                                                                                         |\n",
    "|------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `tgt`                        | 输入到解码器层的序列（必填），通常来说也就是真实标签                                                                                                |\n",
    "| `memory`                     | 来自编码器最后一层的序列（必填）。                                                                                            |\n",
    "| `tgt_mask`                   | 目标序列的掩码（可选），默认接收形状为(seq_len, seq_len)的二维矩阵，**通常该参数默认是执行前瞻掩码**。                                                                                                      |\n",
    "| `memory_mask`                | 编码器输出序列的掩码（可选），默认接收形状为(seq_len, seq_len)的二维矩阵，**通常该参数默认是执行前瞻掩码**，但由于是作用于编码器的结果，因此实际很少使用。                                                                                                 |\n",
    "| `tgt_key_padding_mask`       | 目标序列的填充掩码矩阵（可选），默认接收形状为(batch_size, seq_len)的二维矩阵，这个参数只提供给填充掩码使用。                                                                                             |\n",
    "| `memory_key_padding_mask`    | 编码器输出序列的填充掩码矩阵（可选），默认接收形状为(batch_size, seq_len)的二维矩阵，这个参数只提供给填充掩码使用。                                                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75adc0-6439-47b8-94d6-fc7303b76186",
   "metadata": {},
   "source": [
    "由于解码器本身有两部分输入（真实标签和来自编码器的输入），每一种输入又分别被允许填充掩码和前瞻掩码、因此2种输入 + 每种输入允许的2种掩码，就被允许输入至少6个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e36d535-a33c-4963-9f13-e6140baa20db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37bbe1a1-8a50-4c4f-93db-1e4936778491",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_key_padding_mask = create_padding_mask(tgt,pad_token=0)\n",
    "tgt_mask = create_look_ahead_mask(tgt.shape[1],start_seq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac58d76-e746-486d-b7ef-7b67ee36c045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_key_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92caf665-3f2e-4567-bff6-1850eb4b75e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53204d52-7f79-4b98-ae3d-25e1580feecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#结构不变，但数值是增加了掩码的数值\n",
    "decoder_layer(tgt,memory,tgt_mask = tgt_mask, tgt_key_padding_mask = tgt_key_padding_mask).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678069a-e657-4f68-854b-f74dff0a24f9",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**CLASS`torch.nn.TransformerEncoder`(encoder_layer, num_layers, norm=None, enable_nested_tensor=True, mask_check=True)**\n",
    "\n",
    "- <font color=\"red\">**CLASS`torch.nn.TransformerDecoder`(decoder_layer, num_layers, norm=None, enable_nested_tensor=True, mask_check=True)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9852a118-0ec2-4a02-87aa-59a12bd88e7b",
   "metadata": {},
   "source": [
    "TransformerEncoder类与TransformerDecoder中的几大参数则非常简单，其中encoder_layer这个参数中输入的就是定义好的TransformerEncoderLayer层，decoder_layer这个参数输入的就是定义好的TransformerDecoderLayer，num_layers则决定了当前Transformer中一共有多少个子层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c344908-fb30-4651-aa72-98adc980b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "\n",
    "#如Transformer的论文中规定的一样，有6个Decoder层\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 32, 512) #没有batch_first，因此结构是(seq_len, batch_size, input_dimensions)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "\n",
    "#输出\n",
    "out = transformer_decoder(tgt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55816f60-58c0-463f-8f98-b5ad5523b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape #依然是结构不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3dc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax((QK.T)/dk)*V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder ==> tgt （32,20,512） Q\n",
    "encoder ==> memory （32,10,512） K V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f77dd4-a86d-433c-b5e2-a2e8f2caefbc",
   "metadata": {},
   "source": [
    "> 两个关键问题：<br><br>\n",
    "> **1. Encoder输出的矩阵结构与Decoder中的tgt结构不一致，是如何在编码解码器层中合并的？**<br><br>\n",
    "> **2. 编码解码器层是如何通过多头注意力机制实现的？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de794e89-2bb1-451c-ba58-ff073626d152",
   "metadata": {},
   "source": [
    "tips：编码器-解码器注意力机制中，下列方程并行实现，一共会有多少个方程呢？**由Q中的行数决定。因此解码器最终的输出的序列长度也是与Q的行数一致**。\n",
    "\n",
    "$$\\text{Context}_1 = \\sum_{i} \\text{Attention}(Q_1, K_i) \\times V_i$$\n",
    "\n",
    "$$\\text{Context}_2 = \\sum_{i} \\text{Attention}(Q_2, K_i) \\times V_i$$\n",
    "\n",
    "$$\\text{Context}_3 = \\sum_{i} \\text{Attention}(Q_3, K_i) \\times V_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb51cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorch - nn.MultiheadAttention ==> Q、K、V\n",
    "\n",
    "1) 认为在attention层前面去添加nn.Linear来帮助你生成QKV\n",
    "2) Q、K、V的具体状态是自由的，只要矩阵能相乘、只要矩阵乘法上不出错，Q、K、V可以是任何的模样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb51218",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt (32,20,512) == > 20头注意力机制\n",
    "\n",
    "head1 => 和KV结构一致，但是全部由Q1构成的矩阵\n",
    "head2 => 和KV结构一致，但是全部由Q2构成的矩阵\n",
    "\n",
    "K\\V (10,512)\n",
    "\n",
    "Q (10,512) ==> expanding\\广播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321ed2c-9458-4839-b7cb-13b125baeccb",
   "metadata": {},
   "source": [
    "## 3.2 Encoder-Only任务下的Transformer实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4647c-790e-4ca2-bd1e-451e48cc2d31",
   "metadata": {},
   "source": [
    "不难发现，torch.nn下面配置了一系列构成transformer的元素，但是却没有构成完整的Transformer算法。正如我们 之前提到的那样，在NLP的世界中，不同的任务会对Transformer架构提出不同的要求，编码器和解码器是设计成可以独立或一起使用的组件。它们可以根据不同的NLP任务需求进行组合，以适应各种场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc4689-8609-4bdc-b4c3-cc9c3b12c2b0",
   "metadata": {},
   "source": [
    "### 3.2.1 Encoder-Only任务下的Transformer架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d272fd-6482-4272-917e-65cac3068524",
   "metadata": {},
   "source": [
    "- **只使用编码器的任务**：编码器部分的任务是从输入数据中提取特征。编码器通常用于不需要生成新文本序列的任务，比如：\n",
    "> 文本分类：如情感分析，垃圾邮件检测等，输入一个文本序列，编码器提取特征后进行分类。<br><br>\n",
    "> 命名实体识别（Named Entity Recognition, NER）：在给定文本中识别出实体（如人名、地点等），这也是分类问题的一种，可以用编码器提取文本的特征。<br><br>\n",
    "> 句子相似度：判断两个句子是否相关或相似度如何，可以通过编码器提取句子特征后计算相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bbf24-c447-4613-a3ed-e5a5bc5232a5",
   "metadata": {},
   "source": [
    "Encoder-only架构应该包括如下结构：\n",
    "\n",
    "1. **输入层**：输入序列会通过一个嵌入层，将每个词转换为一个向量表示。\n",
    "2. **位置编码**：添加位置编码，以保留序列中词的位置信息。\n",
    "3. **Transformer 编码器**：使用多个编码器层堆叠，以处理输入序列。\n",
    "4. **输出层**：将编码器输出的表示转换为目标任务所需的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd521a47-d7ff-4933-845a-f24df9683321",
   "metadata": {},
   "source": [
    "#### 3.2.1.1 Embedding层与Encoder数据输入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbbf8e-b270-45fc-8eb1-34bbd5586ed0",
   "metadata": {},
   "source": [
    "<font color=\"red\">**CLASS`torch.nn.Embedding`(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, _freeze=False, device=None, dtype=None)</font>**\n",
    "> **num_embeddings**：词汇表的总长，即词汇表中包含的单词总数量<br><br>\n",
    "> **embedding_dim**：每个单词需要被变成的维度，即transformer中的d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea059878-8c76-4c4c-a06e-976dc22454a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd = nn.Embedding(2000, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6415da1-dfc1-46a0-be1e-866c47368596",
   "metadata": {},
   "source": [
    "embedding可以接纳各式各样维度的数据——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aa9b18f-1e0b-46b1-814c-7ad3304a84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([1,2,3,4,5]) #(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93fc5819-80af-43b9-837d-f03b25ae5b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd(input_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01e4e084-af6f-4798-aa3c-f4238eba7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有两个序列，每个序列包含5个词\n",
    "input_data = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32aa3c82-0856-4e0f-8879-3010da0565d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data #(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aa51420-a3e4-4350-9a05-9dc7a17c53f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd(input_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b9897-1dfc-4031-953f-337e048d7939",
   "metadata": {},
   "source": [
    "不难发现，无论我们对embedding层输入怎样的数据，它只会将最后的维度拓展为我们设置的d_model，并不对其他结构进行改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89333b1f-74fd-43fb-b0d4-e1461debe3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试一段真实的文字作为输入\n",
    "# 从一段话变为能够输入到embedding层的信息，还需经过以下的步骤：\n",
    "# 1)分词 2)制作词汇表 3)依据词汇表编码 4)填充编码后序列，形成统一的seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2193e1d8-6bc0-4e8e-89ec-4dab2a73a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Shuyu\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.542 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# 输入文本\n",
    "text1 = \"\"\"朝堂是谁的朝堂，天下又是谁的天下——庆帝的文武百官绝不敢轻易忤逆或直谏，\\\\\n",
    "夹缝里喘息，贪污，结党，企图吞噬一点点这肮脏血腥的权力，却落得个死无葬身之地，\\\\\n",
    "他想起赖明成，陈萍萍，那些一个个被处以极刑的大臣，他与承乾自孩提时代就见识过权力只是一把刀子，\\\\\n",
    "一场流血，一个个微不足道的死亡，于是他们恐惧又愤恨，他们开始认为阴谋诡计是一种力量，\\\\\n",
    "非要一刀见血，才是一次胜利，嬴的人才配活着，与野兽何异？他们在跟谁争，\\\\\n",
    "只有庆帝一个人把握着权柄，把它高高挂起，高于良知，高于品德，高于世间万物，\\\\\n",
    "他们竟然在争抢这样一个丑陋又卑鄙，散发着腐烂恶臭的东西。\"\"\"\n",
    "\n",
    "text2 = \"\"\"人心？那我亏大了，自抬身价罢了。你觉得他们会感激我，那都是一时的，\\\\\n",
    "他们求的是自己想要的东西，我满足了一时片刻，他们就想要有别的东西了，\\\\\n",
    "这点儿不长久的人心算什么人心。你看那些古来文人大家，那庄墨韩，人人追捧，\\\\\n",
    "高高在上，不容亵渎，一字换一城也毫不夸张，是笔墨纸张值钱，还是他们的名气？\\\\\n",
    "就像是最近给你送礼攀关系那些人一样的，他们为的不是一时的东西，我也不能做那一\\\\\n",
    "时的玩意儿。”李承泽收回目光，转过身来，他握紧了自己的一双手，直视着谢必安冰冷\\\\\n",
    "宛如冬夜般的眼睛，“必安，你得明白，东宫太子有父母，有名头，有朝臣，陛下，\\\\\n",
    "拥有这个天下的人和财权，我只有我自己，但是我要让你知道的是，这些他们有的，\\\\\n",
    "不见得一直有，我依然有我自己。\"\"\"\n",
    "\n",
    "# 使用 jieba 进行分词，要对所有的文本进行分词\n",
    "words = jieba.lcut(text1 + \" \" + text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cbf9a1d-ef48-46d3-a4a1-2b98b7b63ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['朝堂',\n",
       " '是',\n",
       " '谁',\n",
       " '的',\n",
       " '朝堂',\n",
       " '，',\n",
       " '天下',\n",
       " '又',\n",
       " '是',\n",
       " '谁',\n",
       " '的',\n",
       " '天下',\n",
       " '—',\n",
       " '—',\n",
       " '庆帝',\n",
       " '的',\n",
       " '文武百官',\n",
       " '绝',\n",
       " '不敢',\n",
       " '轻易',\n",
       " '忤逆',\n",
       " '或',\n",
       " '直谏',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '夹缝',\n",
       " '里',\n",
       " '喘息',\n",
       " '，',\n",
       " '贪污',\n",
       " '，',\n",
       " '结党',\n",
       " '，',\n",
       " '企图',\n",
       " '吞噬',\n",
       " '一点点',\n",
       " '这',\n",
       " '肮脏',\n",
       " '血腥',\n",
       " '的',\n",
       " '权力',\n",
       " '，',\n",
       " '却',\n",
       " '落得',\n",
       " '个',\n",
       " '死无葬身之地',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '他',\n",
       " '想起',\n",
       " '赖明成',\n",
       " '，',\n",
       " '陈萍萍',\n",
       " '，',\n",
       " '那些',\n",
       " '一个个',\n",
       " '被',\n",
       " '处以',\n",
       " '极刑',\n",
       " '的',\n",
       " '大臣',\n",
       " '，',\n",
       " '他',\n",
       " '与',\n",
       " '承乾自',\n",
       " '孩提时代',\n",
       " '就',\n",
       " '见识',\n",
       " '过',\n",
       " '权力',\n",
       " '只是',\n",
       " '一把',\n",
       " '刀子',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '一场',\n",
       " '流血',\n",
       " '，',\n",
       " '一个个',\n",
       " '微不足道',\n",
       " '的',\n",
       " '死亡',\n",
       " '，',\n",
       " '于是',\n",
       " '他们',\n",
       " '恐惧',\n",
       " '又',\n",
       " '愤恨',\n",
       " '，',\n",
       " '他们',\n",
       " '开始',\n",
       " '认为',\n",
       " '阴谋诡计',\n",
       " '是',\n",
       " '一种',\n",
       " '力量',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '非',\n",
       " '要',\n",
       " '一刀',\n",
       " '见血',\n",
       " '，',\n",
       " '才',\n",
       " '是',\n",
       " '一次',\n",
       " '胜利',\n",
       " '，',\n",
       " '嬴',\n",
       " '的',\n",
       " '人才',\n",
       " '配',\n",
       " '活着',\n",
       " '，',\n",
       " '与',\n",
       " '野兽',\n",
       " '何异',\n",
       " '？',\n",
       " '他们',\n",
       " '在',\n",
       " '跟',\n",
       " '谁',\n",
       " '争',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '只有',\n",
       " '庆帝',\n",
       " '一个',\n",
       " '人',\n",
       " '把握',\n",
       " '着',\n",
       " '权柄',\n",
       " '，',\n",
       " '把',\n",
       " '它',\n",
       " '高高挂起',\n",
       " '，',\n",
       " '高于',\n",
       " '良知',\n",
       " '，',\n",
       " '高于',\n",
       " '品德',\n",
       " '，',\n",
       " '高于',\n",
       " '世间',\n",
       " '万物',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '他们',\n",
       " '竟然',\n",
       " '在',\n",
       " '争抢',\n",
       " '这样',\n",
       " '一个',\n",
       " '丑陋',\n",
       " '又',\n",
       " '卑鄙',\n",
       " '，',\n",
       " '散发',\n",
       " '着',\n",
       " '腐烂',\n",
       " '恶臭',\n",
       " '的',\n",
       " '东西',\n",
       " '。',\n",
       " ' ',\n",
       " '人心',\n",
       " '？',\n",
       " '那',\n",
       " '我',\n",
       " '亏',\n",
       " '大',\n",
       " '了',\n",
       " '，',\n",
       " '自',\n",
       " '抬',\n",
       " '身价',\n",
       " '罢了',\n",
       " '。',\n",
       " '你',\n",
       " '觉得',\n",
       " '他们',\n",
       " '会',\n",
       " '感激',\n",
       " '我',\n",
       " '，',\n",
       " '那',\n",
       " '都',\n",
       " '是',\n",
       " '一时',\n",
       " '的',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '他们',\n",
       " '求',\n",
       " '的',\n",
       " '是',\n",
       " '自己',\n",
       " '想要',\n",
       " '的',\n",
       " '东西',\n",
       " '，',\n",
       " '我',\n",
       " '满足',\n",
       " '了',\n",
       " '一时',\n",
       " '片刻',\n",
       " '，',\n",
       " '他们',\n",
       " '就',\n",
       " '想要',\n",
       " '有',\n",
       " '别的',\n",
       " '东西',\n",
       " '了',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '这点儿',\n",
       " '不',\n",
       " '长久',\n",
       " '的',\n",
       " '人心',\n",
       " '算',\n",
       " '什么',\n",
       " '人心',\n",
       " '。',\n",
       " '你',\n",
       " '看',\n",
       " '那些',\n",
       " '古来',\n",
       " '文人',\n",
       " '大家',\n",
       " '，',\n",
       " '那庄墨',\n",
       " '韩',\n",
       " '，',\n",
       " '人人',\n",
       " '追捧',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '高高在上',\n",
       " '，',\n",
       " '不容',\n",
       " '亵渎',\n",
       " '，',\n",
       " '一字换',\n",
       " '一城',\n",
       " '也',\n",
       " '毫不',\n",
       " '夸张',\n",
       " '，',\n",
       " '是',\n",
       " '笔墨',\n",
       " '纸张',\n",
       " '值钱',\n",
       " '，',\n",
       " '还是',\n",
       " '他们',\n",
       " '的',\n",
       " '名气',\n",
       " '？',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '就',\n",
       " '像是',\n",
       " '最近',\n",
       " '给',\n",
       " '你',\n",
       " '送礼',\n",
       " '攀',\n",
       " '关系',\n",
       " '那些',\n",
       " '人',\n",
       " '一样',\n",
       " '的',\n",
       " '，',\n",
       " '他们',\n",
       " '为',\n",
       " '的',\n",
       " '不是',\n",
       " '一时',\n",
       " '的',\n",
       " '东西',\n",
       " '，',\n",
       " '我',\n",
       " '也',\n",
       " '不能',\n",
       " '做',\n",
       " '那',\n",
       " '一',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '时',\n",
       " '的',\n",
       " '玩意儿',\n",
       " '。',\n",
       " '”',\n",
       " '李承泽',\n",
       " '收回',\n",
       " '目光',\n",
       " '，',\n",
       " '转过身',\n",
       " '来',\n",
       " '，',\n",
       " '他',\n",
       " '握紧',\n",
       " '了',\n",
       " '自己',\n",
       " '的',\n",
       " '一',\n",
       " '双手',\n",
       " '，',\n",
       " '直视',\n",
       " '着',\n",
       " '谢必安',\n",
       " '冰冷',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '宛如',\n",
       " '冬夜',\n",
       " '般的',\n",
       " '眼睛',\n",
       " '，',\n",
       " '“',\n",
       " '必安',\n",
       " '，',\n",
       " '你',\n",
       " '得',\n",
       " '明白',\n",
       " '，',\n",
       " '东宫太子',\n",
       " '有',\n",
       " '父母',\n",
       " '，',\n",
       " '有',\n",
       " '名头',\n",
       " '，',\n",
       " '有',\n",
       " '朝臣',\n",
       " '，',\n",
       " '陛下',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '拥有',\n",
       " '这个',\n",
       " '天下',\n",
       " '的',\n",
       " '人',\n",
       " '和',\n",
       " '财权',\n",
       " '，',\n",
       " '我',\n",
       " '只有',\n",
       " '我',\n",
       " '自己',\n",
       " '，',\n",
       " '但是',\n",
       " '我要',\n",
       " '让',\n",
       " '你',\n",
       " '知道',\n",
       " '的',\n",
       " '是',\n",
       " '，',\n",
       " '这些',\n",
       " '他们',\n",
       " '有',\n",
       " '的',\n",
       " '，',\n",
       " '\\\\',\n",
       " '\\n',\n",
       " '不见得',\n",
       " '一直',\n",
       " '有',\n",
       " '，',\n",
       " '我',\n",
       " '依然',\n",
       " '有',\n",
       " '我',\n",
       " '自己',\n",
       " '。']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0493df7-1026-4821-9bcc-310588af5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计词频并生成词汇表\n",
    "word_counts = Counter(words)\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(word_counts.items(), 1)}  # 从1开始编码，0留给padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e3d5489-c2ac-4e17-9116-b5dead612e07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'朝堂': 2,\n",
       "         '是': 8,\n",
       "         '谁': 3,\n",
       "         '的': 21,\n",
       "         '，': 55,\n",
       "         '天下': 3,\n",
       "         '又': 3,\n",
       "         '—': 2,\n",
       "         '庆帝': 2,\n",
       "         '文武百官': 1,\n",
       "         '绝': 1,\n",
       "         '不敢': 1,\n",
       "         '轻易': 1,\n",
       "         '忤逆': 1,\n",
       "         '或': 1,\n",
       "         '直谏': 1,\n",
       "         '\\\\': 14,\n",
       "         '\\n': 14,\n",
       "         '夹缝': 1,\n",
       "         '里': 1,\n",
       "         '喘息': 1,\n",
       "         '贪污': 1,\n",
       "         '结党': 1,\n",
       "         '企图': 1,\n",
       "         '吞噬': 1,\n",
       "         '一点点': 1,\n",
       "         '这': 1,\n",
       "         '肮脏': 1,\n",
       "         '血腥': 1,\n",
       "         '权力': 2,\n",
       "         '却': 1,\n",
       "         '落得': 1,\n",
       "         '个': 1,\n",
       "         '死无葬身之地': 1,\n",
       "         '他': 3,\n",
       "         '想起': 1,\n",
       "         '赖明成': 1,\n",
       "         '陈萍萍': 1,\n",
       "         '那些': 3,\n",
       "         '一个个': 2,\n",
       "         '被': 1,\n",
       "         '处以': 1,\n",
       "         '极刑': 1,\n",
       "         '大臣': 1,\n",
       "         '与': 2,\n",
       "         '承乾自': 1,\n",
       "         '孩提时代': 1,\n",
       "         '就': 3,\n",
       "         '见识': 1,\n",
       "         '过': 1,\n",
       "         '只是': 1,\n",
       "         '一把': 1,\n",
       "         '刀子': 1,\n",
       "         '一场': 1,\n",
       "         '流血': 1,\n",
       "         '微不足道': 1,\n",
       "         '死亡': 1,\n",
       "         '于是': 1,\n",
       "         '他们': 10,\n",
       "         '恐惧': 1,\n",
       "         '愤恨': 1,\n",
       "         '开始': 1,\n",
       "         '认为': 1,\n",
       "         '阴谋诡计': 1,\n",
       "         '一种': 1,\n",
       "         '力量': 1,\n",
       "         '非': 1,\n",
       "         '要': 1,\n",
       "         '一刀': 1,\n",
       "         '见血': 1,\n",
       "         '才': 1,\n",
       "         '一次': 1,\n",
       "         '胜利': 1,\n",
       "         '嬴': 1,\n",
       "         '人才': 1,\n",
       "         '配': 1,\n",
       "         '活着': 1,\n",
       "         '野兽': 1,\n",
       "         '何异': 1,\n",
       "         '？': 3,\n",
       "         '在': 2,\n",
       "         '跟': 1,\n",
       "         '争': 1,\n",
       "         '只有': 2,\n",
       "         '一个': 2,\n",
       "         '人': 3,\n",
       "         '把握': 1,\n",
       "         '着': 3,\n",
       "         '权柄': 1,\n",
       "         '把': 1,\n",
       "         '它': 1,\n",
       "         '高高挂起': 1,\n",
       "         '高于': 3,\n",
       "         '良知': 1,\n",
       "         '品德': 1,\n",
       "         '世间': 1,\n",
       "         '万物': 1,\n",
       "         '竟然': 1,\n",
       "         '争抢': 1,\n",
       "         '这样': 1,\n",
       "         '丑陋': 1,\n",
       "         '卑鄙': 1,\n",
       "         '散发': 1,\n",
       "         '腐烂': 1,\n",
       "         '恶臭': 1,\n",
       "         '东西': 4,\n",
       "         '。': 5,\n",
       "         ' ': 1,\n",
       "         '人心': 3,\n",
       "         '那': 3,\n",
       "         '我': 8,\n",
       "         '亏': 1,\n",
       "         '大': 1,\n",
       "         '了': 4,\n",
       "         '自': 1,\n",
       "         '抬': 1,\n",
       "         '身价': 1,\n",
       "         '罢了': 1,\n",
       "         '你': 5,\n",
       "         '觉得': 1,\n",
       "         '会': 1,\n",
       "         '感激': 1,\n",
       "         '都': 1,\n",
       "         '一时': 3,\n",
       "         '求': 1,\n",
       "         '自己': 4,\n",
       "         '想要': 2,\n",
       "         '满足': 1,\n",
       "         '片刻': 1,\n",
       "         '有': 7,\n",
       "         '别的': 1,\n",
       "         '这点儿': 1,\n",
       "         '不': 1,\n",
       "         '长久': 1,\n",
       "         '算': 1,\n",
       "         '什么': 1,\n",
       "         '看': 1,\n",
       "         '古来': 1,\n",
       "         '文人': 1,\n",
       "         '大家': 1,\n",
       "         '那庄墨': 1,\n",
       "         '韩': 1,\n",
       "         '人人': 1,\n",
       "         '追捧': 1,\n",
       "         '高高在上': 1,\n",
       "         '不容': 1,\n",
       "         '亵渎': 1,\n",
       "         '一字换': 1,\n",
       "         '一城': 1,\n",
       "         '也': 2,\n",
       "         '毫不': 1,\n",
       "         '夸张': 1,\n",
       "         '笔墨': 1,\n",
       "         '纸张': 1,\n",
       "         '值钱': 1,\n",
       "         '还是': 1,\n",
       "         '名气': 1,\n",
       "         '像是': 1,\n",
       "         '最近': 1,\n",
       "         '给': 1,\n",
       "         '送礼': 1,\n",
       "         '攀': 1,\n",
       "         '关系': 1,\n",
       "         '一样': 1,\n",
       "         '为': 1,\n",
       "         '不是': 1,\n",
       "         '不能': 1,\n",
       "         '做': 1,\n",
       "         '一': 2,\n",
       "         '时': 1,\n",
       "         '玩意儿': 1,\n",
       "         '”': 1,\n",
       "         '李承泽': 1,\n",
       "         '收回': 1,\n",
       "         '目光': 1,\n",
       "         '转过身': 1,\n",
       "         '来': 1,\n",
       "         '握紧': 1,\n",
       "         '双手': 1,\n",
       "         '直视': 1,\n",
       "         '谢必安': 1,\n",
       "         '冰冷': 1,\n",
       "         '宛如': 1,\n",
       "         '冬夜': 1,\n",
       "         '般的': 1,\n",
       "         '眼睛': 1,\n",
       "         '“': 1,\n",
       "         '必安': 1,\n",
       "         '得': 1,\n",
       "         '明白': 1,\n",
       "         '东宫太子': 1,\n",
       "         '父母': 1,\n",
       "         '名头': 1,\n",
       "         '朝臣': 1,\n",
       "         '陛下': 1,\n",
       "         '拥有': 1,\n",
       "         '这个': 1,\n",
       "         '和': 1,\n",
       "         '财权': 1,\n",
       "         '但是': 1,\n",
       "         '我要': 1,\n",
       "         '让': 1,\n",
       "         '知道': 1,\n",
       "         '这些': 1,\n",
       "         '不见得': 1,\n",
       "         '一直': 1,\n",
       "         '依然': 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efa66230-0dea-4a50-860a-717ca7dad9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'朝堂': 1,\n",
       " '是': 2,\n",
       " '谁': 3,\n",
       " '的': 4,\n",
       " '，': 5,\n",
       " '天下': 6,\n",
       " '又': 7,\n",
       " '—': 8,\n",
       " '庆帝': 9,\n",
       " '文武百官': 10,\n",
       " '绝': 11,\n",
       " '不敢': 12,\n",
       " '轻易': 13,\n",
       " '忤逆': 14,\n",
       " '或': 15,\n",
       " '直谏': 16,\n",
       " '\\\\': 17,\n",
       " '\\n': 18,\n",
       " '夹缝': 19,\n",
       " '里': 20,\n",
       " '喘息': 21,\n",
       " '贪污': 22,\n",
       " '结党': 23,\n",
       " '企图': 24,\n",
       " '吞噬': 25,\n",
       " '一点点': 26,\n",
       " '这': 27,\n",
       " '肮脏': 28,\n",
       " '血腥': 29,\n",
       " '权力': 30,\n",
       " '却': 31,\n",
       " '落得': 32,\n",
       " '个': 33,\n",
       " '死无葬身之地': 34,\n",
       " '他': 35,\n",
       " '想起': 36,\n",
       " '赖明成': 37,\n",
       " '陈萍萍': 38,\n",
       " '那些': 39,\n",
       " '一个个': 40,\n",
       " '被': 41,\n",
       " '处以': 42,\n",
       " '极刑': 43,\n",
       " '大臣': 44,\n",
       " '与': 45,\n",
       " '承乾自': 46,\n",
       " '孩提时代': 47,\n",
       " '就': 48,\n",
       " '见识': 49,\n",
       " '过': 50,\n",
       " '只是': 51,\n",
       " '一把': 52,\n",
       " '刀子': 53,\n",
       " '一场': 54,\n",
       " '流血': 55,\n",
       " '微不足道': 56,\n",
       " '死亡': 57,\n",
       " '于是': 58,\n",
       " '他们': 59,\n",
       " '恐惧': 60,\n",
       " '愤恨': 61,\n",
       " '开始': 62,\n",
       " '认为': 63,\n",
       " '阴谋诡计': 64,\n",
       " '一种': 65,\n",
       " '力量': 66,\n",
       " '非': 67,\n",
       " '要': 68,\n",
       " '一刀': 69,\n",
       " '见血': 70,\n",
       " '才': 71,\n",
       " '一次': 72,\n",
       " '胜利': 73,\n",
       " '嬴': 74,\n",
       " '人才': 75,\n",
       " '配': 76,\n",
       " '活着': 77,\n",
       " '野兽': 78,\n",
       " '何异': 79,\n",
       " '？': 80,\n",
       " '在': 81,\n",
       " '跟': 82,\n",
       " '争': 83,\n",
       " '只有': 84,\n",
       " '一个': 85,\n",
       " '人': 86,\n",
       " '把握': 87,\n",
       " '着': 88,\n",
       " '权柄': 89,\n",
       " '把': 90,\n",
       " '它': 91,\n",
       " '高高挂起': 92,\n",
       " '高于': 93,\n",
       " '良知': 94,\n",
       " '品德': 95,\n",
       " '世间': 96,\n",
       " '万物': 97,\n",
       " '竟然': 98,\n",
       " '争抢': 99,\n",
       " '这样': 100,\n",
       " '丑陋': 101,\n",
       " '卑鄙': 102,\n",
       " '散发': 103,\n",
       " '腐烂': 104,\n",
       " '恶臭': 105,\n",
       " '东西': 106,\n",
       " '。': 107,\n",
       " ' ': 108,\n",
       " '人心': 109,\n",
       " '那': 110,\n",
       " '我': 111,\n",
       " '亏': 112,\n",
       " '大': 113,\n",
       " '了': 114,\n",
       " '自': 115,\n",
       " '抬': 116,\n",
       " '身价': 117,\n",
       " '罢了': 118,\n",
       " '你': 119,\n",
       " '觉得': 120,\n",
       " '会': 121,\n",
       " '感激': 122,\n",
       " '都': 123,\n",
       " '一时': 124,\n",
       " '求': 125,\n",
       " '自己': 126,\n",
       " '想要': 127,\n",
       " '满足': 128,\n",
       " '片刻': 129,\n",
       " '有': 130,\n",
       " '别的': 131,\n",
       " '这点儿': 132,\n",
       " '不': 133,\n",
       " '长久': 134,\n",
       " '算': 135,\n",
       " '什么': 136,\n",
       " '看': 137,\n",
       " '古来': 138,\n",
       " '文人': 139,\n",
       " '大家': 140,\n",
       " '那庄墨': 141,\n",
       " '韩': 142,\n",
       " '人人': 143,\n",
       " '追捧': 144,\n",
       " '高高在上': 145,\n",
       " '不容': 146,\n",
       " '亵渎': 147,\n",
       " '一字换': 148,\n",
       " '一城': 149,\n",
       " '也': 150,\n",
       " '毫不': 151,\n",
       " '夸张': 152,\n",
       " '笔墨': 153,\n",
       " '纸张': 154,\n",
       " '值钱': 155,\n",
       " '还是': 156,\n",
       " '名气': 157,\n",
       " '像是': 158,\n",
       " '最近': 159,\n",
       " '给': 160,\n",
       " '送礼': 161,\n",
       " '攀': 162,\n",
       " '关系': 163,\n",
       " '一样': 164,\n",
       " '为': 165,\n",
       " '不是': 166,\n",
       " '不能': 167,\n",
       " '做': 168,\n",
       " '一': 169,\n",
       " '时': 170,\n",
       " '玩意儿': 171,\n",
       " '”': 172,\n",
       " '李承泽': 173,\n",
       " '收回': 174,\n",
       " '目光': 175,\n",
       " '转过身': 176,\n",
       " '来': 177,\n",
       " '握紧': 178,\n",
       " '双手': 179,\n",
       " '直视': 180,\n",
       " '谢必安': 181,\n",
       " '冰冷': 182,\n",
       " '宛如': 183,\n",
       " '冬夜': 184,\n",
       " '般的': 185,\n",
       " '眼睛': 186,\n",
       " '“': 187,\n",
       " '必安': 188,\n",
       " '得': 189,\n",
       " '明白': 190,\n",
       " '东宫太子': 191,\n",
       " '父母': 192,\n",
       " '名头': 193,\n",
       " '朝臣': 194,\n",
       " '陛下': 195,\n",
       " '拥有': 196,\n",
       " '这个': 197,\n",
       " '和': 198,\n",
       " '财权': 199,\n",
       " '但是': 200,\n",
       " '我要': 201,\n",
       " '让': 202,\n",
       " '知道': 203,\n",
       " '这些': 204,\n",
       " '不见得': 205,\n",
       " '一直': 206,\n",
       " '依然': 207}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab #是词汇表，包含了每个词和对应的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4e80df7-7525-414a-be8a-ea0b202f12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将分词结果转换为索引序列\n",
    "texts = []\n",
    "max_len = 0\n",
    "\n",
    "for text in [text1,text2]:\n",
    "    #将编码映射到每个词上\n",
    "    encoded_sequence = [vocab[word] for word in jieba.lcut(text)]\n",
    "    texts.append(encoded_sequence)\n",
    "\n",
    "    #确认max_len是多少\n",
    "    if len(encoded_sequence) > max_len:\n",
    "        max_len = len(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8492c772-e592-4dc8-9f23-41381cbe112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2e1c968-a06b-4afc-a380-32ee7d11e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#依据max_len对句子进行填充\n",
    "sequence = []\n",
    "for text in texts:\n",
    "    padding_text = text + [0] * (max_len - len(text))\n",
    "    sequence.append(padding_text)  # 使用0进行padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff0b397d-1b77-452a-8643-6931ec8a4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为 PyTorch 张量\n",
    "sequences = torch.tensor(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b4b87f5-fdc3-412d-bdae-a53dad3222e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   1,   5,   6,   7,   2,   3,   4,   6,   8,   8,\n",
       "           9,   4,  10,  11,  12,  13,  14,  15,  16,   5,  17,  18,  19,  20,\n",
       "          21,   5,  22,   5,  23,   5,  24,  25,  26,  27,  28,  29,   4,  30,\n",
       "           5,  31,  32,  33,  34,   5,  17,  18,  35,  36,  37,   5,  38,   5,\n",
       "          39,  40,  41,  42,  43,   4,  44,   5,  35,  45,  46,  47,  48,  49,\n",
       "          50,  30,  51,  52,  53,   5,  17,  18,  54,  55,   5,  40,  56,   4,\n",
       "          57,   5,  58,  59,  60,   7,  61,   5,  59,  62,  63,  64,   2,  65,\n",
       "          66,   5,  17,  18,  67,  68,  69,  70,   5,  71,   2,  72,  73,   5,\n",
       "          74,   4,  75,  76,  77,   5,  45,  78,  79,  80,  59,  81,  82,   3,\n",
       "          83,   5,  17,  18,  84,   9,  85,  86,  87,  88,  89,   5,  90,  91,\n",
       "          92,   5,  93,  94,   5,  93,  95,   5,  93,  96,  97,   5,  17,  18,\n",
       "          59,  98,  81,  99, 100,  85, 101,   7, 102,   5, 103,  88, 104, 105,\n",
       "           4, 106, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [109,  80, 110, 111, 112, 113, 114,   5, 115, 116, 117, 118, 107, 119,\n",
       "         120,  59, 121, 122, 111,   5, 110, 123,   2, 124,   4,   5,  17,  18,\n",
       "          59, 125,   4,   2, 126, 127,   4, 106,   5, 111, 128, 114, 124, 129,\n",
       "           5,  59,  48, 127, 130, 131, 106, 114,   5,  17,  18, 132, 133, 134,\n",
       "           4, 109, 135, 136, 109, 107, 119, 137,  39, 138, 139, 140,   5, 141,\n",
       "         142,   5, 143, 144,   5,  17,  18, 145,   5, 146, 147,   5, 148, 149,\n",
       "         150, 151, 152,   5,   2, 153, 154, 155,   5, 156,  59,   4, 157,  80,\n",
       "          17,  18,  48, 158, 159, 160, 119, 161, 162, 163,  39,  86, 164,   4,\n",
       "           5,  59, 165,   4, 166, 124,   4, 106,   5, 111, 150, 167, 168, 110,\n",
       "         169,  17,  18, 170,   4, 171, 107, 172, 173, 174, 175,   5, 176, 177,\n",
       "           5,  35, 178, 114, 126,   4, 169, 179,   5, 180,  88, 181, 182,  17,\n",
       "          18, 183, 184, 185, 186,   5, 187, 188,   5, 119, 189, 190,   5, 191,\n",
       "         130, 192,   5, 130, 193,   5, 130, 194,   5, 195,   5,  17,  18, 196,\n",
       "         197,   6,   4,  86, 198, 199,   5, 111,  84, 111, 126,   5, 200, 201,\n",
       "         202, 119, 203,   4,   2,   5, 204,  59, 130,   4,   5,  17,  18, 205,\n",
       "         206, 130,   5, 111, 207, 130, 111, 126, 107]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences\n",
    "#形状为(2, 句子长度)的 PyTorch 张量，其中每个序列都被填充到相同的长度，这就是输入Transformer的数据X\n",
    "#当然，在Encoder-Only结构中，我们还需要关注标签，我们需要使用dataloder打包标签，给损失函数使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddd3d653-e6ba-4b2f-a746-e0a459f9cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 219, 512])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd = nn.Embedding(2000, 512)\n",
    "ebd(sequences).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9e461-4956-46ff-8685-d952464673ac",
   "metadata": {},
   "source": [
    "需要注意的是，**在实际构建Encoder时，Embedding 层既可以写在 Encoder 的结构中，也可以单独写**。如果将Embedding层写在Encoder结构中，代码会整洁，所有与模型相关的部分都在同一个类中，便于维护，但这个操作相当于将整个Transformer结构的输入数据由(batch_size, seq_len, input_dimensions)结构修改为了(batch_size, seq_len)结构、从而会影响掩码的结构、影响掩码函数、这个Embedding层无法与Decoder或其他算法共用、甚至可能导致你的Encoder结构无法用于时间序列任务；如果我们将Embedding层写在Encoder结构之外，灵活性更高，可以在多个模型中共享同一个 Embedding 层，也可以对Embedding后的结果进行更加顺畅的独立处理，但缺点是就需要额外的代码来管理Embedding层的初始化和传递。在实际进行编程时，Embedding结构究竟写在Encoder内还是外，与你的数据和实现的架构有很大的关系，你需要根据具体情况进行具体的分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e5635-a197-488a-b2c4-b979ef5cc688",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 位置编码的实现与技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336efa8-19f2-4947-a86c-43313be83b52",
   "metadata": {},
   "source": [
    "首先，正弦余弦位置编码的公式如下：\n",
    "\n",
    "> - 正弦位置编码（Sinusoidal Positional Encoding）\n",
    "$$PE_{(pos, 2i)} = \\sin \\left( \\frac{pos}{10000^{\\frac{2i}{d_{\\text{model}}}}} \\right) $$\n",
    "\n",
    "> - 余弦位置编码（Cosine Positional Encoding）\n",
    "$$ PE_{(pos, 2i+1)} = \\cos \\left( \\frac{pos}{10000^{\\frac{2i}{d_{\\text{model}}}}} \\right) $$\n",
    "\n",
    "其中——\n",
    "> - pos代表样本在序列中的位置，也就是样本的索引（是三维度中的seq_len/vocal_size/time_step这个维度上的索引）<br><br>\n",
    "> - $2i$和$2i+1$分别代表embedding矩阵中的偶数和奇数维度索引，当我们让i从0开始循环增长时，可以获得[0,1,2,3,4,5,6...]这样的序列。<br><br>\n",
    "> - $d_{\\text{model}} $ 代表embedding后矩阵的总维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88882c8c-764f-4c37-a110-90cd8ef5bd3a",
   "metadata": {},
   "source": [
    "![Alt text](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9d764-b5bb-40d1-a992-ddc58cf6c2cb",
   "metadata": {},
   "source": [
    "正弦余弦编码的具体代码时下方式如下 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911638d1-b1f1-438d-ad18-095063290370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        \"\"\"\n",
    "        创造位置编码层（设定为batch_first=False模式）\n",
    "        \n",
    "        参数:\n",
    "        d_model (int): 嵌入向量的维度。\n",
    "        dropout (float): Dropout 概率。\n",
    "        max_len (int): 序列的最大长度（注意与矩阵中的seq_len区分开来）\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # 位置编码作为精确到每一个维度的信息，容易导致过拟合\n",
    "        # 因此在实际实践位置编码的时候我们会加上扛过拟合的dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 创建一个空白的编码矩阵，形状为 (max_len, d_model)\n",
    "        # 通过给空白的位置编码矩阵填上具体值，来构成真正的位置编码矩阵\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        # 接下来开始生成正弦余弦编码公式中的各个元素\n",
    "        # 位置索引 (pos)，形状为 (max_len, 1)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # 计算公式中的分母，由于分母会随着特征的编号i发生变化，因此要根据不同的i计算出不同的分母\n",
    "        # 应用于sin的偶数列和应用于cos的奇数列的数目是一致的，分别占原始特征的1/2\n",
    "        # 同时，应用于sin和cos公式的分母都是一致的\n",
    "        # 因此我们只需要计算出一组分母，就可以给sin和cos函数通用，这组分母的数量是 d_model/2\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        # 计算出分母后，计算出正弦余弦值，并赋值给原本设置好的位置编码矩阵\n",
    "        # 计算正弦位置编码: PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "        # 所有行上、从0开始、每2列赋予一个sin值\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # 计算余弦位置编码: PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "        # 所有行上，从1开始，每2列赋予一个cos值\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # 正弦余弦位置编码加起来的结构应该等于d_model\n",
    "        \n",
    "        # 使用unsquezze添加batch维度，将原本二维的结构转变为三维，形状变为 (1, max_len, d_model)\n",
    "        # 又使用transpose交换了维度，因此pe的最终结构是(max_len, 1, d_model)，这是batch_first=False下合理的结构\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # 位置编码与batch无关，因此对所有batch都是一样的\n",
    "        # 最终会通过广播的方式复制成(seq_len, batch_size, input_dimension)上\n",
    "        \n",
    "        # 将位置编码矩阵注册为模型的缓冲区，不会作为模型参数更新\n",
    "        # 同时，这一步相当于定义了self.pe，但规定pe不参与模型参数更新\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数，给输入添加位置编码。\n",
    "        \n",
    "        参数:\n",
    "        x (Tensor): embedding后的张量，形状为 (batch_size, seq_len, d_model)\n",
    "        \n",
    "        返回值:\n",
    "        Tensor: 添加了位置编码的输入张量，形状不变\n",
    "        \"\"\"\n",
    "        # 添加位置编码，注意这里对位置编码进行了切片以匹配输入的序列长度\n",
    "        # 也就是说，会根据x中的seq_len对原本设置的max_len进行裁剪\n",
    "        # 为什么要在init中设置max_len，然后在forward中进行裁剪？\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        \n",
    "        # 应用 Dropout 并返回\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a9676-f134-49ae-9f81-19576c1d414b",
   "metadata": {},
   "source": [
    "> 细节解读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17604b8-6151-4df8-b0f5-f0150060147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#假定数据\n",
    "x = torch.zeros(size=(32,10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3388bdff-1bfd-4da7-9409-a153bd16d008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed44bd84-1f8c-4eda-98f6-23e76e0f4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置超参数值\n",
    "max_len = 15\n",
    "d_model = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b6ba2b-67fd-44fa-b701-252c460a3f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#为生成的位置编码准备完整的矩阵\n",
    "\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "pe.shape #直接生成一个能够与特征矩阵完美相加的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425a5897-4c62-48de-8241-cbaab3aa5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成用于公式中的位置索引本身（pos）\n",
    "\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d2ed39-5946-44b7-82b2-8d44f8095c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.],\n",
       "        [11.],\n",
       "        [12.],\n",
       "        [13.],\n",
       "        [14.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a229677-831c-4d76-9314-7af97870027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创造公式中的分母"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfb0b3-25f2-4340-aa27-a310cfd5b2b1",
   "metadata": {},
   "source": [
    "$$10000^{\\frac{2i}{d_{\\text{model}}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208fb6a6-51f3-4281-a3b2-03ea7a25c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0fbc50-eb8f-4780-ab7d-514aeec781f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float() #这就是2i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1799a-8830-4c98-8672-0ced53316be7",
   "metadata": {},
   "source": [
    "让我们来看一下该段代码实现的具体公式：\n",
    "\n",
    "$$\n",
    "\\exp\\left(\\left[0, 2, 4, \\ldots, d_{\\text{model}} - 2\\right] \\times \\left(-\\frac{\\log(10000.0)}{d_{\\text{model}}}\\right)\\right)\n",
    "$$\n",
    "\n",
    "解释：\n",
    "- $[0, 2, 4, \\ldots, d_{\\text{model}} - 2]$ 表示从 0 到 `d_model` 以步长为 2 的整数序列，也就是2i\n",
    "- $\\log(10000.0)$ 是对 10000.0 取自然对数。\n",
    "- $d_{\\text{model}}$ 是嵌入向量的维度。\n",
    "- $\\exp$ 表示指数函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d65da-f776-4d1b-89f8-7338787b40f5",
   "metadata": {},
   "source": [
    "设 $ x = -\\frac{\\log(10000.0)}{d_{\\text{model}}} $，则有——"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95a6ca-9c73-4b97-ad8b-e557695732d0",
   "metadata": {},
   "source": [
    "则：\n",
    "$$ \\exp\\left(\\left[0, 2, 4, \\ldots, d_{\\text{model}} - 2\\right] \\times \\left(-\\frac{\\log(10000.0)}{d_{\\text{model}}}\\right)\\right) = e^{\\left( [0, 2, 4, \\ldots, d_{\\text{model}} - 2] \\cdot x \\right)} $$\n",
    "\n",
    "可以展开为：\n",
    "$$ e^{0 \\cdot x}, e^{2x}, e^{4x}, \\ldots, e^{(d_{\\text{model}} - 2) \\cdot x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7caef80-0aa2-4695-a3e8-6bb68de51667",
   "metadata": {},
   "source": [
    "以其中的$e^{2x}$为例——\n",
    "\n",
    "$$\n",
    "e^{-\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}}\n",
    "$$\n",
    "\n",
    "其中对数函数 $\\log$ 是以自然数 $e$ 为底，我们可以化简这个式子。根据指数的性质，$e^{-x} = \\frac{1}{e^x}$，我们可以写成：\n",
    "\n",
    "$$\n",
    "e^{-\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}} = \\frac{1}{e^{\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}}}\n",
    "$$\n",
    "\n",
    "接下来，我们知道$e^{a*log(x)} = (e^{log(x)})^a$，因此：\n",
    "\n",
    "$$\n",
    "e^{\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}} = (e^{\\log(10000.0)})^{(\\frac{2}{d_{\\text{model}}})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c2a0b-cf8a-4839-9af5-c1a46d047b85",
   "metadata": {},
   "source": [
    "又因为$e^{\\log(x)} = x$，因此：\n",
    "\n",
    "$$\n",
    "e^{\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}} = 10000^{\\frac{2}{d_{\\text{model}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b606c-4c5d-4bf7-8ccf-f5a52a765c40",
   "metadata": {},
   "source": [
    "所以，最终的化简结果是：\n",
    "\n",
    "$$\n",
    "e^{ -\\frac{2 \\cdot \\log(10000.0)}{d_{\\text{model}}}} = \\frac{1}{10000^{\\frac{2}{d_{\\text{model}}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d9ee7-c6e7-4df6-9767-c218e49ccaab",
   "metadata": {},
   "source": [
    "因此——\n",
    "\n",
    "$$\n",
    "\\exp\\left(\\left[0, 2, 4, \\ldots, d_{\\text{model}} - 2\\right] \\times \\left(-\\frac{\\log(10000.0)}{d_{\\text{model}}}\\right)\\right)\n",
    "= \\frac{1}{10000^{\\frac{\\left[0, 2, 4, \\ldots, d_{\\text{model}} - 2\\right]}{d_{\\text{model}}}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06aedc-5a06-44ec-a45d-a697b0385151",
   "metadata": {},
   "source": [
    "这个公式与正弦余弦位置编码的公式一致：$$PE_{(pos, 2i)} = \\sin \\left( \\frac{pos}{10000^{\\frac{2i}{d_{\\text{model}}}}} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c63a6-4a3f-4983-90d0-8bf5445e6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算出分母后，计算出正弦余弦值，并赋值给原本设置好的位置编码矩阵\n",
    "# 计算正弦位置编码: PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "# 所有行上、从0开始、每2列赋予一个sin值\n",
    "pe[:, 0::2] = torch.sin(position * div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0fa0915-2575-4bf6-ab0c-0148db878b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6cc6ad8-79e9-41fb-aab5-209f424f29ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_[0::2] #从0开始索引到最后一位数，但是步长为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321ae24d-2c8d-4af8-93ef-9548ad235c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_[1::2] #这是取出序列中奇数和偶数的常见方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d21f1d4-1875-4c63-a7e4-1dbc8befbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003990888595581055\n"
     ]
    }
   ],
   "source": [
    "# 示例：定义并测试 PositionalEncoding 类\n",
    "\n",
    "import time\n",
    "\n",
    "d_model = 512\n",
    "dropout = 0.1\n",
    "max_len = 5000\n",
    "\n",
    "# 创建一个示例输入张量，形状为 (batch_size, seq_len, d_model)\n",
    "batch_size = 32\n",
    "seq_len = 10\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# 实例化 PositionalEncoding 类\n",
    "# 5000个位置编码是在此刻就计算完成的\n",
    "start = time.time()\n",
    "pos_encoder = PositionalEncoding(d_model, dropout, max_len)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3795f6b0-7183-421b-8f60-48a820ae7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009982585906982422\n"
     ]
    }
   ],
   "source": [
    "# 前向传播，添加位置编码\n",
    "start = time.time()\n",
    "output = pos_encoder(x)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c332b-e80c-44fd-bcb6-9a3cc4ee2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#看到消耗的时间差异了吗？这是我们设置max_len，而不直接设置seq_len的关键原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93644a2c-9110-4e46-9365-c4cd237e92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)  # 输出的形状应为 (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b72b3-c0d8-4622-8b84-639833e312a4",
   "metadata": {},
   "source": [
    "上面是针对每一个位置添加的512维的位置编码。**Embedding后的编码结构与位置编码需要是完全一致的结构**，这样便可以对应位置元素相加，构成Transformer所需要的完整的编码。有了完整的编码后，我们可以开始定义我们的Encoder了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb784f-6787-469c-9a3b-845c34c177b4",
   "metadata": {},
   "source": [
    "#### 3.2.1.3 从0实现编码器Only架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "559d3838-8b72-44fc-81d3-d0b28b325b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化 Transformer 编码器模型\n",
    "        \n",
    "        参数:\n",
    "        input_dim (int): 输入的词汇表大小。\n",
    "        d_model (int): 嵌入向量的维度。\n",
    "        nhead (int): 多头注意力机制中的头数。\n",
    "        num_encoder_layers (int): 编码器层的数量。\n",
    "        dim_feedforward (int): 前馈网络的隐藏层维度。\n",
    "        dropout (float): Dropout 概率。\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "        \n",
    "        # 嵌入层，将输入的词汇索引转换为嵌入向量\n",
    "        self.embedding = nn.Embedding(input_dim, d_model)\n",
    "        \n",
    "        # 位置编码层，添加位置信息以保留序列顺序\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # 定义单个 Transformer 编码器层\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, \n",
    "                                                    dim_feedforward, dropout,\n",
    "                                                    batch_first=True)\n",
    "        \n",
    "        # 堆叠多个 Transformer 编码器层\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers\n",
    "                                                         , num_layers=num_encoder_layers)\n",
    "        \n",
    "        # 保存 d_model 维度，可能会用于后续计算\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 输出层，将 Transformer 编码器的输出转换为目标任务的输出\n",
    "        # 用于回归任务\n",
    "        self.fc_out = nn.Linear(d_model, 1) \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 用于二分类任务\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(d_model, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 用于多分类任务\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(d_model, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        前向传播函数\n",
    "        \n",
    "        参数:\n",
    "        src (Tensor): 进行embedding之前的张量，形状为 (batch_size, seq_len)\n",
    "        src_mask: 前瞻掩码，输入结构为(seq_len, seq_len)\n",
    "        src_key_padding_mask: 填充掩码，输入结构为(batch_size,seq_len)。\n",
    "        \n",
    "        返回值:\n",
    "        Tensor: 模型的输出，形状为 (batch_size, 1)\n",
    "        \"\"\"\n",
    "        # 将输入词汇索引转换为嵌入向量，并进行缩放\n",
    "        # Scaled Embedding = Embedding × sqrt(d_model)\n",
    "        # 这里为什么要进行缩放？\n",
    "        src = self.embedding(src) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        \n",
    "        # 添加位置编码\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        # 通过 Transformer 编码器层进行编码\n",
    "        output = self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # 对编码器的输出进行平均池化，获得序列的固定长度表示\n",
    "        # 这一步同样也是对Transformer输出数据结构的整合\n",
    "        # 如果Encoder的结果是直接输出给Decoder使用，很可能不需要这一步骤\n",
    "        output = output.mean(dim=1)\n",
    "        \n",
    "        # 通过全连接层将固定长度表示转换为目标任务的输出\n",
    "        output = self.fc_out(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b6b19-54c5-4852-bf84-a94bd6034440",
   "metadata": {},
   "source": [
    "在Transformer 模型中，对输入的嵌入向量进行缩放是一个常见的技巧，最早是在原始的 Transformer 论文《Attention Is All You Need》中提出的。我们来详细解释一下这种缩放的意义以及为什么要乘以 `torch.sqrt(torch.tensor(d_model))`。\n",
    "\n",
    "> 缩放的意义\n",
    "> 1. **防止数值过小**：在进行多头注意力机制时，输入的嵌入向量会与注意力权重矩阵相乘，如果嵌入向量的值过小，可能会导致梯度消失问题。通过缩放嵌入向量的值，可以减缓这种问题。<br><br>\n",
    "> 2. **稳定训练过程**：缩放嵌入向量可以使注意力机制的计算更加稳定，从而有助于模型的训练。在论文中提到，通过缩放嵌入向量，可以使模型在训练初期更快地收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3078300b-a742-4f4f-b47c-d71d3377dbe6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.6274)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model=512\n",
    "torch.sqrt(torch.tensor(d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "45fdda4a-1929-44dc-8010-1c97e44ccc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：为Encoder-Only结构输入数据、跑通架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2be6837b-fe1f-4c66-b858-e858718c5a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 219])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape #之前在embedding的例子中使用的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5803390d-6ff0-4e7f-bfa1-a4410fb501e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   1,   5,   6,   7,   2,   3,   4,   6,   8,   8,\n",
       "           9,   4,  10,  11,  12,  13,  14,  15,  16,   5,  17,  18,  19,  20,\n",
       "          21,   5,  22,   5,  23,   5,  24,  25,  26,  27,  28,  29,   4,  30,\n",
       "           5,  31,  32,  33,  34,   5,  17,  18,  35,  36,  37,   5,  38,   5,\n",
       "          39,  40,  41,  42,  43,   4,  44,   5,  35,  45,  46,  47,  48,  49,\n",
       "          50,  30,  51,  52,  53,   5,  17,  18,  54,  55,   5,  40,  56,   4,\n",
       "          57,   5,  58,  59,  60,   7,  61,   5,  59,  62,  63,  64,   2,  65,\n",
       "          66,   5,  17,  18,  67,  68,  69,  70,   5,  71,   2,  72,  73,   5,\n",
       "          74,   4,  75,  76,  77,   5,  45,  78,  79,  80,  59,  81,  82,   3,\n",
       "          83,   5,  17,  18,  84,   9,  85,  86,  87,  88,  89,   5,  90,  91,\n",
       "          92,   5,  93,  94,   5,  93,  95,   5,  93,  96,  97,   5,  17,  18,\n",
       "          59,  98,  81,  99, 100,  85, 101,   7, 102,   5, 103,  88, 104, 105,\n",
       "           4, 106, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [109,  80, 110, 111, 112, 113, 114,   5, 115, 116, 117, 118, 107, 119,\n",
       "         120,  59, 121, 122, 111,   5, 110, 123,   2, 124,   4,   5,  17,  18,\n",
       "          59, 125,   4,   2, 126, 127,   4, 106,   5, 111, 128, 114, 124, 129,\n",
       "           5,  59,  48, 127, 130, 131, 106, 114,   5,  17,  18, 132, 133, 134,\n",
       "           4, 109, 135, 136, 109, 107, 119, 137,  39, 138, 139, 140,   5, 141,\n",
       "         142,   5, 143, 144,   5,  17,  18, 145,   5, 146, 147,   5, 148, 149,\n",
       "         150, 151, 152,   5,   2, 153, 154, 155,   5, 156,  59,   4, 157,  80,\n",
       "          17,  18,  48, 158, 159, 160, 119, 161, 162, 163,  39,  86, 164,   4,\n",
       "           5,  59, 165,   4, 166, 124,   4, 106,   5, 111, 150, 167, 168, 110,\n",
       "         169,  17,  18, 170,   4, 171, 107, 172, 173, 174, 175,   5, 176, 177,\n",
       "           5,  35, 178, 114, 126,   4, 169, 179,   5, 180,  88, 181, 182,  17,\n",
       "          18, 183, 184, 185, 186,   5, 187, 188,   5, 119, 189, 190,   5, 191,\n",
       "         130, 192,   5, 130, 193,   5, 130, 194,   5, 195,   5,  17,  18, 196,\n",
       "         197,   6,   4,  86, 198, 199,   5, 111,  84, 111, 126,   5, 200, 201,\n",
       "         202, 119, 203,   4,   2,   5, 204,  59, 130,   4,   5,  17,  18, 205,\n",
       "         206, 130,   5, 111, 207, 130, 111, 126, 107]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a8b51503-b4d0-4128-84d1-1616eb531b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2000  # 词汇表大小\n",
    "batch_size = 1\n",
    "seq_len = 219\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "model = TransformerEncoderModel(input_dim, d_model, nhead\n",
    "                                , num_encoder_layers\n",
    "                                , dim_feedforward, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32e168b7-7ae3-4c83-a0cf-651eb927cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟掩码 - Encoder-Only结构，无需前瞻掩码，只需填充掩码\n",
    "# 当你的模型输入是(batch_size, seq_len, embedding_dim)时，你的填充掩码函数：\n",
    "def create_padding_mask_1(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len, embedding_dim)\n",
    "    # 检查填充值位置\n",
    "    padding_mask = (seq == pad_token).all(dim=-1)  # (batch_size, seq_len)\n",
    "    padding_mask = padding_mask.float() * -1e9\n",
    "    return padding_mask\n",
    "\n",
    "#当你的模型输入是(batch_size, seq_len)时，你的填充掩码函数：\n",
    "def create_padding_mask_2(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len)\n",
    "    # 创建一个与输入序列形状相同的掩码\n",
    "    padding_mask = (seq == pad_token).float() * -1e9  # (batch_size, seq_len)\n",
    "    return padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e4a8cfdb-25bb-4470-99d8-612673c9d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mask = create_padding_mask_2(sequences,pad_token=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f9a3d4df-8dc5-4dfc-b0ee-b209a0ff1735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 219])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask.shape #batch_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "74462172-9caf-4dd3-925a-9e64752d93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 前向传播\n",
    "output = model(sequences,src_key_padding_mask = padding_mask)\n",
    "print(output.shape)  # 输出的形状应为 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0644c1-eb41-4357-a5c3-008f91240720",
   "metadata": {},
   "source": [
    "### 3.2.2【实战】Transformer案例之情感分类案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca097f2e-04b7-4e4f-8225-46e08cea14a5",
   "metadata": {},
   "source": [
    "极性情感分类是一种利用计算机程序通过分析文本内容来判定其情感倾向（如正面、负面或中性）的技术，它是自然语言处理领域中的一项基本任务，也是因其广泛的应用场景而备受关注的领域。这个任务涉及到从文本数据中提取情感信号，并将这些信号准确地映射到预定义的情感类别中，同时尽可能地捕捉文本中的情感细节和语境变化，而这些文本数据可能来自网站评论区、社交媒体平台或专门为情感分析任务收集的语料库。数据集中的每个样本都已经被人工标注好情感极性，这为训练监督学习模型提供了基础。总而言之，情感分类是自然语言处理领域中的一个重要而典型的研究方向，广泛应用于客户服务、社交媒体分析和市场研究等领域。\n",
    "\n",
    "在使用深度学习技术进行情感分类的各种实践中，Transformer被认为是非常有效的模型。通过训练大量的文本数据，Transformer能够学习复杂的情感表达模式，它能够理解和分类各种复杂的情绪表达，适应不同的语言风格，并处理含糊或隐晦的情感表达。对于Transformer模型来说，情感分类是一个典型的分类任务。这意味着模型需要接收一系列的输入（如文本数据），并输出一个分类结果（情感类别）。Transformer中的自注意力机制允许模型在分类时能够关注到输入文本中的所有词语，帮助模型理解更复杂的情感表达和语境依赖，使得分类结果更加准确和具有深度；同时，在情感分类任务中，Transformer中的编码器用于理解输入的文本，而输出层则直接基于编码后的表示来判定情感类别，因此情感分类是一个只使用编码器、而不是用解码器的架构。在Tansformer用于情感分类任务时，每一层都进一步提炼和传递信息，增强了模型在处理复杂文本时的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdbcae1-87b8-4262-85fb-0192316f6f54",
   "metadata": {},
   "source": [
    "在今天的项目中，我们将完成一个英文文本的情感分类任务。通常来说，一个情感分类任务需要覆盖至少如下的流程：\n",
    "\n",
    "- **数据准备**：数据导入、数据认知、分词、词汇表/词典构建、词汇表/词典质量提升、未知词处理、文本编码、编码转嵌入、加入位置编码、数据规范化、设置掩码\n",
    "\n",
    "- **模型构建与训练准备**：位置编码、Encoder-Only架构定义、数据分割（训练测试分割）、数据分批（依据Dataloader分batch）、批次结构规范化（collate_fn）、优化器、损失函数设置\n",
    "\n",
    "- **训练与测试**：训练循环、训练监控与可视化、测试循环\n",
    "\n",
    "不难发现，每个环节的工作其实都相对繁重，尤其是数据准备部分。今天我们就将使用代码来完成上述所有的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad5c83-f8f4-4a4a-940d-926a27b13621",
   "metadata": {},
   "source": [
    "#### 3.2.2.1 情感分类任务的数据准备与数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2c58b-9acc-45da-b264-cff186698e8c",
   "metadata": {},
   "source": [
    "对于任何NLP任务来说，我们都需要对数据进行详细的处理、毕竟算法本身无法处理文字数据，而语言数据同时带有时序属性和文字属性，具有复杂的处理流程，其中中文又比英文更加复杂。本次我们准备的是基于英文文本的情感分类任务，我们使用了自然语言库NLTK中的sentence_polarity数据集。NLTK（Natural Language Toolkit）是一个强大的Python库，专门用于处理人类语言数据，广泛应用于自然语言处理（NLP）研究和教育，而本次我们所使用的sentence_polarity数据则是一个经典的英文情感分类数据集。在深度学习的世界中，还有大量以中文为主的情感分类数据集 ↓\n",
    "\n",
    "> **中文情感分析综合数据集** (Chinese Sentiment Analysis Dataset, ChnSentiCorp)：这是一个广泛使用的中文情感分类数据集，包含酒店、书籍和电子产品的评论，这些评论被标注为正面或负面。\n",
    "\n",
    "> **豆瓣电影评论数据集**：你可以在github找到这个数据集，这个数据集包含大量来自豆瓣网站的电影评论，这些评论被用户标记为推荐（正面）或不推荐（负面）。\n",
    "\n",
    "> **微博情感分析数据集**：你依然可以从github找到这个数据集，这是从新浪微博收集的数据，包括带有情感倾向的微博文本，常用于研究社交媒体上的情感表达。\n",
    "\n",
    "当然，也还有很多其他语言的情感分类数据集——\n",
    "\n",
    "> **IMDb电影评论数据集 (IMDb Movie Review Dataset)**：包含来自IMDb网站的50,000条电影评论，分为正面和负面两类，是进行情感分析的一个标准数据集。\n",
    "\n",
    "> **亚马逊商品评论数据集 (Amazon Product Review Dataset)**：包含数百万用户对亚马逊商品的评论，这些评论被标记有星级，通常用星级来推断评论的情感倾向。\n",
    "\n",
    "> **斯坦福情感树库 (Stanford Sentiment Treebank, SST)**：包含电影评论的数据集，特点是每个句子都被分析成语法树，每个节点（句子、短语、单词）都被标注情感，非常适合深入研究语义上的情感分析。\n",
    "\n",
    "> **Twitter情感分析数据集**：包含从Twitter抓取的推文，这些推文被标注为正面、负面或中性，用于研究社交媒体文本的情感倾向。\n",
    "\n",
    "不难发现，情感分类的数据集基本都来自于对于公开评论、网络评论的收集。随着NLP技术的发展，现在已经较少有仅仅针对情感分析进行学术研究的项目了，情感分类被认为是“自然语言理解”的一个子板块。在NLP的领域，我们会要求模型对语言的理解能力更强。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064318f7-c4cf-4a42-8802-b17c0b6e2f04",
   "metadata": {},
   "source": [
    "- **认知nltk数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8f2126-e57f-43b4-99f9-30e6e2afa8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 用于构建掩码的库\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "# 用于构建词典的库\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2c08c-b600-4aa7-9907-df38ca132269",
   "metadata": {},
   "source": [
    "- 导入nltk中的数据sentence_polarity来使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cbb50a-91e5-48e4-a7a1-389b2e25920f",
   "metadata": {},
   "source": [
    "首先要确保你的系统重装有nltk库，如果没有的话你可以使用如下的代码来简单进行安装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6555ab7-eb6e-4634-ab7d-4023397c4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3113a53-0a13-4fd1-abd1-b57ea911b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading sentence_polarity: <urlopen error [Errno\n",
      "[nltk_data]     11004] getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "#我们可以将nltk中所带的数据下载到本地来进行调用\n",
    "#这个过程需要梯子，最好挂美区ip\n",
    "nltk.download('sentence_polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd227c9-c2bd-4817-80d1-0137c8b54199",
   "metadata": {},
   "source": [
    "NLTK（Natural Language Toolkit）是一个用于处理自然语言文本的开源库，广泛用于 Python 语言的自然语言处理（NLP）任务。它提供了丰富的工具和资源，适用于各种NLP应用，如文本分析、词性标注、语法解析、情感分析等。NLTK提供了一系列自然语言处理工具和应用程序，涵盖多个关键领域，包括：通过图形界面展示语法和词频的分析工具；使用Stanford Parser和Earley算法解析自然语言结构；构建和应用统计语言模型，如N-gram；用于文本分类和聚类的机器学习算法，如朴素贝叶斯和K-means；支持多语言词法分析的工具；词形还原和词干提取工具；访问和读取广泛语料库的工具；评估解析器和分类器性能的工具；词性标注和分类工具，如隐马尔科夫模型和感知机算法；情感分析工具，如VADER；以及用于翻译和跨语言的工具，如BLEU评分系统。这些工具为用户提供了全面的自然语言处理解决方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b709dcbb-6e9c-4a74-bc24-730985c1d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentence_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26975a0a-6c68-4c6b-9fe2-2a3447324e04",
   "metadata": {},
   "source": [
    "当一个数据集被从语料库中import出来之后，我们可以使用sents()方法来调取出具体句子（虽然大部分时候是分割好的tokens），并使用.categories()方法来查看这个数据集所对应的标签类别："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c2fc87-f56c-4b1d-bc2a-2e8f514b8a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.'], ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.sents() #非常便利，是已经分好的句子、每个句子里都是已分割好的tokens，无需我们再按照空格进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6df45c-5b9d-467a-9f9c-c41ca748d9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7921aa84-e19f-434d-8caa-01704cb9dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#赋值，为后续展示句子做准备\n",
    "sentences = sentence_polarity.sents()\n",
    "label_type = sentence_polarity.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f8ae2-e1ef-4c97-b0c8-a5f5deb382e3",
   "metadata": {},
   "source": [
    "要查看每个样本所对应的标签，需要特殊的指令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1991c00-574e-4caa-9d69-863aa7745b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: simplistic , silly and tedious .\n",
      "标签: neg\n",
      "句子: it's so laddish and juvenile , only teenage boys could possibly find it funny .\n",
      "标签: neg\n",
      "句子: exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable .\n",
      "标签: neg\n",
      "句子: [garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation .\n",
      "标签: neg\n",
      "句子: a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .\n",
      "标签: neg\n",
      "句子: the story is also as unoriginal as they come , already having been recycled more times than i'd care to count .\n",
      "标签: neg\n",
      "句子: about the only thing to give the movie points for is bravado -- to take an entirely stale concept and push it through the audience's meat grinder one more time .\n",
      "标签: neg\n",
      "句子: not so much farcical as sour .\n",
      "标签: neg\n",
      "句子: unfortunately the story and the actors are served with a hack script .\n",
      "标签: neg\n",
      "句子: all the more disquieting for its relatively gore-free allusions to the serial murders , but it falls down in its attempts to humanize its subject .\n",
      "标签: neg\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentence_polarity\n",
    "\n",
    "# 加载句子和标签\n",
    "documents = [(list(sentence), category) for category in sentence_polarity.categories() \n",
    "             for sentence in sentence_polarity.sents(categories=category)]\n",
    "\n",
    "# 打印前几个句子及其标签\n",
    "for doc, label in documents[:10]:\n",
    "    print('句子:', ' '.join(doc))\n",
    "    print('标签:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8847972c-7110-4bbd-b3f6-a1b5ff1873f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.__len__() #一共有1w多个句子，每个句子里包含一串单词，是一个量级较小的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626b0893-d3ef-48bc-8c60-91f4600a9fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[garbus]',\n",
       " 'discards',\n",
       " 'the',\n",
       " 'potential',\n",
       " 'for',\n",
       " 'pathological',\n",
       " 'study',\n",
       " ',',\n",
       " 'exhuming',\n",
       " 'instead',\n",
       " ',',\n",
       " 'the',\n",
       " 'skewed',\n",
       " 'melodrama',\n",
       " 'of',\n",
       " 'the',\n",
       " 'circumstantial',\n",
       " 'situation',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[3] #可以通过索引的方式取出单一的句子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e1f7b-025f-44c2-8db3-8c3e8fdce5be",
   "metadata": {},
   "source": [
    "针对这样的数据，我们需要构建训练数据、测试数据集，并且将文本标签转化为数字；然而在进行所有的这些操作之前，我们需要构建该数据对应的词典和词汇表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b524952-b48c-4890-ab47-6b8b36a34c05",
   "metadata": {},
   "source": [
    "- **从一段文字到编码的常规流程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b904d74-1567-459e-aa2a-75bde69c53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见视频《【Transformer】19 EncoderOnly架构的输入与Embedding层的实现》\n",
    "# 从一段话变为能够输入到embedding层的信息，还需经过以下的步骤：\n",
    "# 1)分词 2)制作词汇表 3)依据词汇表编码 4)填充编码后序列，形成统一的seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6923d-b41d-4694-88c2-8c4a6b6c8b60",
   "metadata": {},
   "source": [
    "- **词典构造的过程中有哪些关键注意事项可能需要考虑？**\n",
    "\n",
    "第一个需要考虑的问题是**陌生词**，也叫未知词。在进行深度学习算法预测的时候，只有在词汇表中的词才能够被进行编码，但是在预测中、可能会出现很多不常用的词、拼写错误的词、甚至可能因为训练数据集比较小、所以在测试数据中出现陌生的词。当出现这种情况时，编码就可能会发生错误，而且如果每次都给不常用词、或者拼写错误的词分配唯一的索引、可能会导致词汇表非常大且稀疏。因此在我们构建词汇表的时候，我们要使用字符串\"\\<unk>\"（unknown）来代表模型在训练过程中从未遇到过的词，以减少词汇表的大小，提高模型的泛化能力。有了\"\\<unk>\"的存在，模型就能够处理在训练中未遇到过的词。<br>\n",
    "\n",
    "第二个需要考虑的问题是**词汇表/词典的质量**。原则上来说，词汇表中应该包括语料中出现过的所有词，但这其实是一个低效并且甚至可能损害算法的语言理解能力的状态，因为一个NLP项目涉及到的语料越多时、语料中的垃圾信息就可能越多。例如，拼写错误的可能性会增加、不常见的词的词可能会变得更多、特殊符号甚至广告等信息混入的可能性就变得更大，事实上在大部分的语料中，只有少量高频且有价值的词汇是值得NLP算法进行学习的。因此在针对大型NLP数据构建词汇表和词典时，我们要重视词汇表的质量，需要对词汇表进行压缩和筛选。因此我们有着以下的筛选方法——\n",
    "> 1. 停用词过滤<br>\n",
    "> 停用词（stop words）是一些在文本中频繁出现但对语义贡献较少的词，如“the”、“is”、“in”等。过滤掉这些停用词可以减少词汇表的大小，同时不影响文本的语义理解。<br><br>\n",
    "> 2. 词性过滤<br>\n",
    "> 根据具体任务的需求，只保留特定词性的词汇。例如，对于情感分析任务，形容词和副词可能更重要，而名词和动词则在信息检索任务中更为关键。<br><br>\n",
    "> 3. 词长度过滤<br>\n",
    "> 过滤掉过短或过长的词汇。例如，长度为1或2的词汇可能是噪音，而过长的词汇可能是拼写错误。<br><br>\n",
    "> 4. 字符类型过滤<br>\n",
    "> 根据字符类型进行过滤。例如，只保留字母或数字，过滤掉包含特殊字符的词汇。这可以有效去除文本中的特殊符号和广告信息。<br><br>\n",
    "> 5. 词汇标准化<br>\n",
    "> 使用词干提取（stemming）或词形还原（lemmatization）将不同形式的同一词汇标准化为一个基本形式。例如，将“running”和“ran”都转换为“run”，从而减少词汇表的大小。<br><br>\n",
    "> 6. 频率截断<br>\n",
    "> 除了简单的词频筛选，还可以设置上限和下限频率阈值。即保留在一定频率范围内的词汇，过高频率的词汇也可以视为停用词进行过滤。<br><br>\n",
    "> 7. 领域相关性筛选<br>\n",
    "对于特定领域的NLP任务，可以根据领域词典或知识库进行筛选，只保留与领域相关的词汇。例如，医学文本处理时，只保留医学术语。<br><br>\n",
    "> 8. 基于统计和信息论的方法<br>\n",
    "> 使用更复杂的统计方法，如互信息（Mutual Information）、卡方检验（Chi-Square Test）、点互信息（Pointwise Mutual Information, PMI）等，评估词汇的重要性和关联性，进行筛选。<br><br>\n",
    "> 9. 基于预训练模型的词汇筛选<br>\n",
    "> 使用预训练语言模型的词嵌入，计算词汇的语义相似性，将相似性较高的词汇进行合并或筛选，保留重要的词汇。<br><br>\n",
    ">这些方法可以单独使用，也可以组合使用，以构建一个高质量、精简且适用于具体任务的词汇表。选择合适的筛选方法取决于具体的应用场景和任务需求。<br><br>\n",
    "\n",
    "**在本次案例中，我们所使用的方法是词频筛选**。词汇频率筛选在自然语言处理任务中具有重要意义，因为它能够有效地减少噪音，提高模型的训练效率和性能。通过统计每个词汇在文本中的出现频率，我们可以筛选出那些高频且有价值的词汇，避免将稀有词汇引入词汇表。低频词汇往往是拼写错误、特殊符号或不常见的词，这些词汇不仅增加了模型的复杂性，还可能对模型的学习过程产生干扰。通过过滤掉这些低频词汇，我们不仅能够简化词汇表，减少计算资源的消耗，还能使模型更专注于学习有用的词汇和模式，从而提升整体的表现。此外，较小的词汇表意味着更少的参数需要处理，训练速度也因此得到显著提升。因此，词汇频率筛选在构建高质量词汇表时至关重要，是提高模型效率和性能的关键步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803f972-4f80-40a3-9023-94b67233981c",
   "metadata": {},
   "source": [
    "- **Vocab：递归的编码函数的编写**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8096d-b3c2-4394-97ee-10b1ec8e5f30",
   "metadata": {},
   "source": [
    "在本次案例中，我们定义Vocab类来帮助我们完成词汇表构建→编码的全流程。本次我们使用的来自nltk的数据呈现为已经分好词的Token样式，但我们实际却可能应用到原始的文字数据，因此在构建Vocab这个类的时候，**我们考虑赋予这个类能够处理Token、同时也能够处理文字的能力**——\n",
    "> 如果数据是原始文字数据，我们则需要：分词、词频筛选、添加未知词、词汇表构建、根据词汇表进行编码<br><br>\n",
    "> 如果数据是已经分好词的Token，我们则需要：添加未知词、构建词汇表、根据词汇表进行编码\n",
    "\n",
    "不难发现，这两种输入数据类型在处理时，有一半以上的流程是重复的。基于这样的理解和思路，**我们在Vocab类中构建了两大核心模块**，一个是所有类都必须定义的init，另一个是build方法，其中init中的流程用于接受原本就是Token格式的数据，包含添加未知词、词汇表构建两大流程，而build方法用于接受text数据，包含分词、词频筛选两大流程；同时，将词汇表进行编码的流程我们单独编写为类Vocab的方法（method）供我们调用。\n",
    "\n",
    "从我们刚才梳理的对数据处理的流程来看，原始文字数据经过分词和词频筛选、转变为Token后，都必须经过未知词处理、完成词汇表构建，否则在构建词典的时候就会报错。因此当build方法将text处理成Tokens后，这个Tokens应该需要再放入init中完成词汇表构建。我们要如何让一个类的方法所输出的结果再次进入这个类的init呢？**如果将Vocab构建成一个具有递归性质的类，所有的问题和流程将迎刃而解**，来看下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef54d658-44aa-43d5-9936-c8d12c80ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"\n",
    "    可以同时接纳Token和text两种类型的数据\n",
    "    对原始文字数据，调用build方法，进行分词、并完成词频筛选\n",
    "    对Token数据，使用init中的流程，完成添加未知词、词汇表构建并根据词汇表进行编码\n",
    "    建好词汇表后，再调用单独的方法来进行编码\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe8dba-be5d-4146-b2dd-a5061ea03e3f",
   "metadata": {},
   "source": [
    "> - **init与build部分解读**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee876ab0-800b-4bb9-9fe2-5f04f45fd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"\n",
    "    可以同时接纳Token和text两种类型的数据\n",
    "    对原始文字数据，调用build方法，进行分词、并完成词频筛选\n",
    "    对Token数据，使用init中的流程，完成添加未知词、词汇表构建并根据词汇表进行编码\n",
    "    建好词汇表后，再调用单独的方法来进行编码\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens=None):\n",
    "        # init的输入参数是Token\n",
    "        #注意！这里的Token要求是一个【包含所有token的list】\n",
    "        #也就是这个列表里只能有token本身，不能再包含其他内容或者其他层次\n",
    "        #比如，一个list中包含了多个句子，每个句子都是按照token的方式排列的\n",
    "        #那这个list就不属于【包含所有token的list】，而是包含句子的list\n",
    "        \n",
    "        # 构建两个变量，一个idx_to_token，一个是token_to_idx\n",
    "        # idx_to_token是列表，包含了数据集中所有的单词\n",
    "        # token_to_idx是词汇表，是不重复的单词 + 索引构成的结果\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        #如果输入了tokens（Tokens不为None）\n",
    "        #就直接进行未知词操作\n",
    "\n",
    "        if tokens is not None:\n",
    "            # 如果tokens中不包含\"<unk>\"这个词（未知词），则添加\"<unk>\"\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            # 遍历tokens，将每个token添加到idx_to_token列表，并在token_to_idx字典中映射其索引\n",
    "            # 基于添加了未知词的Tokens，直接创造出列表 + 词汇表\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            # 设置未知词的索引，将未知的词设置为一个单独的属性self.unk\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    #调用魔法命令classmethod，这个命令允许我们在不进行实例化的情况下使用类中的方法\n",
    "    #build的输入参数与Vocab本身的init完全不同，因此我们可以运行它被单独调用\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        # build，此时输入的参数有4个\n",
    "        # cls是Vocab这个类本身，这魔法命令classmethod的要求\n",
    "        # 有了cls就可以在不进行实例化的情况下直接调用build功能\n",
    "        # text是需要构建词汇表和词典的文本，在这个文本上我们可以直接开始进行词频筛选\n",
    "        # 注意！这个文本的范围很广泛，只要不是单一token list，都可以被认为是文本（见下面的详细说明）\n",
    "        # min_freq是我们用于筛选的最小频率，低于该频率阈值的词会被删除\n",
    "        # reserved_token是我们可以选择性输入的\"通用词汇表\"，假设text本身太短词太少的话\n",
    "        # reserved_token可以帮助我们构建更大的词典、从而构建更大的词向量空间\n",
    "        # 以上4个参数中只有text是必填的\n",
    "        \n",
    "        # 创建一个defaultdict字典，用于统计每个单词的出现频率\n",
    "        token_freqs = defaultdict(int)\n",
    "        # 遍历文本中的每个句子，统计每个单词的出现次数\n",
    "        # 其中，单词使用变量token来代表\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                # 不断保存到字典中的是——\n",
    "                # 以token（词本身）作为键、词出现的频率作为值的键值对\n",
    "                token_freqs[token] += 1\n",
    "        \n",
    "        # 创建一个空列表uniq_tokens，用于存储\"<unk>\"和输入用来保底的reserved_tokens\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        \n",
    "        # 将token_freqs中保存的词和词频进行循环\n",
    "        # 除了\"<unk>\"之外，过滤掉出现次数少于min_freq的词\n",
    "        # 并将没有被过滤掉的词打包到一个列表中\n",
    "        # 这个列表uniq_tokens就是过滤后的Tokens列表\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        # 将过滤后的Tokens列表放入cls，也就是Vocab类中\n",
    "        # 这个Token进入到Vocab类之后，会触发init，开始进入init中的流程\n",
    "        # 因此，只要调用build方法，就可以从text构建一组token、并将这组token放入Vocab类\n",
    "        # 这是这个类的“递归”所在，我们可以调用类中的方法来创造类所需的数据类型\n",
    "        # 并在该方法的最后重启这个类\n",
    "        return cls(uniq_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925ac33-dd68-479b-a33f-1a53930df069",
   "metadata": {},
   "source": [
    "根据上面的代码，相信你已经发现Vocab这个类的神奇之处了。当我们的输入数据为Token时，我们可以直接调用Vocab类来同时生成词汇表和词典，当我们输入的数据是text时，我们可以调用build方法，build不仅能够直接将text转变为tokens，还能把tokens放入Vocab类、来生成词汇表和词典。Vocab因此能够同时包容text和tokens两种不同结构的数据，因此在使用这个类时，我们的具体调用方法是 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1a5c1f-7230-4dcd-9a91-b646f7e9a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#示例代码，不可运行\n",
    "\n",
    "#当输入数据为Token时，调用流程（该流程的本质是实例化）：\n",
    "\n",
    "#vocab = Vocab(tokens)\n",
    "\n",
    "#当输入数据为text时，调用流程（该流程的本质是通过@classmethod方法跳过实例化过程\n",
    "#直接调用类中的方法，不过build方法最终return的还是Vocab类，因此其本质相当于先处理text为token，再实例化）：\n",
    "\n",
    "#vocab = Vocab.build(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cf497-485d-4308-8440-f255df5e0a58",
   "metadata": {},
   "source": [
    "这两种方法下生成的vocab都是类，不过这个类中此时已经包括了生成好的 词汇表idx_to_token和词典token_to_idx。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1129667-f488-47a9-9d1a-776603439359",
   "metadata": {},
   "source": [
    "> - **build方法解读**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8fe5c5-622c-4548-b58a-cc885aa8987f",
   "metadata": {},
   "source": [
    "我们有提到init只能接受【单一token list】，这是指——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f22f5b-0cb6-44c1-bdd9-a6dfb353bc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.'], ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.sents()\n",
    "#我们此时使用的数据，虽然看起来是token但实际上是包含了多个tokens的列表\n",
    "#因此无法被Vocab的init直接处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e09b37-065b-4775-a934-167c63a72679",
   "metadata": {},
   "source": [
    "但是init可以处理——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "135ef148-7c8c-4ebd-85bf-189f663bfa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simplistic', ',', 'silly', 'and', 'tedious', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.sents()[0] #这就是单一token list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035e097-1c5c-43d7-ba34-8bb32fd8254c",
   "metadata": {},
   "source": [
    "而build可以接受的任意文本数据是——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b4c6bb-a128-4922-9e6c-7fe312cbf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [\"我爱中国\",\"我的大好河山\"]\n",
    "text2 = \"我爱中国\"\n",
    "text3 = [\"我\",\"爱\",\"中\",\"国\",\"我\",\"的\",\"大\",\"好\",\"河\",\"山\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3d0a10-98e1-4a55-9d16-c3857b68ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "爱\n",
      "中\n",
      "国\n",
      "我\n",
      "的\n",
      "大\n",
      "好\n",
      "河\n",
      "山\n"
     ]
    }
   ],
   "source": [
    "for sentence in text1:\n",
    "    #print(sentence)\n",
    "    for token in sentence:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4614216-f0ca-449d-a4ff-31c7c94a153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "爱\n",
      "中\n",
      "国\n"
     ]
    }
   ],
   "source": [
    "for sentence in text2:\n",
    "    for token in sentence:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d59eb3-313b-4c0f-aa1f-f9fbcf2e8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "爱\n",
      "中\n",
      "国\n",
      "我\n",
      "的\n",
      "大\n",
      "好\n",
      "河\n",
      "山\n"
     ]
    }
   ],
   "source": [
    "for sentence in text3:\n",
    "    #print(sentence)\n",
    "    for token in sentence:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5b9ce-9318-42d0-b1f0-37957c6c1dbe",
   "metadata": {},
   "source": [
    "词频筛选代码解读——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9acf67f2-d398-412c-ab29-aee0f8f3235e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d9070-883a-4351-a0e3-78d09c143dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在已有的词频字典中进行循环\n",
    "for token, freq in token_freqs.items():\n",
    "    #如果该词的出现频率大于我们规定的筛选频率\n",
    "    #并且这个token不是\"<unk>\"的话\n",
    "    #就把这个token加入到uniq_tokens中\n",
    "    #形成不重复的词列表\n",
    "    if freq >= min_freq and token != \"<unk>\":\n",
    "        uniq_tokens += token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbccf6-9ac9-4653-9bd1-5750a459c40f",
   "metadata": {},
   "source": [
    "> - **剩余部分解读 + Vocab类的使用与循环**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f44982-fff2-447a-bde6-3e6cf2396295",
   "metadata": {},
   "source": [
    "接下来，我们只需要写一系列的方法来调用我们的词汇表和词典、并根据词典将特定文字转化成编码后的结果就可以了。完整的Vocab类代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99953818-3a4e-42b5-a2a4-ecac3f29b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    #在已经生成词汇表和词典的基础上\n",
    "    #我们可以对词汇表和词典进行各项操作 ↓\n",
    "    def __len__(self):\n",
    "        # 返回词汇表的大小\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        # 获取token对应的索引，如果不存在则返回未知词的索引\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        # 将token列表转换为索引列表（也就是将文字进行编码）\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        # 将索引列表转换为token列表（也就是根据编码、找到相应的token）\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e2c68-faeb-43ee-8a5f-30da53f0ac4b",
   "metadata": {},
   "source": [
    "在这段代码中，你还可以增加许多其他的操作，例如直接让vocab类为我们返回idx_to_token和token_to_idx这两个结果，便于你查看词汇表和词典，也可以针对词汇表和词典进行更加丰富的操作。在这里，最关键的功能就是将token转换成索引、即将文字进行编码的过程。接下来我们可以来测试一下该段代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46671027-e5d6-4290-bc5a-a0799769adc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.'], ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.sents()\n",
    "#我们此时使用的数据，虽然看起来是token但实际上是包含了多个tokens的列表\n",
    "#因此无法被Vocab的init直接处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80d16612-1ac2-428e-b48d-725fa2033765",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2176/1719023963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_polarity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#会发现，因为列表中还包含列表，所以无法处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2176/2679930856.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx_to_token\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_to_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx_to_token\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_to_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<unk>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(sentence_polarity.sents()) #会发现，因为列表中还包含列表，所以无法处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d250392c-002e-4933-be76-b541a8ae3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.build(sentence_polarity.sents()) #但是build却可以把这个列表当做text来处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dc5e06d-463d-42fe-b8c3-ae64f5a6b838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocab at 0x1c2736a5520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab #此时生成的vocab是一个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a32c6b81-b983-48bd-aa9b-5f7494f15b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentence_polarity.sents(categories='pos')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "693302e7-0be9-4c75-9aa7-b5977d8a510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23,\n",
       " 2444,\n",
       " 61,\n",
       " 9851,\n",
       " 76,\n",
       " 308,\n",
       " 23,\n",
       " 1664,\n",
       " 14509,\n",
       " 496,\n",
       " 219,\n",
       " 14510,\n",
       " 219,\n",
       " 4,\n",
       " 27,\n",
       " 175,\n",
       " 363,\n",
       " 76,\n",
       " 29,\n",
       " 32,\n",
       " 5884,\n",
       " 201,\n",
       " 7984,\n",
       " 73,\n",
       " 5354,\n",
       " 4219,\n",
       " 2,\n",
       " 14511,\n",
       " 1204,\n",
       " 2701,\n",
       " 25,\n",
       " 2184,\n",
       " 14512,\n",
       " 6]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将一个句子根据词典转变成索引\n",
    "vocab.convert_tokens_to_ids(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "285a48cf-27b3-4106-bb55-0d46d5c1b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们还可以定义其他的方法，例如——\n",
    "\n",
    "def save_vocab(vocab, path):\n",
    "    # 将词汇表保存到指定路径的文件中\n",
    "    with open(path, 'w') as writer:\n",
    "        writer.write(\"\\n\".join(vocab.idx_to_token))\n",
    "\n",
    "def read_vocab(path):\n",
    "    # 从指定路径的文件中读取词汇表\n",
    "    with open(path, 'r') as f:\n",
    "        tokens = f.read().split('\\n')\n",
    "    # 返回一个新的Vocab实例，初始化它的词汇表\n",
    "    return Vocab(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329097d-f068-4b88-a7cc-5617f3625454",
   "metadata": {},
   "source": [
    "在接下来的案例实际过程中，我们虽然不会使用到这两个函数，但这两个函数可以帮助你进一步拓展你的函数使用方法。整个vocab类的编排十分巧妙，未来你依然可以借助这个思路来编排你的词典构建函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd32486-c22b-43bf-9d6c-783a06681429",
   "metadata": {},
   "source": [
    "- **Embedding前的其他步骤**\n",
    "> **循环创建测试集与训练集**：将完整的文本数据创建测试、训练数据<br><br>\n",
    "> **加入位置编码**：在获取词向量后，模型还会加入位置编码，以引入序列中各单词的位置信息，这对于帮助模型理解词语之间的关系非常重要。<br><br>\n",
    "> **数据规范化**：对长句子进行裁剪、短句子进行填充，保证所有句子在embedding之前所包含的单词量一致<br><br>\n",
    "> **设置掩码**：对编码后的数据进行掩码。假设架构有解码器，则需要掩码未来的部分（矩阵的上三角）。假设架构只有解码器，则需要对短句子填充的部分进行掩码，以免给句子带来干扰。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f9716e-6bf8-4820-8bae-8f85571e30a9",
   "metadata": {},
   "source": [
    "现在已经有了能够根据文字本身构建词汇表、词典、并将数据根据词典进行编码的类Vocab，接下里我们将利用这个类来创建相应的训练、测试数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5acd5fa-998c-40da-a410-3a8b51662eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentence_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4011d2c-0a28-4cde-acaa-8df0d1c57c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#赋值，为后续展示句子做准备\n",
    "sentences = sentence_polarity.sents()\n",
    "label_type = sentence_polarity.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d941210e-0010-4353-a8aa-68048380069d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.__len__() #一共有1w多个句子，每个句子里包含一串单词，是一个量级较小的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58145c-a96a-4f11-8f7c-28804076f448",
   "metadata": {},
   "source": [
    "由于polarity数据中的数据量比较充足，我们将其中的前4000个句子作为训练集、4000-10662个句子作为测试集来构建数据集。在NLP的任务中，训练数据的数量比测试数据小很多是正常现象。在分割数据集的过程中，我们是直接使用列表推导式不断从positive和negative两个子集中取出相应的句子，并对每一个句子按照字典的方式进行编码。我们定义这个编码函数为load_sentences_polarity，具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19a915c8-4bca-431f-bf0e-3c57bbd28464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentence_polarity():\n",
    "    # 导入NLTK库中的sentence_polarity模块\n",
    "    from nltk.corpus import sentence_polarity\n",
    "\n",
    "    # 创建一个词汇表vocab\n",
    "    # 词汇表是在字典之前、先对句子中出现的所有不重复的词进行统计的表单\n",
    "    # 先构建词汇表vocab，再对vocab进行编码就可以构成字典\n",
    "    vocab = Vocab.build(sentence_polarity.sents())\n",
    "\n",
    "    # 构建训练数据集\n",
    "    # 将正面情感的句子标记为0，取前4000个正面句子\n",
    "    # 负面情感的句子标记为1，取前4000个负面句子\n",
    "    train_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                  for sentence in sentence_polarity.sents(categories='pos')[:4000]] \\\n",
    "    + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[:4000]]\n",
    "\n",
    "    # 构建测试数据集\n",
    "    # 使用剩余的正面情感句子，标记为0\n",
    "    # 使用剩余的负面情感句子，标记为1\n",
    "    test_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                 for sentence in sentence_polarity.sents(categories='pos')[4000:]] \\\n",
    "        + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[4000:]]\n",
    "\n",
    "    # 返回训练数据、测试数据和vocab类本身\n",
    "    return train_data, test_data, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d8b62-d1ef-4e34-8859-8ae3c58edefa",
   "metadata": {},
   "source": [
    "在处理自然语言处理（NLP）任务时，输入的数据常常是可变长度的序列。例如，一些句子可能只有几个单词，而另一些句子可能有几十个单词。在这种情况下，我们需要一种方法来标记哪些时间步是有效的，即哪些时间步对应的是输入序列中的实际单词，哪些时间步是填充（padding）字符。\n",
    "\n",
    "有效的时间步是指那些在序列中实际包含有意义信息的时间步。例如，对于一个句子 \"I love NLP\"，其有效的时间步是 \"I\", \"love\", \"NLP\"，而如果这个句子被填充到一个固定长度，比如 6 个单词的长度，填充后的句子可能是 \"I love NLP <pad> <pad> <pad>\"。在这种情况下，只有前 3 个时间步是有效的，后面的 3 个时间步是填充字符 \"<pad>\"。\n",
    "\n",
    "因此在这里，我们需要生成一个布尔掩码，用于标记每个序列中有效的时间步。这个掩码在处理可变长度序列时非常有用，例如在计算模型损失或进行序列模型的计算时，可以用掩码忽略填充字符的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dce42e4-f072-484f-b2c0-3f8d265834c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_mask(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len)\n",
    "    # 创建一个与输入序列形状相同的掩码\n",
    "    padding_mask = (seq == pad_token).float() * -1e9  # (batch_size, seq_len)\n",
    "    return padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada7dbf-01bb-4bee-971b-74fdc80d5263",
   "metadata": {},
   "source": [
    "#### 3.2.2.2 模型构建与训练流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea487c40-9c0d-4665-85ec-ff6994e80adf",
   "metadata": {},
   "source": [
    "在之前的课程中，我们详细复现过Transformer中的Encoder架构，因此你对于Transformer结构应该非常熟悉。无论是多么简单的NLP任务，transformer中的零散结构都是需要自己定义的。在情感分类任务中，我们只使用了encoder编码器，因此我们需要定义的结构有：位置编码层、embedding层、包含注意力机制的编码层、打包了多个编码层的编码器、以及对编码器中的输入数据进行掩码的掩码结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "188ff042-37a1-4a72-89e1-fbb337e84d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f19858-c513-42d6-a63b-3e4c53a4e45a",
   "metadata": {},
   "source": [
    "- **加载数据**\n",
    "\n",
    "在数据进入Pytorch之前，我们通常需要将数据进行如下的处理——\n",
    "\n",
    "1. **将数据转变为与PyTorch兼容的结构**，包括但不限于：\n",
    "> - 确保数据集拥有`__len__` 方法（返回数据集大小）和 `__getitem__` 方法（根据索引返回数据）。<br><br>\n",
    "> - 数据应该是 `torch.Tensor` 类型，因为 PyTorch 的大部分操作都是针对张量进行的。如果数据是其他格式（如 NumPy 数组、Pandas DataFrame 等），需要将其转换为 PyTorch 张量。<br><br>\n",
    "> - 数据各类预处理：在加载数据之前需要进行归一化或其他基础的预处理操作，以确保数据适合训练，可以在 `__getitem__` 方法中添加这些预处理操作。\n",
    "\n",
    "2. **经过DataLoader对数据完成分批**，包括但不限于：\n",
    "> - 完成batch分割，将数据集转变为神经网络需要的输入格式<br><br>\n",
    "> - 完成padding、裁剪、类型转换等奖数据变得更整齐的预处理操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7b6b1720-f2f1-4862-91f1-57deffdc85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train_data, test_data, vocab = load_sentence_polarity()  # 调用函数加载训练数据和测试数据，以及词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5fa91b86-3d03-47f3-93dd-334f5e96f8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([23,\n",
       "  2444,\n",
       "  61,\n",
       "  9851,\n",
       "  76,\n",
       "  308,\n",
       "  23,\n",
       "  1664,\n",
       "  14509,\n",
       "  496,\n",
       "  219,\n",
       "  14510,\n",
       "  219,\n",
       "  4,\n",
       "  27,\n",
       "  175,\n",
       "  363,\n",
       "  76,\n",
       "  29,\n",
       "  32,\n",
       "  5884,\n",
       "  201,\n",
       "  7984,\n",
       "  73,\n",
       "  5354,\n",
       "  4219,\n",
       "  2,\n",
       "  14511,\n",
       "  1204,\n",
       "  2701,\n",
       "  25,\n",
       "  2184,\n",
       "  14512,\n",
       "  6],\n",
       " 0)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n",
    "#每个样本中，包含了编码好的句子 + 当前句子的标签\n",
    "#如果不考虑标签的话，现在train_data的结构可以被概括成是(num_sentences,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1e39bd1-65ed-4bf2-ae7d-eb43cefea386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义TransformerDataset类\n",
    "# 用于为数据赋予len和getitem属性\n",
    "# 从而让数据能够适应PyTorch的数据结构\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 初始化数据集，将传入的数据保存在实例变量data中\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 根据索引i获取数据集中的第i个样本\n",
    "        return self.data[i]\n",
    "\n",
    "# 定义collate_fn函数，用于在DataLoader中对一个batch的数据进行处理\n",
    "def collate_fn(examples):\n",
    "    \n",
    "    # 将每个样本的输入部分转换为张量（转变为Tensor）\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    \n",
    "    # 将每个样本的目标部分转换为长整型张量\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    \n",
    "    # pytorch自带的padding工具\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    \n",
    "    # 返回处理后的输入、长度和目标\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b848a2-2904-4cae-ba64-eb1938ba680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate_fn函数内部的代码等同于：\n",
    "\n",
    "i = 0\n",
    "inputs_ = []\n",
    "for ex in train_data:\n",
    "    inputs_.append(torch.tensor(ex[0]))\n",
    "    i +=1\n",
    "    if i > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc50436-7130-460a-8650-b654cbf98b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([   23,  2444,    61,  9851,    76,   308,    23,  1664, 14509,   496,\n",
       "           219, 14510,   219,     4,    27,   175,   363,    76,    29,    32,\n",
       "          5884,   201,  7984,    73,  5354,  4219,     2, 14511,  1204,  2701,\n",
       "            25,  2184, 14512,     6]),\n",
       " tensor([   23,  4733,  5842, 14513,    22,   219,    23, 10446,    22,    23,\n",
       "           124,   219,  7728,    61,     8,   915,    27,    32,  4812,    22,\n",
       "          2012,  3524, 11773,  1451, 11941,  2200, 11627,  3281,  7293,    22,\n",
       "          1097,     6,  2341,     6,  2341,     6, 14514, 14515,     6]),\n",
       " tensor([ 2745,    51, 14516,  4999]),\n",
       " tensor([ 444,  449, 1888,  355,   76,  190,   76,   23,  188,   76,  136,  447,\n",
       "            2, 8665,   61,   32,  922,  466,   76,  514,    6]),\n",
       " tensor([ 2159,    63,   885,  1309,     2,    86,  2743,    81,   362,     8,\n",
       "           486,     4, 14517, 14518,    27,    17,   547,  1571,   355,    95,\n",
       "             6])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6656a6-ee42-46f5-9585-09ecf3c569cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = pad_sequence(inputs_, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131cc2ad-2b75-41a9-8ec3-75dd91de1f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 39])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(inputs_, batch_first=True).shape #结构为(batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8538b901-3c69-48df-b047-359746e36f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_to_mask(inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771eaef5-98e4-4809-ba11-d34cbe3d0cd5",
   "metadata": {},
   "source": [
    "- **数据分割**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5216d827-e3a3-4b5f-b0e5-6e51dcd2ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TransformerDataset(train_data)  # 创建训练数据集\n",
    "test_dataset = TransformerDataset(test_data)  # 创建测试数据集\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)  # 创建训练数据加载器\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)  # 创建测试数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3477f666-0bd4-4a48-9a82-389fd9981eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 2444, 61, 9851, 76, 308, 23, 1664, 14509, 496, 219, 14510, 219, 4, 27, 175, 363, 76, 29, 32, 5884, 201, 7984, 73, 5354, 4219, 2, 14511, 1204, 2701, 25, 2184, 14512, 6]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#查看一下经过train_datatset\n",
    "#此时x的结构就是(batch_size,seq_len)\n",
    "for x,y in train_dataset:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "878a58f8-45c7-426a-97ac-bef55e988bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 598,   22, 5435,  ...,    0,    0,    0],\n",
      "        [  32, 3554,    4,  ...,    0,    0,    0],\n",
      "        [4982,   32,  381,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   7,   95,   22,  ...,  242, 4227,    6],\n",
      "        [5080,  471,   76,  ...,    0,    0,    0],\n",
      "        [   7,   32,  228,  ...,    0,    0,    0]])\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1])\n",
      "torch.Size([32, 46])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data in train_data_loader:\n",
    "    print(data[0]) # 第一个batch中的实际数据，结构为(batch_size, seq_len)\n",
    "    print(data[1]) # 每个句子所对应的标签（积极与消极）\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674e127-fdeb-44dc-8310-3db3413e551c",
   "metadata": {},
   "source": [
    "- **定义Transformer中的各个结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "92b116f2-4000-4b35-97ed-b870f46906ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义PositionalEncoding类，用于为输入添加位置信息\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        #有transpose，代表默认输入数据形状为(seq_len, batch_size, d_model)\n",
    "        #如果输入结构为(batch_size, seq_len, d_model)，则不需要transpose\n",
    "        if batch_first:\n",
    "            pe = pe.unsqueeze(0)\n",
    "        else:\n",
    "            pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        #如果batch_first，则需要截断的是中间的维度\n",
    "        #且用于中间维度截断的维度是seq_len\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:, :x.size(1), :]\n",
    "        else:\n",
    "            #如果没有batch_first，需要截断的是第一个维度\n",
    "            x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7bc08033-d1b9-4e54-aef7-99f08b032577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Transformer类，用于实现Transformer模型\n",
    "class EncoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class,\n",
    "                 dim_feedforward=256, num_head=2, num_layers=2\n",
    "                 , dropout=0.1, max_len=128, activation: str = \"relu\"\n",
    "                 , batch_first = True):\n",
    "        \n",
    "        # 调用父类的构造函数\n",
    "        super(EncoderOnlyTransformer, self).__init__()\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 位置编码层\n",
    "        self.position_embedding = PositionalEncoding(embedding_dim, dropout\n",
    "                                                     , max_len\n",
    "                                                     , batch_first = batch_first)\n",
    "        \n",
    "        # 编码层与编码层的打包\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head\n",
    "                                                   , dim_feedforward\n",
    "                                                   , dropout, activation\n",
    "                                                  , batch_first = batch_first)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 输出层，现在是情感分类，二分类任务\n",
    "        #self.output = nn.Sequential(nn.Linear(hidden_dim, num_class)\n",
    "                                   #,nn.Sigmoid())\n",
    "        \n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 如果你希望batch_first=False，你随时可以使用Transpose来进行转置\n",
    "\n",
    "        # 生成填充掩码，现在填充掩码函数\n",
    "        padding_mask = length_to_mask(inputs)\n",
    "        \n",
    "        # 获取词嵌入表示\n",
    "        src = self.embeddings(inputs)\n",
    "        \n",
    "        # 添加位置编码\n",
    "        src = self.position_embedding(src)\n",
    "\n",
    "        # 通过Transformer编码器进行处理\n",
    "        src = self.transformer(src, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        # 进行平均池化，或者索引\n",
    "        # 经过这一步数据的结构会变为(batch_size,1,input_dimension)\n",
    "        # 因此线性层的hidde_dim维度应该设置为input_dimension\n",
    "        src = src[:,-1,:]\n",
    "        \n",
    "        # 通过输出层得到分类结果\n",
    "        output = self.output(src)\n",
    "\n",
    "        #log_softmax函数\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6858334-aff3-40a5-9306-751098663deb",
   "metadata": {},
   "source": [
    "- 三、训练过程\n",
    "\n",
    "Transformer的训练过程对我们来说其实是相对简单和熟悉的。我们需要定义Dataloader等结构，并且需要保持每个batch内的数据长度一致（需要对短的数据进行填充，对长的数据进行裁剪）。除此之外，我们需要定义优化器、进行epoch上的循环等过程。这个流程与其他深度学习算法并无区别，因此对大家来说相对容易。我们已经定义了数据、定义了模型，接下来定义训练和测试等步骤的具体代码。进入训练过程时，使用**二分类交叉熵损失**和 **Adam优化器**，在每个训练轮次中，遍历训练数据，进行前向传播、计算损失、反向传播和参数更新，并记录每轮次的总损失。在测试过程中，通过遍历测试数据，禁用梯度计算进行前向传播，计算预测准确率，最终输出在测试集上的总体准确率。整个流程通过 tqdm 模块显示训练和测试的进度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ca81d-a47b-4950-8772-600ab11494cc",
   "metadata": {},
   "source": [
    "> 整合之前的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c5e91f-93df-48a2-b34b-674f2ae6458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import sentence_polarity\n",
    "\n",
    "#赋值，为后续展示句子做准备\n",
    "sentences = sentence_polarity.sents()\n",
    "label_type = sentence_polarity.categories()\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def load_sentence_polarity():\n",
    "    from nltk.corpus import sentence_polarity\n",
    "    vocab = Vocab.build(sentence_polarity.sents())\n",
    "    train_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                  for sentence in sentence_polarity.sents(categories='pos')[:4000]] \\\n",
    "    + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[:4000]]\n",
    "    test_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                 for sentence in sentence_polarity.sents(categories='pos')[4000:]] \\\n",
    "        + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[4000:]]\n",
    "    return train_data, test_data, vocab\n",
    "\n",
    "def length_to_mask(seq, pad_token=0):\n",
    "    padding_mask = (seq == pad_token).float() * -1e9  # (batch_size, seq_len)\n",
    "    return padding_mask\n",
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, targets\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        if batch_first:\n",
    "            pe = pe.unsqueeze(0)\n",
    "        else:\n",
    "            pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:, :x.size(1), :]\n",
    "        else:\n",
    "            x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# 定义Transformer类，用于实现Transformer模型\n",
    "class EncoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class,\n",
    "                 dim_feedforward=256, num_head=2, num_layers=2\n",
    "                 , dropout=0.1, max_len=128, activation: str = \"relu\"\n",
    "                 , batch_first = True):\n",
    "        super(EncoderOnlyTransformer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = PositionalEncoding(embedding_dim, dropout\n",
    "                                                     , max_len\n",
    "                                                     , batch_first = batch_first)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head\n",
    "                                                   , dim_feedforward\n",
    "                                                   , dropout, activation\n",
    "                                                  , batch_first = batch_first)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 输出层，现在是情感分类，二分类任务\n",
    "        #self.output = nn.Sequential(nn.Linear(hidden_dim, num_class)\n",
    "                                   #,nn.Sigmoid())\n",
    "        \n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        padding_mask = length_to_mask(inputs)\n",
    "        src = self.embeddings(inputs)\n",
    "        src = self.position_embedding(src)\n",
    "        src = self.transformer(src, src_key_padding_mask=padding_mask)\n",
    "        src = src[:,-1,:]\n",
    "        output = self.output(src)\n",
    "        log_probs = F.log_softmax(output, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5ebfcb-518b-42dd-901e-b44b86dddba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128  # 词嵌入的维度为128\n",
    "hidden_dim = 128  # 隐藏层的维度为128，同embedding_dim\n",
    "num_class = 2  # 类别数量为2\n",
    "batch_size = 32  # 每个批次的大小为32\n",
    "num_epoch = 15  # 训练的轮数为10\n",
    "\n",
    "# 加载数据\n",
    "train_data, test_data, vocab = load_sentence_polarity()\n",
    "train_dataset = TransformerDataset(train_data)  # 创建训练数据集\n",
    "test_dataset = TransformerDataset(test_data)  # 创建测试数据集\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)  # 创建训练数据加载器\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)  # 创建测试数据加载器\n",
    "\n",
    "# 加载模型\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 选择设备（GPU或CPU）\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = EncoderOnlyTransformer(len(vocab), embedding_dim, hidden_dim, num_class)  # 实例化Transformer模型\n",
    "model.to(device)  # 将模型加载到GPU中（如果已经正确安装）\n",
    "\n",
    "# 训练过程\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用Adam优化器，学习率为0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db939243-65e2-4bee-ac33-68962cf5a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 170.24\n",
      "Loss: 157.07\n",
      "Loss: 139.92\n",
      "Loss: 119.64\n",
      "Loss: 99.74\n",
      "Loss: 83.95\n",
      "Loss: 66.40\n",
      "Loss: 52.33\n",
      "Loss: 44.19\n",
      "Loss: 33.92\n",
      "Loss: 29.01\n",
      "Loss: 27.34\n",
      "Loss: 18.26\n",
      "Loss: 17.21\n",
      "Loss: 15.10\n"
     ]
    }
   ],
   "source": [
    "# 设置模型为训练模式\n",
    "model.train()\n",
    "\n",
    "# 遍历每个epoch\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss_for_epoch = 0  # 初始化总损失为0\n",
    "    # 遍历每个批次，显示训练进度\n",
    "    for batch in train_data_loader:\n",
    "        # 将输入、长度和目标数据移动到设备上\n",
    "        inputs, targets = [x for x in batch]\n",
    "        \n",
    "        # 前向传播得出log softmax结果\n",
    "        log_probs = model(inputs)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(log_probs, targets)\n",
    "        \n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 反向传播、计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失\n",
    "        total_loss_for_epoch += loss.item()\n",
    "    \n",
    "    # 输出每个轮次的总损失\n",
    "    print(f\"Loss: {total_loss_for_epoch:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4cacf04-b6a6-42fa-bc27-e7fe83b67f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.67\n"
     ]
    }
   ],
   "source": [
    "# 测试过程\n",
    "acc = 0  # 初始化准确率计数器\n",
    "model.eval()\n",
    "for batch in test_data_loader:  # 遍历每个测试批次\n",
    "    inputs, targets = [x for x in batch]  # 将输入、长度和目标数据移动到设备上\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        output = model(inputs)  # 前向传播计算输出\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()  # 计算预测正确的数量并累加\n",
    "\n",
    "# 输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")  # 计算并输出测试集上的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d804ad-d391-4230-8fe2-e69acfaa2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = torch.tensor([0.3,0.5,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8535f8c1-9e97-46dd-a539-b8740400866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.argmax() #返回最大的数字所在的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b4600-5072-4044-84c2-dada3b3509af",
   "metadata": {},
   "source": [
    "损失在稳步下降中，我们还可以继续训练、继续调整，对模型进行进一步的提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0acb47-2dab-46cd-bfca-c4cf28abd183",
   "metadata": {},
   "source": [
    "## 3.3 Decoder-Only任务下的Transformer实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2970d-6daf-4a41-ab53-15d1993883de",
   "metadata": {},
   "source": [
    "生成式算法在Transformer领域占据了举足轻重的地位，它们极大地推动了自然语言处理和生成任务的发展。通过利用Transformer架构中的自注意力机制，生成式算法能够在捕捉长距离依赖关系和上下文信息方面表现出色。它们在文本生成、机器翻译、对话系统等任务中展现了强大的能力，如OpenAI的GPT系列模型就是典型的代表。生成式算法不仅提高了生成文本的流畅性和连贯性，还在处理复杂的上下文和多样化输出方面取得了显著进步，推动了自然语言生成技术的前沿发展。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7a9e4-7219-49cf-9a64-daca6b99e2f8",
   "metadata": {},
   "source": [
    "适合作为生成式算法训练样本的数据类型包括以下几种：\n",
    "\n",
    "1. **文本数据**：\n",
    "   - **书籍和小说**：这些数据通常包含丰富的语言表达和上下文信息，适合训练语言模型生成连贯的长文本。\n",
    "   - **新闻文章**：提供正式和信息密集的内容，帮助模型生成结构化和信息准确的文本。\n",
    "   - **对话数据**：包括聊天记录和对话数据集，适合训练对话生成模型。\n",
    "   - **社交媒体帖子**：如推特、博客等，包含多样化的语言风格和主题，适合生成多样化的文本内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f72a6b-dd49-43d7-b546-0b54d1208af8",
   "metadata": {},
   "source": [
    "2. **脚本和剧本**：\n",
    "   - 电影、电视剧、戏剧的剧本包含丰富的对话和场景描述，适合对话生成和场景描述生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687a0e1-b2d1-466a-9799-8445450c62fe",
   "metadata": {},
   "source": [
    "3. **技术文档和编程代码**：\n",
    "   - 技术文档、API文档和编程代码库适合训练代码生成和自动文档生成模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad679ec-b65c-4f57-99c5-f32ec35a3b6f",
   "metadata": {},
   "source": [
    "4. **诗歌和文学作品**：\n",
    "   - 这些数据包含独特的语言风格和创意表达，适合生成诗歌和文学作品。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c839a-840c-4418-a03d-556b868f05ee",
   "metadata": {},
   "source": [
    "5. **法律文书和合同**：\n",
    "   - 法律文书和合同文本适合训练生成法律相关文本的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c99b7b-73e0-4a27-9180-5625a6bff81e",
   "metadata": {},
   "source": [
    "6. **医学文献和病例报告**：\n",
    "   - 医学文献、病例报告和诊断记录适合生成医学相关的文本和诊断报告。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c910eb-d880-43d5-891d-753861e21bbf",
   "metadata": {},
   "source": [
    "7. **教学资料和教科书**：\n",
    "   - 教学资料和教科书内容适合训练教育和教学相关文本生成模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3545bd-292f-4778-8cdf-3c96769507d7",
   "metadata": {},
   "source": [
    "8. **科学论文和研究报告**：\n",
    "   - 科学论文和研究报告数据适合生成学术文本和研究内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc07e08-8578-4843-9331-2b05c27274b7",
   "metadata": {},
   "source": [
    "以上数据类型能够为生成式算法提供丰富的语言资源和多样化的上下文信息，有助于提升模型的生成质量和适应性。在收集和使用这些数据时，需注意数据的合法性和隐私保护，确保数据来源的合法和合规。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f87bf6a-ec7e-4699-a34a-df92401c24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29493acd-b952-452a-90c0-25d351b27faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'DLdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d562e00-5f34-46cb-b93e-3a3e64d730ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(PATH,\"cnews.train.txt\")\n",
    "                         , sep=\"\\t\", names = [\"label\",\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c12b93-246f-4ce0-9f5e-36ef8a9d8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =pd.read_csv(os.path.join(PATH,\"cnews.test.txt\")\n",
    "                      , sep=\"\\t\", names = [\"label\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a171dd4-e4aa-4903-a82e-e2c04f77202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>体育</td>\n",
       "      <td>商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>体育</td>\n",
       "      <td>冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>体育</td>\n",
       "      <td>辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>体育</td>\n",
       "      <td>揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0    体育  马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...\n",
       "1    体育  商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...\n",
       "2    体育  冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...\n",
       "3    体育  辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...\n",
       "4    体育  揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79bc94b-411a-4390-b53d-4af136050c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>体育</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>娱乐</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>家居</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>房产</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>教育</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时尚</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时政</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>游戏</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>科技</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>财经</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       content\n",
       "label         \n",
       "体育        5000\n",
       "娱乐        5000\n",
       "家居        5000\n",
       "房产        5000\n",
       "教育        5000\n",
       "时尚        5000\n",
       "时政        5000\n",
       "游戏        5000\n",
       "科技        5000\n",
       "财经        5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f91fd1e-b5d5-4944-8a9e-503191afe580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>教育</td>\n",
       "      <td>法国欢迎理科生 商学院学生易就业在3月24日的法国文化开放日活动的留学专题讲座中，法驻穗总领...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>教育</td>\n",
       "      <td>留学提醒：教育部发布赴比利时留学预警针对最近我国赴比利时留学人员接连发生入境时被比海关拒绝或...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>教育</td>\n",
       "      <td>留学访谈实录：澳际专家谈国际教育巡回展10月16日下午5点，北京澳际教育咨询有限公司的国内市...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>教育</td>\n",
       "      <td>五名中国留学生因诈骗现金在韩被捕据《环球时报》 韩国警方24日逮捕了涉嫌多次通过声讯诈骗现金...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>教育</td>\n",
       "      <td>专家提醒：留学忌盲目做好职业规划人民网·天津视窗1月3日电：记者在采访中了解到，在今年严峻的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>教育</td>\n",
       "      <td>中央财大与斯蒂文斯理工学院合作项目毕业典礼2011年5月11日下午，中央财经大学与美国斯蒂文...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>教育</td>\n",
       "      <td>揭秘体育明星赴美留学生活 张怡宁变身厨娘(组图)4月中旬，由16位奥运冠军和世界冠军组成的第...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>教育</td>\n",
       "      <td>新通国际第22届教育展暨出国考试展开幕此届出国考(微博)试留学(微博)展有来自澳大利亚、加拿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>教育</td>\n",
       "      <td>海外实拍：英国学生不靠高考一锤定音(组图)韩国：高考不算总分在韩国高考中，考生、家长以及社会...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>教育</td>\n",
       "      <td>美国名校IAUC课程：高考后准备9月留学正合适又到了高考(微博)临战前最让家长们纠结的时候，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            content\n",
       "20000    教育  法国欢迎理科生 商学院学生易就业在3月24日的法国文化开放日活动的留学专题讲座中，法驻穗总领...\n",
       "20001    教育  留学提醒：教育部发布赴比利时留学预警针对最近我国赴比利时留学人员接连发生入境时被比海关拒绝或...\n",
       "20002    教育  留学访谈实录：澳际专家谈国际教育巡回展10月16日下午5点，北京澳际教育咨询有限公司的国内市...\n",
       "20003    教育  五名中国留学生因诈骗现金在韩被捕据《环球时报》 韩国警方24日逮捕了涉嫌多次通过声讯诈骗现金...\n",
       "20004    教育  专家提醒：留学忌盲目做好职业规划人民网·天津视窗1月3日电：记者在采访中了解到，在今年严峻的...\n",
       "...     ...                                                ...\n",
       "24995    教育  中央财大与斯蒂文斯理工学院合作项目毕业典礼2011年5月11日下午，中央财经大学与美国斯蒂文...\n",
       "24996    教育  揭秘体育明星赴美留学生活 张怡宁变身厨娘(组图)4月中旬，由16位奥运冠军和世界冠军组成的第...\n",
       "24997    教育  新通国际第22届教育展暨出国考试展开幕此届出国考(微博)试留学(微博)展有来自澳大利亚、加拿...\n",
       "24998    教育  海外实拍：英国学生不靠高考一锤定音(组图)韩国：高考不算总分在韩国高考中，考生、家长以及社会...\n",
       "24999    教育  美国名校IAUC课程：高考后准备9月留学正合适又到了高考(微博)临战前最让家长们纠结的时候，...\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"label\"] == \"教育\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acee24-8dbf-409c-be8b-5039c22226ad",
   "metadata": {},
   "source": [
    "<font color=\"red\">**在最初录制“数据预处理”视频时，没有设置随机数种子，因此你看到的视频结果可能与你运行的代码结果不一致。在最新的版本的课件中，我为这个随机抽样的过程设置了随机数种子，所有视频与课件不一致的地方，请以课件为准。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951d7b2f-9bbb-4783-a809-bf03a53779ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1252/1585671898.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = train_data.groupby('label').apply(lambda x: x.sample(n=500)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to DLdata/cnews_train_sampled.txt\n"
     ]
    }
   ],
   "source": [
    "# 随机抽样 - 训练集\n",
    "np.random.seed(1412)\n",
    "sampled_df = train_data.groupby('label').apply(lambda x: x.sample(n=500)).reset_index(drop=True)\n",
    "\n",
    "# 保存为txt文件\n",
    "output_file_path = os.path.join(PATH,\"cnews_train_sampled.txt\")\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in sampled_df.iterrows():\n",
    "        f.write(f\"{row['label']}\\t{row['content']}\\n\")\n",
    "\n",
    "print(f\"Sampled data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d1987a-8743-4824-b70a-7fe6d805bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1252/3182694706.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = test_data.groupby('label').apply(lambda x: x.sample(n=500)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to DLdata/cnews_test_sampled.txt\n"
     ]
    }
   ],
   "source": [
    "# 随机抽样 - 测试集\n",
    "np.random.seed(1412)\n",
    "sampled_df = test_data.groupby('label').apply(lambda x: x.sample(n=500)).reset_index(drop=True)\n",
    "\n",
    "# 保存为txt文件\n",
    "output_file_path = os.path.join(PATH,\"cnews_test_sampled.txt\")\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in sampled_df.iterrows():\n",
    "        f.write(f\"{row['label']}\\t{row['content']}\\n\")\n",
    "\n",
    "print(f\"Sampled data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69007147-1f4b-4cd2-85aa-acc238da3405",
   "metadata": {},
   "source": [
    "### 3.3.1 数据导入与数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a618096-15a8-434e-bbdd-a5c3f7c34092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                label, content = parts\n",
    "                data.append(content) #只要content，不要label\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af03a7ef-3926-4467-a0b8-e63df2aab761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class calculate_stats:\n",
    "    def __init__(self,data):\n",
    "        self.total_samples = len(data)\n",
    "        self.len_ = []\n",
    "        for content in data:\n",
    "            self.len_.append(len(content))\n",
    "\n",
    "        self.lower_quartile = np.percentile(self.len_, 25)\n",
    "        self.median = np.median(self.len_)\n",
    "        self.upper_quartile = np.percentile(self.len_, 75)\n",
    "        self.percentile_90 = np.percentile(self.len_, 90)\n",
    "\n",
    "    def stats(self):\n",
    "        # 输出结果\n",
    "        print(f\"总字数: {sum(self.len_)}\")\n",
    "        print(f\"样本数量: {self.total_samples}\")\n",
    "        print(f\"平均每篇文章的字数: {sum(self.len_)/self.total_samples}\")\n",
    "        print(f\"最长句子的字数:{max(self.len_)}\")\n",
    "        print(f\"最短句子的字数:{min(self.len_)}\")\n",
    "        print(f\"句子长度的25%分位数:{self.lower_quartile}\")\n",
    "        print(f\"句子长度的50%分位数:{self.median}\")\n",
    "        print(f\"句子长度的75%分位数:{self.upper_quartile}\")\n",
    "        print(f\"句子长度的90%分位数:{self.percentile_90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e2fada-1adc-4eb1-9433-7a23b867d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设数据存储在 'data.txt'\n",
    "file_path = os.path.join(PATH,\"cnews_train_sampled.txt\")\n",
    "\n",
    "# 读取数据\n",
    "data = read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2573ac-1928-4197-bd57-563f3bd4a915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 samples: ['新浪正在视频直播尼克斯vs魔术 魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？(新体)[视频直播室] [视频直播室-教育网专用] [图文直播室]', '弗老大同意终止合同 高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。北京队助理教练袁超对新华社说，“弗朗西斯下午来到首钢体育馆，告诉球队，他已经决定离开了。”33岁的弗朗西斯在上一轮对阵江苏队的比赛中，没有能出场，他在中场休息时间无故离开了更衣室。在赛后的新闻发布会上，闵鹿蕾确认了弗朗西斯中场离开的消息，并且说“这是我第一次看到有球员在比赛期间离开的。”闵鹿蕾的一番话，更加加剧了弗朗西斯离开北京队的可能性，而且他在25号缺席了球队的训练，原因是要和家里人度过圣诞节，他在接受采访时候表示：“我没有无故不训练，我给教练打过招呼了，他也答应了。”袁超在接受新华社采访时候，终于说出了今天谈判的进展，“我今天早上和弗朗西斯谈了谈关于他中场离开和圣诞节不训练的事儿，我告诉他，为了球队的利益，我们想让他离开。当时他在会谈中没有给我一个明确的答复。”“但是，当他下午出现在首钢训练馆中的时候，他说他已经准备好要离开了。”袁超说。无论北京俱乐部还是弗朗西斯，都希望双方有个圆满的结局。过去的两周，弗朗西斯一共为北京打了4场比赛，场均3分钟内得到0.5分，0.7个篮板，这和昔日的三次NBA全明星队员相比，确实相差甚远。俱乐部做出这样的决定，或许对双方都有好处。(FRANK)']\n"
     ]
    }
   ],
   "source": [
    "# 查看前2个样本\n",
    "print(f\"First 2 samples: {data[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ad13eb-abc0-4422-8a6c-45fde9b20a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总字符数和样本数\n",
    "cal = calculate_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "225d3dc0-41c0-4629-b768-c0c4b1ed133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 4537518\n",
      "样本数量: 5000\n",
      "平均每篇文章的字数: 907.5036\n",
      "最长句子的字数:16179\n",
      "最短句子的字数:18\n",
      "句子长度的25%分位数:348.0\n",
      "句子长度的50%分位数:686.0\n",
      "句子长度的75%分位数:1151.0\n",
      "句子长度的90%分位数:1876.2000000000007\n"
     ]
    }
   ],
   "source": [
    "cal.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720cbb5-0649-454c-bde4-bfdd7c711518",
   "metadata": {},
   "source": [
    "【Q】句子长度差异太大，应该如何处理？\n",
    "- padding与truncate（填充与裁剪）\n",
    "- 句子长度筛选 + padding\n",
    "- 段落重组/段落重分块 + padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b93a3f-98ae-45af-8388-599403e5f540",
   "metadata": {},
   "source": [
    "> **句子长度筛选函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75489b9d-0b12-45fd-b9ca-dae8b3230492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences_by_length(sentences, min_len, max_len):\n",
    "    \"\"\"\n",
    "    筛选出字数超过指定最小长度的所有句子。\n",
    "\n",
    "    参数：\n",
    "    sentences (list of str): 输入的句子列表。\n",
    "    min_length (int): 最小字数长度。\n",
    "\n",
    "    返回：\n",
    "    List[str]: 筛选后的句子列表。\n",
    "    \"\"\"\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(sentence) > min_len and len(sentence) < max_len]\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38b9c0c-7952-4f83-a56b-72539a9304d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filter_sentences_by_length(data,300,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58bace0-8c40-4cf0-96dc-edf0af12e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 3708916\n",
      "样本数量: 3800\n",
      "平均每篇文章的字数: 976.0305263157895\n",
      "最长句子的字数:2989\n",
      "最短句子的字数:301\n",
      "句子长度的25%分位数:543.0\n",
      "句子长度的50%分位数:814.0\n",
      "句子长度的75%分位数:1231.25\n",
      "句子长度的90%分位数:1818.1\n"
     ]
    }
   ],
   "source": [
    "cal = calculate_stats(filtered_data)\n",
    "cal.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82546f3-f795-4cea-a36a-7092b6aa9703",
   "metadata": {},
   "source": [
    "> **段落重组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcbb2da-4cef-4ee4-a177-9b8a878a5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.661 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "#重组之前，要先进行分词\n",
    "data_split = [jieba.lcut(sentence) for sentence in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7a8a180-e124-4c71-a695-a19b1fe06b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['新浪', '正在', '视频', '直播', '尼克斯', 'vs', '魔术', ' ', '魔兽', '小斯', '强强', '对话', '新浪', '体育讯', '12', '月', '31', '日', '8', ':', '00', '，', '新浪', '体育', '将', '为', '您', '视频', '直播', '魔术', '主场', '迎战', '尼克斯', '的', '比赛', '。', '摆脱', '了', '赛季', '初', '的', '低迷', '之后', '，', '尼克斯', '打出', '14', '胜', '1', '负', '战绩', '，', '最近', '他们', '在', '圣诞', '大战', '中', '又', '战胜', '了', '公牛', '，', '不过', '随后', '一战', '却', '再次', '被', '热火', '打败', '。', '如今', '尼克斯', '两胜', '公牛', '，', '两败', '于', '凯尔特人', '和', '热火', '，', '东部', '四强', '中', '只有', '魔术', '还', '没', '交手', '，', '两队', '在', '11', '月', '3', '日', '曾', '被']\n"
     ]
    }
   ],
   "source": [
    "print(data_split[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11164334-57cb-43b0-83c8-6a1a7520d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先为现有的句子添加起始符号与终止符号\n",
    "processed_data = []\n",
    "\n",
    "for content in data_split:\n",
    "    content = [\"<sos>\"] + content + [\"<eos>\"]\n",
    "    processed_data.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73fff46e-967e-4855-adea-31fd7405786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '阿帅', '狂赞', '希尔', '：', '真的', '难以置信', ' ', '他', '让', '整个', '世界', '都', '不同', '了', '新浪', '体育讯', '北京', '时间', '1', '月', '16', '日', '(', '美国', '当地', '时间', '1', '月', '15', '日', ')', '消息', '，', '休斯敦', '火箭', '客场', '挑战', '亚特兰大', '老鹰', '，', '火箭', '克服', '了', '种种', '不利因素', '，', '最终', '以', '112', '-', '106', '战胜', '了', '对手', '。', '赛后', '，', '阿', '德尔曼', '接受', '了', '采访', '，', '点名', '表扬', '两位', '替补', '阿隆', '-', '布鲁克斯', '和', '乔丹', '-', '希尔', '，', '表示', '帕特森', '伤势', '不明', '。', '和', '昨天', '的', '怒批', '裁判', '不同', '，', '今天', '阿帅', '开起', '了', '记者', '的', '玩笑', '，', '对', '《', '休斯敦', '纪实']\n"
     ]
    }
   ],
   "source": [
    "print(processed_data[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec2dbc4-3dae-47cd-9817-a2dee3fac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_chunk(data, chunk_size):\n",
    "    \"\"\"\n",
    "    将所有嵌套列表合并为一个长列表，然后按指定大小分块。\n",
    "    \n",
    "    参数：\n",
    "    data (list of list of str): 输入的嵌套字符串列表。\n",
    "    chunk_size (int): 每个块的最大大小。\n",
    "    \n",
    "    返回：\n",
    "    list of list of str: 分块后的字符串列表。\n",
    "    \"\"\"\n",
    "    # 合并所有列表为一个长列表\n",
    "    merged_list = []\n",
    "    for sublist in data:\n",
    "        merged_list.extend(sublist)\n",
    "    \n",
    "    # 通过索引的方式，按指定大小分块\n",
    "    chunks = [merged_list[i:i + chunk_size] for i in range(0, len(merged_list), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637f837-059b-41c5-8530-35c09bf4daa3",
   "metadata": {},
   "source": [
    "<font color=\"red\">**在最初录制“数据预处理”视频时，我设置的seq_len长度为2000，后为更好地适应大家的硬件，调整为更小的seq_len=512。所有视频与课件不一致的地方，请以课件为准。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a4c1f64-4762-408b-acb1-21e8ce332234",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = merge_and_chunk(processed_data,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bcb4aa4-df51-4e72-930c-35da780ff58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '新浪', '正在', '视频', '直播', '尼克斯', 'vs', '魔术', ' ', '魔兽', '小斯', '强强', '对话', '新浪', '体育讯', '12', '月', '31', '日', '8', ':', '00', '，', '新浪', '体育', '将', '为', '您', '视频', '直播', '魔术', '主场', '迎战', '尼克斯', '的', '比赛', '。', '摆脱', '了', '赛季', '初', '的', '低迷', '之后', '，', '尼克斯', '打出', '14', '胜', '1', '负', '战绩', '，', '最近', '他们', '在', '圣诞', '大战', '中', '又', '战胜', '了', '公牛', '，', '不过', '随后', '一战', '却', '再次', '被', '热火', '打败', '。', '如今', '尼克斯', '两胜', '公牛', '，', '两败', '于', '凯尔特人', '和', '热火', '，', '东部', '四强', '中', '只有', '魔术', '还', '没', '交手', '，', '两队', '在', '11', '月', '3', '日', '曾', '被', '安排', '一战', '，', '但是', '因故', '未能', '进行', '，', '急欲', '给', '自己', '加盖', '强队', '标签', '的', '尼克斯', '会', '在', '这场', '迟来', '的', '比赛', '中', '全力以赴', '。', '而', '最近', '4', '连胜', '的', '魔术', '也', '想', '在', '这场', '比赛', '中一试', '牛刀', '，', '连胜', '凯尔特人', '马刺', '的', '他们', '，', '何惧', '尼克斯', '？', '(', '新', '体', ')', '[', '视频', '直播室', ']', ' ', '[', '视频', '直播室', '-', '教育网', '专用', ']', ' ', '[', '图文', '直播室', ']', '<eos>', '<sos>', '弗老大', '同意', '终止', '合同', ' ', '高层', '确认', '为', '球队', '利益', '让', '他', '离去', '新浪', '体育讯', '北京', '时间', '12', '月', '27', '日', '，', '来自', '新华网', '英文版', '消息', '，', '在']\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "509657bc-6a4b-432f-aafe-2df85979dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0134498b-ae1f-4ad3-b9c5-97a31a2cd061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8823fb95-ab49-4898-bfb9-f626a48faf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(chunks[-2].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bc3d340-7b7d-4934-8f59-846f02bf4c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    }
   ],
   "source": [
    "print(chunks[-1].__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c76cfe-f427-4288-8fd7-125e3818a686",
   "metadata": {},
   "source": [
    "> **停用词与标点符号处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31655d1e-c9cd-4a01-9c43-d8fef94bc36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['暗地里', 'associated', 'Ａ', '[', '临', '［⑦］', '继之', '自家', '》），', '独自']\n"
     ]
    }
   ],
   "source": [
    "#创建停用词列表\n",
    "\n",
    "import os\n",
    "\n",
    "# 定义目录路径\n",
    "stopwords_dir = os.path.join(PATH,\"stopwords\")\n",
    "\n",
    "# 获取目录下所有的txt文件\n",
    "stopwords_files = [os.path.join(stopwords_dir, file) for file in os.listdir(stopwords_dir) if file.endswith('.txt')]\n",
    "\n",
    "# 初始化一个集合来存储所有的停用词（去重）\n",
    "stopwords_set = set()\n",
    "\n",
    "# 读取所有txt文件并将停用词加入集合\n",
    "for file_path in stopwords_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 去除换行符和空格\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                stopwords_set.add(word)\n",
    "\n",
    "# 将集合转换为列表\n",
    "stopwords_list = list(stopwords_set)\n",
    "\n",
    "# 输出合并后的停用词列表\n",
    "print(stopwords_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d15ee3b-4bc8-469b-afb2-6329738e0029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list.__len__() #2126个停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e01344c-651d-48b2-a0cf-6bc2ad34eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要将结果保存到文件\n",
    "output_file_path = os.path.join(PATH,\"merged_stopwords.txt\")\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    for word in stopwords_list:\n",
    "        output_file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c01072-5ecc-4bd0-a450-bd9db78b812a",
   "metadata": {},
   "source": [
    "> **Vocab：词汇表的构成与编码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1f06789-922c-4c23-91ce-e5c8feafe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"\n",
    "    可以同时接纳Token和text两种类型的数据\n",
    "    对原始文字数据，调用build方法，进行分词、完成预处理、完成词频筛选\n",
    "    对Token数据，使用init中的流程，完成添加未知词、词汇表构建并根据词汇表进行编码\n",
    "    建好词汇表后，再调用单独的方法来进行编码\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = [\"<unk>\"] + tokens \n",
    "            if \"<sos>\" not in tokens:\n",
    "                tokens = [\"<sos>\"] + tokens\n",
    "            if \"<eos>\" not in tokens:\n",
    "                tokens = [\"<eos>\"] + tokens\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text, min_freq=1\n",
    "              , stopwords = set([\"的\", \"和\", \"了\", \"在\", \"是\", \"就\", \"不\", \"也\", \"有\", \"但\"])\n",
    "              , preprocessing=False\n",
    "              , reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for tokens in text:\n",
    "            if preprocessing:\n",
    "                #去除标点符号\n",
    "                tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
    "                #去除停用词\n",
    "                tokens = [token for token in tokens if token and token not in stopwords]\n",
    "            #词频筛选\n",
    "            for token in tokens:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\", \"<sos>\", \"<eos>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e9ffe5b-ae57-4719-bf07-0f2b6ab6fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.build(chunks,min_freq=1\n",
    "                   ,stopwords = stopwords_list\n",
    "                   ,preprocessing = True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22ac712a-f56c-4d64-80b3-debc99d11d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_token = []\n",
    "for tokens in chunks:\n",
    "    ordinal_token.append(vocab.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b7c275-1897-422a-9069-d517b9c3f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5189"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_token.__len__() #结构为(batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "857fe080-fa8c-4db4-9fb4-529a77ad4972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>']\n",
      "['<sos>']\n",
      "['<eos>']\n"
     ]
    }
   ],
   "source": [
    "#前三个编码就正好是三个我们自行添加的字符\n",
    "for i in [[0],[1],[2]]:\n",
    "    print(vocab.convert_ids_to_tokens(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cae2a715-12f8-409a-b7a1-78f4a4a3a4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 0, 5, 6, 7, 0, 8, 9, 10, 11, 12, 13, 4, 14, 15, 16, 17, 18, 19, 0, 20, 0, 4, 21, 0, 0, 0, 5, 6, 8, 22, 23, 7, 0, 24, 0, 25, 0, 26, 27, 0, 28, 0, 0, 7, 29, 30, 31, 32, 33, 34, 0, 0, 0, 0, 35, 36, 37, 0, 38, 0, 39, 0, 0, 40, 41, 42, 0, 0, 43, 44, 0, 0, 7, 45, 39, 0, 46, 0, 47, 0, 43, 0, 48, 49, 37, 0, 8, 50, 51, 52, 0, 53, 0, 54, 16, 55, 18, 56, 0, 57, 41, 0, 0, 58, 59, 0, 0, 60, 0, 0, 61, 62, 63, 0, 7, 0, 0, 64, 65, 0, 24, 37, 66, 0, 0, 0, 67, 68, 0, 8, 0, 69, 0, 64, 24, 70, 71, 0, 68, 47, 72, 0, 0, 0, 73, 7, 0, 0, 74, 75, 0, 0, 5, 76, 0, 9, 0, 5, 76, 0, 77, 78, 0, 9, 0, 79, 76, 0, 2, 1, 81, 82, 83, 84, 9, 85, 86, 0, 87, 88, 0, 0, 89, 4, 14, 90, 91, 15, 16, 92, 18, 0, 93, 94, 95, 96, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_token[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9158511b-ce29-4afd-af24-ef94f229376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '新浪', '<unk>', '视频', '直播', '尼克斯', '<unk>', '魔术', ' ', '魔兽', '小斯', '强强', '对话', '新浪', '体育讯', '12', '月', '31', '日', '8', '<unk>', '00', '<unk>', '新浪', '体育', '<unk>', '<unk>', '<unk>', '视频', '直播', '魔术', '主场', '迎战', '尼克斯', '<unk>', '比赛', '<unk>', '摆脱', '<unk>', '赛季', '初', '<unk>', '低迷', '<unk>', '<unk>', '尼克斯', '打出', '14', '胜', '1', '负', '战绩', '<unk>', '<unk>', '<unk>', '<unk>', '圣诞', '大战', '中', '<unk>', '战胜', '<unk>', '公牛', '<unk>', '<unk>', '随后', '一战', '却', '<unk>', '<unk>', '热火', '打败', '<unk>', '<unk>', '尼克斯', '两胜', '公牛', '<unk>', '两败', '<unk>', '凯尔特人', '<unk>', '热火', '<unk>', '东部', '四强', '中', '<unk>', '魔术', '还', '没', '交手', '<unk>', '两队', '<unk>', '11', '月', '3', '日', '曾']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.convert_ids_to_tokens(ordinal_token[0])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "166166dd-315d-484b-b430-f150c261e178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_token[0].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eab05e14-ec62-45fc-bf1e-d4209cabc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_token[-1].__len__()) #最后一个样本，极可能是剩余的tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70646cc7-2c0d-42a3-adbe-144d6f360841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 2656730\n",
      "样本数量: 5189\n",
      "平均每篇文章的字数: 511.9926768163423\n",
      "最长句子的字数:512\n",
      "最短句子的字数:474\n",
      "句子长度的25%分位数:512.0\n",
      "句子长度的50%分位数:512.0\n",
      "句子长度的75%分位数:512.0\n",
      "句子长度的90%分位数:512.0\n"
     ]
    }
   ],
   "source": [
    "cal = calculate_stats(ordinal_token)\n",
    "cal.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e1354-112b-47a6-a1ce-4ee703e29054",
   "metadata": {},
   "source": [
    "**【Q】停用词到底该不该设置呢？不适用去除停用词和标点符号的场景有哪些？**\n",
    "> 1. **文本生成和机器翻译**<br><br>\n",
    "> 在文本生成和机器翻译任务中，保留停用词和标点符号是非常重要的，因为这些元素对生成流畅和自然的句子至关重要。<br><br>\n",
    "> 这些任务要求模型理解和生成完整的句子结构，包括停用词和标点符号，以确保输出的文本连贯、自然。<br><br>\n",
    "> 2.**句子级别的情感分析**<br><br>\n",
    "> 在情感分析任务中，停用词和标点符号有时也携带情感信息，如“不是很好”、“非常喜欢”等表达方式中的“不是”、“非常”等词对情感倾向有影响。<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02e371f8-941b-49ae-aacd-a0da869f666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.build(chunks,min_freq=1\n",
    "                   ,stopwords = stopwords_list\n",
    "                   ,preprocessing = False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "669d07e5-36e7-4ac9-a60f-c1a63e9b4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_token = []\n",
    "for tokens in chunks:\n",
    "    ordinal_token.append(vocab.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f670a48b-62cc-4086-9919-703e07ab7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 4, 25, 26, 27, 28, 6, 7, 10, 29, 30, 8, 31, 32, 33, 34, 35, 36, 37, 31, 38, 39, 24, 8, 40, 41, 42, 43, 44, 45, 24, 46, 47, 48, 49, 50, 51, 52, 53, 35, 54, 24, 55, 56, 57, 58, 59, 60, 61, 62, 33, 63, 8, 64, 54, 24, 65, 66, 67, 68, 61, 24, 69, 70, 51, 71, 10, 72, 73, 74, 24, 75, 48, 76, 18, 77, 20, 78, 60, 79, 57, 24, 80, 81, 82, 83, 24, 84, 85, 86, 87, 88, 89, 31, 8, 90, 48, 91, 92, 31, 32, 51, 93, 33, 94, 46, 95, 96, 31, 10, 97, 98, 48, 91, 32, 99, 100, 24, 96, 67, 101, 31, 47, 24, 102, 8, 103, 104, 105, 106, 107, 108, 6, 109, 110, 11, 108, 6, 109, 111, 112, 113, 110, 11, 108, 114, 109, 110, 115, 3, 116, 117, 118, 119, 11, 120, 121, 27, 122, 123, 124, 125, 126, 4, 16, 127, 128, 17, 18, 129, 20, 24, 130, 131, 132, 133, 24, 48]\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_token[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69a05408-4949-4df1-8cea-5ced5dd3dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '新浪', '正在', '视频', '直播', '尼克斯', 'vs', '魔术', ' ', '魔兽', '小斯', '强强', '对话', '新浪', '体育讯', '12', '月', '31', '日', '8', ':', '00', '，', '新浪', '体育', '将', '为', '您', '视频', '直播', '魔术', '主场', '迎战', '尼克斯', '的', '比赛', '。', '摆脱', '了', '赛季', '初', '的', '低迷', '之后', '，', '尼克斯', '打出', '14', '胜', '1', '负', '战绩', '，', '最近', '他们', '在', '圣诞', '大战', '中', '又', '战胜', '了', '公牛', '，', '不过', '随后', '一战', '却', '再次', '被', '热火', '打败', '。', '如今', '尼克斯', '两胜', '公牛', '，', '两败', '于', '凯尔特人', '和', '热火', '，', '东部', '四强', '中', '只有', '魔术', '还', '没', '交手', '，', '两队', '在', '11', '月', '3', '日', '曾']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.convert_ids_to_tokens(ordinal_token[0])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b9a9e11-e6b9-4587-86dd-b42a16f0676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 2656730\n",
      "样本数量: 5189\n",
      "平均每篇文章的字数: 511.9926768163423\n",
      "最长句子的字数:512\n",
      "最短句子的字数:474\n",
      "句子长度的25%分位数:512.0\n",
      "句子长度的50%分位数:512.0\n",
      "句子长度的75%分位数:512.0\n",
      "句子长度的90%分位数:512.0\n"
     ]
    }
   ],
   "source": [
    "cal = calculate_stats(ordinal_token)\n",
    "cal.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99f66725-6c9a-4a5d-8aac-e621df4ffe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_token[-1].__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410cf83-d3b8-4355-9293-72f4987544c6",
   "metadata": {},
   "source": [
    "1) 分词、sos、eos\n",
    "2）预处理【筛选、重组、词汇表（提升质量、未知词、词频筛选、停用词）、编码】\n",
    "3）整理成pytorch能够接纳的形式\n",
    "4）编码转嵌入\n",
    "5）位置编码\n",
    "6）进Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f613a78-6c4d-41ef-a03f-480f67d7704b",
   "metadata": {},
   "source": [
    "- **生成式算法/Decoder-Only结构中的数据导入**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74616071-8b74-4860-9de2-bb718c243cfb",
   "metadata": {},
   "source": [
    "在数据进入Pytorch之前，我们通常需要将数据进行如下的处理——\n",
    "\n",
    "1. **将数据转变为与PyTorch兼容的结构**，包括但不限于：\n",
    "> - 确保数据集拥有`__len__` 方法（返回数据集大小）和 `__getitem__` 方法（根据索引返回数据）。<br><br>\n",
    "> - 数据应该是 `torch.Tensor` 类型，因为 PyTorch 的大部分操作都是针对张量进行的。如果数据是其他格式（如 NumPy 数组、Pandas DataFrame 等），需要将其转换为 PyTorch 张量。<br><br>\n",
    "> - 数据各类预处理：在加载数据之前需要进行归一化或其他基础的预处理操作，以确保数据适合训练，可以在 `__getitem__` 方法中添加这些预处理操作。\n",
    "\n",
    "2. **经过DataLoader对数据完成进一步的处理**，包括但不限于：\n",
    "> - 完成batch分割，将数据集转变为特定神经网络能够接纳的格式<br><br>\n",
    "> - 完成padding、裁剪、类型转换等奖数据变得更整齐的预处理操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b6cee4c-4a12-4a0f-a783-349290e60a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14979914-c9eb-46a2-9ef1-8a6712b559f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#兼容Pytorch，我们使用继承自Dataset的类\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 初始化数据集，将传入的数据保存在实例变量data中\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 根据索引i获取数据集中的第i个样本\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfe6d336-0e6e-426a-b01b-37be8fb6d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义collate_fn函数，用于在DataLoader中对一个batch的数据进行处理\n",
    "def collate_fn(examples):\n",
    "    # 将每个样本的输入部分转换为张量\n",
    "    seq = [torch.tensor(ex) for ex in examples]\n",
    "    y_true = [torch.tensor(ex[1:] + [0]) for ex in examples]\n",
    "    \n",
    "    # pytorch自带的padding工具\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    seq = pad_sequence(seq, batch_first=True)\n",
    "    y_true = pad_sequence(y_true, batch_first=True)\n",
    "    \n",
    "    # 返回处理后的输入和目标\n",
    "    return seq, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8357835-bb04-46fa-aef9-feaa22c42762",
   "metadata": {},
   "source": [
    "> - **灵魂拷问：Decoder-Only架构所需的数据输入是什么样子？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68393fa-7d2f-427a-abb1-665c7cee81ac",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-1.png\" alt=\"描述文字\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f9968-fd21-4547-94f5-5c9549c356a5",
   "metadata": {},
   "source": [
    "几个关键事实：\n",
    "\n",
    "1) 与完整的Transformer不同，Decoder-only结构的输入没有memory，只有标签outputs（在pytorch的代码中一般写作tgt，但极易与损失函数使用的标签所混淆）\n",
    "\n",
    "2) Decoder-Only结构训练的时候是teacher forcing，测试的时候是autoregressive，因此不分特征标签、不分训练集测试集，只有一个序列seq。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce932b-fc7f-402f-b667-8274a8541424",
   "metadata": {},
   "outputs": [],
   "source": [
    "之前讲解过多次，Decoder-Only的结构中预测模式是：\n",
    "\n",
    "训练——（teacher forcing - 不会累计错误）\n",
    "\n",
    "这 👉 xxx1\n",
    "\n",
    "这是 👉 xxx2\n",
    "\n",
    "这是最 👉 xxx3\n",
    "\n",
    "这是最好 👉 xxx4\n",
    "\n",
    "测试——（autoregressive - 累计错误）\n",
    "\n",
    "这是最坏的时代 👉 xxx1\n",
    "\n",
    "这是最坏的时代，xxx1 👉 xxx2\n",
    "\n",
    "这是最坏的时代，xxx1 xxx2 👉 xxx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561038d-7856-4807-9868-c31f838b6220",
   "metadata": {},
   "source": [
    "那seq是什么结构呢？**在embedding之前，是（batch_size，seq_len），就像现在我们得到的ordinal_token一样**。在embedding之后，是（batch_size，seq_len，input_dimension），就是transformer所需要的输入数据格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c9dc4fe-f6ca-41b3-b0ae-a44c96744234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 4, 25, 26, 27, 28, 6, 7, 10, 29, 30, 8, 31, 32, 33, 34, 35, 36, 37, 31, 38, 39, 24, 8, 40, 41, 42, 43, 44, 45, 24, 46, 47, 48, 49, 50, 51, 52, 53, 35, 54, 24, 55, 56, 57, 58, 59, 60, 61, 62, 33, 63, 8, 64, 54, 24, 65, 66, 67, 68, 61, 24, 69, 70, 51, 71, 10, 72, 73, 74, 24, 75, 48, 76, 18, 77, 20, 78, 60, 79, 57, 24, 80, 81, 82, 83, 24, 84, 85, 86, 87, 88, 89, 31, 8, 90, 48, 91, 92, 31, 32, 51, 93, 33, 94, 46, 95, 96, 31, 10, 97, 98, 48, 91, 32, 99, 100, 24, 96, 67, 101, 31, 47, 24, 102, 8, 103, 104, 105, 106, 107, 108, 6, 109, 110, 11, 108, 6, 109, 111, 112, 113, 110, 11, 108, 114, 109, 110, 115, 3, 116, 117, 118, 119, 11, 120, 121, 27, 122, 123, 124, 125, 126, 4, 16, 127, 128, 17, 18, 129, 20, 24, 130, 131, 132, 133, 24, 48, 134, 35, 135, 31, 136, 39, 24, 137, 138, 139, 140, 24, 141, 120, 142, 97, 143, 35, 121, 33, 140, 144, 145, 146, 147, 148, 149, 24, 150, 137, 151, 152, 153, 154, 24, 155, 122, 24, 125, 156, 138, 139, 35, 33, 157, 158, 159, 31, 137, 48, 160, 161, 162, 163, 31, 32, 51, 24, 164, 165, 166, 24, 125, 48, 167, 168, 169, 139, 35, 170, 33, 48, 171, 31, 172, 173, 160, 24, 174, 121, 35, 137, 167, 139, 31, 133, 24, 175, 149, 150, 176, 177, 178, 179, 180, 181, 182, 48, 32, 183, 139, 31, 33, 157, 174, 31, 184, 24, 185, 186, 35, 137, 139, 140, 31, 187, 24, 188, 125, 48, 189, 190, 191, 35, 122, 31, 192, 24, 193, 177, 194, 68, 195, 196, 197, 24, 125, 48, 198, 199, 200, 201, 202, 150, 178, 164, 169, 203, 192, 24, 178, 85, 145, 204, 205, 206, 35, 24, 125, 97, 207, 35, 33, 157, 146, 48, 198, 148, 199, 200, 24, 208, 209, 35, 210, 211, 31, 212, 24, 150, 178, 210, 213, 68, 137, 214, 35, 214, 215, 125, 167, 139, 68, 197, 203, 192, 31, 216, 24, 178, 155, 125, 24, 217, 122, 31, 123, 24, 218, 98, 124, 125, 139, 33, 219, 125, 220, 164, 85, 178, 221, 222, 31, 223, 33, 157, 150, 80, 24, 224, 125, 151, 225, 48, 153, 226, 51, 31, 200, 24, 125, 149, 125, 156, 227, 228, 139, 35, 33, 157, 146, 149, 33, 229, 127, 141, 230, 137, 24, 231, 232, 233, 234, 235, 31, 236, 33, 237, 31, 135, 24, 137, 238, 27, 127, 204, 35, 95, 239, 32, 24, 240, 77, 241, 242, 243, 244, 245, 24, 246, 247, 248, 24, 176, 68, 249, 31, 250, 251, 252, 253, 254, 24, 255, 256, 257, 33, 141, 258, 259, 31, 138] \n",
      " \n",
      " [24, 260, 147, 233, 231, 181, 261, 33, 104, 262, 107, 115, 3, 263, 264, 265, 202, 266, 267, 11, 125, 124, 268, 269, 231, 270, 35, 4, 16, 127, 128, 43, 18, 271, 20, 104, 272, 273, 128, 43, 18, 274, 20, 107, 133, 24, 275, 276, 277, 278, 279, 280, 24, 276, 281, 35, 282, 283, 24, 284, 285, 286, 111, 287, 53, 35, 288, 33, 171, 24, 289, 290, 198, 35, 199, 24, 291, 292, 293, 294, 295, 111, 296, 68, 297, 111, 265, 24, 201, 298, 299, 300, 33, 68, 301, 31, 302, 303, 270, 24, 210, 263, 304, 35, 305, 31, 306, 24, 147, 307, 275, 308, 309, 310, 305, 311, 149, 24, 150, 312, 313, 314, 315, 32, 24, 312, 155, 178, 104, 316, 31, 107, 193, 317, 33, 157, 318, 210, 31, 32, 24, 289, 290, 319, 320, 24, 150, 218, 237, 321, 24, 178, 155, 47, 24, 322, 323, 24, 218, 181, 324, 325, 32, 31, 326, 24, 218, 327, 328, 329, 330, 331, 32, 24, 210, 332, 231, 333, 334, 24, 295, 210, 40, 35, 335, 333, 336, 31, 32, 24, 337, 333, 336, 24, 48, 338, 134, 35, 339, 335, 32, 340, 24, 178, 27, 47, 329, 31, 341, 342, 33, 157, 343, 265, 329, 31, 341, 24, 263, 344, 345, 24, 150, 104, 125, 31, 341, 107, 267, 33, 346, 218, 327, 125, 143, 31, 33, 125, 210, 347, 35, 348, 248, 24, 349, 348, 350, 24, 48, 351, 352, 24, 224, 125, 353, 354, 355, 31, 200, 24, 124, 218, 122, 268, 269, 231, 270, 35, 33, 157, 165, 48, 43, 18, 356, 357, 51, 325, 335, 358, 24, 263, 147, 329, 31, 32, 333, 359, 24, 59, 292, 35, 360, 361, 362, 24, 150, 176, 363, 218, 364, 31, 365, 24, 47, 333, 334, 24, 47, 366, 367, 24, 218, 368, 164, 369, 370, 143, 31, 371, 325, 372, 31, 32, 24, 218, 164, 347, 248, 24, 218, 164, 373, 336, 374, 33, 178, 232, 375, 376, 68, 329, 31, 32, 24, 377, 378, 379, 24, 380, 270, 24, 324, 349, 350, 33, 157, 263, 201, 24, 381, 48, 277, 382, 383, 355, 24, 339, 384, 325, 358, 24, 150, 178, 98, 385, 218, 386, 165, 331, 32, 24, 387, 122, 24, 388, 382, 389, 111, 76, 245, 390, 24, 48, 277, 384, 391, 31, 24, 224, 218, 392, 32, 51, 24, 218, 393, 24, 218, 327, 394, 393, 24, 218, 194, 395, 396, 397, 31, 398, 33, 157, 263, 201, 24, 399, 400, 31, 401, 318, 402, 31, 276, 333, 403, 24, 150, 265, 177, 333, 403, 31, 404, 24, 125, 177, 122, 405, 31, 365, 24, 125, 406, 407, 408, 24, 125, 203, 409, 86, 370, 410, 143, 24, 178, 406, 98, 180, 125, 165, 204, 411, 355, 412, 24, 125, 412, 32, 31, 200, 165, 181, 348, 353, 33, 232, 125, 165, 413, 210, 414, 143, 31, 415, 147, 416, 31, 32, 51, 33, 157, 305, 417, 231, 333, 418, 298, 419, 420, 24, 263, 201] \n",
      " \n",
      " [203, 421, 24, 150, 178, 203, 422, 24, 125, 406, 423, 24, 424, 425, 125, 426, 427, 428, 24, 178, 68, 429, 104, 430, 107, 431, 24, 80, 73, 432, 433, 133, 33, 157, 104, 434, 107, 115, 3, 435, 202, 436, 437, 438, 358, 439, 440, 11, 441, 177, 442, 443, 444, 329, 31, 32, 24, 177, 435, 445, 446, 39, 179, 285, 288, 31, 447, 68, 448, 449, 33, 48, 450, 91, 32, 386, 451, 270, 31, 452, 453, 24, 454, 363, 455, 31, 435, 456, 48, 448, 31, 457, 36, 255, 85, 125, 458, 35, 459, 460, 31, 461, 24, 55, 402, 462, 463, 464, 465, 466, 175, 467, 468, 469, 31, 125, 470, 35, 194, 471, 122, 53, 448, 31, 472, 24, 150, 448, 473, 36, 341, 474, 24, 160, 335, 475, 35, 476, 24, 94, 218, 53, 205, 476, 24, 477, 178, 98, 478, 31, 358, 322, 439, 218, 33, 157, 48, 448, 136, 183, 24, 435, 177, 122, 31, 479, 24, 48, 125, 31, 471, 480, 24, 448, 481, 482, 483, 484, 485, 31, 486, 122, 487, 488, 489, 70, 24, 94, 125, 490, 97, 40, 35, 491, 31, 492, 33, 329, 493, 473, 86, 494, 495, 31, 288, 24, 435, 496, 497, 498, 194, 499, 24, 481, 500, 501, 502, 503, 24, 150, 441, 177, 178, 504, 205, 31, 442, 443, 31, 145, 505, 24, 448, 31, 253, 97, 231, 366, 181, 506, 24, 507, 218, 382, 24, 508, 509, 510, 35, 33, 157, 435, 201, 33, 481, 368, 341, 511, 512, 513, 514, 340, 515, 516, 517, 518, 24, 426, 419, 519, 24, 520, 521, 231, 522, 517, 523, 24, 435, 31, 524, 97, 525, 35, 526, 31, 527, 24, 528, 403, 31, 177, 125, 419, 529, 165, 530, 86, 48, 122, 51, 31, 531, 24, 150, 178, 532, 35, 482, 105, 122, 24, 68, 348, 182, 488, 105, 497, 24, 178, 98, 181, 221, 533, 31, 534, 333, 535, 24, 176, 97, 177, 178, 536, 537, 32, 341, 538, 31, 193, 24, 539, 540, 253, 348, 24, 178, 541, 542, 543, 322, 544, 47, 528, 355, 31, 545, 24, 419, 122, 31, 546, 529, 336, 24, 178, 181, 547, 548, 90, 549, 33, 157, 160, 335, 550, 551, 95, 552, 95, 51, 24, 124, 218, 180, 35, 435, 181, 553, 554, 555, 24, 141, 556, 557, 232, 125, 558, 559, 33, 560, 561, 562, 31, 435, 563, 97, 564, 35, 24, 565, 566, 567, 94, 568, 31, 557, 304, 35, 306, 202, 150, 312, 569, 554, 35, 24, 570, 218, 24, 312, 411, 571, 572, 33, 157, 55, 333, 124, 365, 573, 31, 177, 24, 435, 467, 574, 24, 575, 58, 576, 577, 24, 324, 537, 32, 48, 578, 579, 160, 143, 411, 538, 24, 124, 122, 580, 451, 581, 33, 582, 509, 583, 31, 125, 419, 528, 203, 584, 585, 35, 24, 586, 587, 48, 588, 589, 590, 35, 591, 24, 575, 164, 592, 221, 222, 31, 593, 24, 125, 406, 149, 202, 150, 178, 68, 435, 594, 31, 546, 72, 165]\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_token[0],\"\\n \\n\",ordinal_token[1],\"\\n \\n\",ordinal_token[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8a455-08e1-45c7-aca1-2783e2169f27",
   "metadata": {},
   "source": [
    "3) dataloader需要整理的不止是Decoder-only结构本身需要的数据，而是整个训练过程中必备的数据。因此除了准备架构的输入之外，还要考虑在计算损失过程中必须的真实标签y_true。那真实标签y_true是什么结构呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150bf67-e0e0-471b-b29a-091e1d8248c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "依据现在的数据结构，我们的序列长度seq_len为512，因此Decoder-Only架构的训练模式是：\n",
    "\n",
    "这 👉 xxx1\n",
    "[0]    [1]\n",
    "\n",
    "这是 👉 xxx2\n",
    "[0,1]    [2]\n",
    "\n",
    "这是最 👉 xxx3\n",
    "[0,1,2]    [3]\n",
    "\n",
    "这是最好 👉 xxx4\n",
    "[0,1,2,3]    [4]\n",
    "\n",
    "以此类推……"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d0aad-c095-4024-8541-8d0496294e25",
   "metadata": {},
   "source": [
    "因此在Decoder的训练过程中，我们是依据“逐渐变长的句子前半段”来预测“句子的下一个字”。奇妙的是，虽然大部分人会认为上面的过程是按顺序逐渐发生的，但在Decoder架构中上述所有预测是同步进行的，且在Transformer的计算流程中，**上述的每一次预测都是一个样本**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28d653-1be3-414e-9565-5f23ae3ac45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "样本1:\n",
    "这 👉 xxx1\n",
    "[0]    [1]\n",
    "\n",
    "样本2:\n",
    "这是 👉 xxx2\n",
    "[0,1]    [2]\n",
    "\n",
    "样本3:\n",
    "这是最 👉 xxx3\n",
    "[0,1,2]    [3]\n",
    "\n",
    "样本4:\n",
    "这是最好 👉 xxx4\n",
    "[0,1,2,3]    [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16d519-d954-45c4-a461-49c2d20bfa03",
   "metadata": {},
   "source": [
    "输入数据是——\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th>索引</th><th></th><th>y1</th><th>y2</th><th>y3</th><th>y4</th><th>y5</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>0</td><td>\"sos\"</td><td>0.1821</td><td>0.4000</td><td>0.2248</td><td>0.4440</td><td>0.7771</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>1</td><td>这</td><td>0.1821</td><td>0.4000</td><td>0.2248</td><td>0.4440</td><td>0.7771</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>2</td><td>是</td><td>0.1721</td><td>0.5030</td><td>0.8948</td><td>0.2385</td><td>0.0987</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>3</td><td>最好的</td><td>0.1342</td><td>0.8297</td><td>0.2978</td><td>0.7120</td><td>0.2565</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>4</td><td>时代</td><td>0.1248</td><td>0.5003</td><td>0.7559</td><td>0.4804</td><td>0.2593</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c39d5-e029-4f4a-9b51-85f671d9b360",
   "metadata": {},
   "source": [
    "然而，从Decoder的掩码注意力层中输出的是**经过掩码后**、每一行只携带特定时间段信息的结果$C_{decoder}$：\n",
    "\n",
    "$$\n",
    "C_{decoder} = \\begin{bmatrix}\n",
    "c_{0} & c_{0} & \\ldots & c_{0} \\\\\n",
    "c_{0 \\to 1} & c_{0 \\to 1} & \\ldots & c_{0 \\to 1} \\\\\n",
    "c_{0 \\to 1} & c_{0 \\to 2} & \\ldots & c_{0 \\to 2} \\\\\n",
    "c_{0 \\to 3} & c_{0 \\to 3} & \\ldots & c_{0 \\to 3} \\\\\n",
    "c_{0 \\to 4} & c_{0 \\to 4} & \\ldots & c_{0 \\to 4} \\\\\n",
    "&……\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<font color=\"red\">**这里出于教学目的，省略了特征维度上的脚标。现在你所看到的脚标只代表时间维度/序列长度的维度。**\n",
    "\n",
    "从注意力机制中输出的每行数据、就代表了一个“逐渐变长的句子前半段”，因此每行数据也就对应着一个标签。故而在下面的流程中，真实标签就是[1,2,3,4]这样的序列，也就是原始序列seq[1:] + [0]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d687fc5f-ccf3-4ce6-b900-5aaa35e0a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#兼容Pytorch，我们使用继承自Dataset的类\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 初始化数据集，将传入的数据保存在实例变量data中\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 根据索引i获取数据集中的第i个样本\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0807036a-1e3d-46f5-a5cc-d71b47d9575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义collate_fn函数，用于在DataLoader中对一个batch的数据进行处理\n",
    "def collate_fn(examples):\n",
    "    # 将每个样本的输入部分转换为张量\n",
    "    seq = [torch.tensor(ex) for ex in examples]\n",
    "    y_true = [torch.tensor(ex[1:] + [0]) for ex in examples]\n",
    "    \n",
    "    # pytorch自带的padding工具\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    seq = pad_sequence(seq, batch_first=True)\n",
    "    y_true = pad_sequence(y_true, batch_first=True)\n",
    "    \n",
    "    # 返回处理后的输入和目标\n",
    "    return seq, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18f909e9-a565-489c-879f-3640e43a617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TransformerDataset(ordinal_token)  # 创建数据集\n",
    "dataloader = DataLoader(dataset\n",
    "                        , batch_size=batch_size\n",
    "                        , drop_last = False\n",
    "                        , collate_fn=collate_fn\n",
    "                        , shuffle=False)  # 创建训练数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09d3d809-9a87-4b82-9025-1b50267c05dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 4, 25, 26, 27, 28, 6, 7, 10, 29, 30, 8, 31, 32, 33, 34, 35, 36, 37, 31, 38, 39, 24, 8, 40, 41, 42, 43, 44, 45, 24, 46, 47, 48, 49, 50, 51, 52, 53, 35, 54, 24, 55, 56, 57, 58, 59, 60, 61, 62, 33, 63, 8, 64, 54, 24, 65, 66, 67, 68, 61, 24, 69, 70, 51, 71, 10, 72, 73, 74, 24, 75, 48, 76, 18, 77, 20, 78]\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x[:100])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b988781-b3e7-4dc7-9fe7-39222b33cdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   3,    4,    5,  ...,  259,   31,  138],\n",
      "        [  24,  260,  147,  ...,   24,  263,  201],\n",
      "        [ 203,  421,   24,  ...,  546,   72,  165],\n",
      "        ...,\n",
      "        [  24, 3256,   31,  ...,  366, 3349,   24],\n",
      "        [3350, 1142,  218,  ..., 3262,  546,  419],\n",
      "        [  97,  177, 3409,  ..., 3215,  479,  600]]), tensor([[   4,    5,    6,  ...,   31,  138,    0],\n",
      "        [ 260,  147,  233,  ...,  263,  201,    0],\n",
      "        [ 421,   24,  150,  ...,   72,  165,    0],\n",
      "        ...,\n",
      "        [3256,   31,  445,  ..., 3349,   24,    0],\n",
      "        [1142,  218, 3268,  ...,  546,  419,    0],\n",
      "        [ 177, 3409,   33,  ...,  479,  600,    0]])) \n",
      "\n",
      "\n",
      "seq: \n",
      " tensor([[   3,    4,    5,  ...,  259,   31,  138],\n",
      "        [  24,  260,  147,  ...,   24,  263,  201],\n",
      "        [ 203,  421,   24,  ...,  546,   72,  165],\n",
      "        ...,\n",
      "        [  24, 3256,   31,  ...,  366, 3349,   24],\n",
      "        [3350, 1142,  218,  ..., 3262,  546,  419],\n",
      "        [  97,  177, 3409,  ..., 3215,  479,  600]]) \n",
      "\n",
      "\n",
      "torch.Size([32, 512]) \n",
      "\n",
      "\n",
      "y_true: \n",
      " tensor([[   4,    5,    6,  ...,   31,  138,    0],\n",
      "        [ 260,  147,  233,  ...,  263,  201,    0],\n",
      "        [ 421,   24,  150,  ...,   72,  165,    0],\n",
      "        ...,\n",
      "        [3256,   31,  445,  ..., 3349,   24,    0],\n",
      "        [1142,  218, 3268,  ...,  546,  419,    0],\n",
      "        [ 177, 3409,   33,  ...,  479,  600,    0]]) \n",
      "\n",
      "\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch,\"\\n\\n\") # 第一个batch中的实际数据，包括需要输入的seq与标签y_true\n",
    "    print(\"seq: \\n\", batch[0],\"\\n\\n\") #seq，结构为(batch_size, seq_len)\n",
    "    print(batch[0].shape,\"\\n\\n\")\n",
    "    print(\"y_true: \\n\", batch[1],\"\\n\\n\") #y_true，结构也为(batch_size,seq_len)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403ed5e-630f-4a86-88a9-b16a0c950265",
   "metadata": {},
   "source": [
    "对生成式算法而言，我们不分训练集与测试集，同时我们也不分特征和标签，因为我们是用句子的前半段去预测句子的后半段。在生成式任务中，比如文本生成或语言模型训练，常常采用自回归模型（autoregressive model）来逐步预测序列中的下一个元素。这种情况下，通常不需要明确地划分训练集和测试集，而是通过给定的序列前半部分来预测后半部分，从而进行训练和评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4530cd9-91d6-4b4d-bbef-50295fdb137b",
   "metadata": {},
   "source": [
    "### 3.3.2 Decoder-Only Transformer的架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1715a-fc8a-4015-963f-1bc9fcf38c4e",
   "metadata": {},
   "source": [
    "Decoder-only架构应该包括如下结构：\n",
    "\n",
    "1. **输入层**：输入序列会通过一个嵌入层，将每个词转换为一个向量表示。\n",
    "\n",
    "2. **位置编码**：添加位置编码，以保留序列中词的位置信息，确保模型在处理序列时能够感知到词的位置。\n",
    "\n",
    "3. **Transformer 解码器**：使用多个解码器层堆叠，以逐步生成序列中的下一个词。解码器层通常包括自注意力机制、交叉注意力机制（如果有Memory输入）以及前馈神经网络FFN。\n",
    "\n",
    "4. **输出层**：将解码器的输出表示转换为词汇表中的概率分布，通常通过一个线性层和softmax层来实现，生成最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bc2070f-cd82-4385-8bfa-408e7c593ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#位置编码（同样关系到是否batch_first = True）\n",
    "# 定义PositionalEncoding类，用于为输入添加位置信息\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        #有transpose，代表默认输入数据形状为(seq_len, batch_size, d_model)\n",
    "        #如果输入结构为(batch_size, seq_len, d_model)，则不需要transpose\n",
    "        if batch_first:\n",
    "            pe = pe.unsqueeze(0)\n",
    "        else:\n",
    "            pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        #如果batch_first，则需要截断的是中间的维度\n",
    "        #且用于中间维度截断的维度是seq_len\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:, :x.size(1), :]\n",
    "        else:\n",
    "            #如果没有batch_first，需要截断的是第一个维度\n",
    "            x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d5e1c22-7dad-4dac-a19b-ef1b3f11f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#两大掩码函数\n",
    "def create_padding_mask(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len)\n",
    "    # 创建一个与输入序列形状相同的掩码\n",
    "    padding_mask = (seq == pad_token).float() * -1e9  # (batch_size, seq_len)\n",
    "    return padding_mask\n",
    "\n",
    "def create_look_ahead_mask(seq_len, start_seq=1):\n",
    "    mask = torch.triu(torch.ones((seq_len, seq_len)), diagonal=start_seq)  # 上三角矩阵\n",
    "    mask = mask.float() * -1e9  # 将未来的位置设置为负无穷大\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc00d60a-01c8-4b09-940d-8d7d5f36eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim,\n",
    "                 dim_feedforward=256, num_head=2, num_layers=2,\n",
    "                 dropout=0.1, max_len=1000, activation: str = \"relu\", batch_first=True):\n",
    "        super(DecoderOnlyTransformer, self).__init__()  # 调用父类nn.Module的构造函数\n",
    "        \n",
    "        self.embedding_dim = embedding_dim  # 保存嵌入维度\n",
    "\n",
    "        # 输入，与encoder一致\n",
    "        # 定义嵌入层，将词汇ID映射到embedding表示\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 定义位置编码层，添加位置信息，注意batch_first\n",
    "        self.position_embedding = PositionalEncoding(\n",
    "            hidden_dim, dropout\n",
    "            , max_len, batch_first=batch_first)  \n",
    "        \n",
    "        # 定义一个Transformer解码器层\n",
    "        # 包括带掩码的多头注意力机制、残差链接、Layer Norm以及前馈神经网络\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            embedding_dim, num_head\n",
    "            , dim_feedforward, dropout\n",
    "            , activation\n",
    "            , batch_first=batch_first\n",
    "        )\n",
    "        # 定义多层解码器\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer\n",
    "                                                 , num_layers)\n",
    "        \n",
    "        # 输出层 - 现在是针对每个样本都进行输出\n",
    "        # 将解码器输出映射到词汇表大小\n",
    "        # 此时注意力机制的输出结构为(batch_size, seq_len, input_dim)\n",
    "        # 通常来说我们需要将 seq_len * input_dim\n",
    "        # 不过现在nn.Linear已经可以接纳三维输出\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)  \n",
    "\n",
    "    def forward(self, seq, tgt_mask=None, tgt_key_padding_mask=None):\n",
    "        # 填充掩码\n",
    "        tgt_key_padding_mask = create_padding_mask(seq)\n",
    "        \n",
    "        # 将输入的词汇ID转换为embedding表示\n",
    "        # 添加位置信息        \n",
    "        seq = self.embeddings(seq)\n",
    "        seq = self.position_embedding(seq)\n",
    "        \n",
    "        # 通过Transformer解码器层处理输入\n",
    "        # memory = seq则是普通的掩码注意力机制\n",
    "        # memory = memory则是编码-解码器注意力层\n",
    "        # 对Decoder-only结构来说，只需要一个打包的掩码注意力层即可\n",
    "        output = self.transformer(tgt = seq\n",
    "                                  , memory = seq\n",
    "                                  , tgt_mask=tgt_mask\n",
    "                                  , tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        # 生成式算法，如果linear准备接受三维输入，则无需进行降维索引\n",
    "        # 通过输出层得到分类结果\n",
    "        output = self.output(output)  # 将解码器输出映射到词汇表大小\n",
    "\n",
    "        #log_softmax函数\n",
    "        log_probs = F.log_softmax(output, dim=-1)  # 计算log softmax以获取概率分布\n",
    "        \n",
    "        return log_probs  # 返回log概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b1339-6e32-40b0-88dd-e2d872b5957b",
   "metadata": {},
   "source": [
    "- linear接受高维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4197a268-53f3-454b-a656-05ddd76cce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128  # input_dimension为128\n",
    "linear = nn.Linear(embedding_dim, vocab_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d65768c9-bcec-4cbf-b1cb-59390bfef83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_data = torch.ones(size=(32,512,128),dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "295b3e0f-28ce-46f1-a208-582daac290ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 109839])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(draft_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e96c7c-0dce-4ce3-8f49-20b181938925",
   "metadata": {},
   "source": [
    "- 跑通当前架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f28c128f-4190-40bb-8d39-f35294a7a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_data_2 = torch.ones(size=(32,512),dtype = torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6591ebe4-ac33-4e67-8728-ae330ab59cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128  # input_dimension为128\n",
    "hidden_dim = 128  # 隐藏层的维度为128，同embedding_dim\n",
    "seq_len = 512\n",
    "tgt_mask = create_look_ahead_mask(seq_len)\n",
    "tgt_key_padding_mask = create_padding_mask(draft_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f83ef59-6c09-4f96-ab39-c9d4b0c40f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6600ab13-7c8a-4a1a-a9dc-8400f6b3413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(draft_data_2,tgt_mask,tgt_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16f6f105-ffd7-482b-a3c2-f32a7680bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 109839])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67911ec7-b077-4e94-8023-3295d310a259",
   "metadata": {},
   "source": [
    "- 当前架构的参数量及所占用运存大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36aa9a6d-69df-4ac8-bbf5-a9aa367bcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim, batch_first=True)\n",
    "total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68a9c37a-aa54-4a0a-9dc6-1f795c9851ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28626191\n"
     ]
    }
   ],
   "source": [
    "print(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00984815-638f-4369-b516-406b174e7d8f",
   "metadata": {},
   "source": [
    "28,626,191 个参数大约等于 2862 万个参数。这个参数量相比于现代的大语言模型来说、是一个微型模型。通常在描述语言模型时，我们会使用“百万（M）”或“十亿（B）”作为参数计量单位。\n",
    "\n",
    "- **2862 万**个参数可以表示为 **28.6M**或**0.0286B**的参数。\n",
    "- **2 亿**个参数为 **200M**，也就是**0.2B**。\n",
    "- **2B**（2 Billion）意味着 20 亿个参数，也就是 **2000M**。\n",
    "\n",
    "现在能够对语言进行正常输出、达到一定工业应用程度的最小型的模型大约是2B的参数量，但2B大小模型在语言模型的世界中也属于小模型。普通工业级模型最低标准要有7~12B参数，类似于llama3.1这样能够顺畅与人类交流、与人类同频思考的模型一般会推出三种不同的型号，最小的是llama3.1 8B，居中的是70B，最大的模型是405B。传闻中，GPT4o的参数量有1800B。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8d0c765-bcfa-4156-b78b-c592a9239ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_model = DecoderOnlyTransformer(vocab_size, embedding_dim=512, hidden_dim=512\n",
    "                                     , dim_feedforward = 2048\n",
    "                                     , num_head = 8\n",
    "                                     , num_layers = 6\n",
    "                                     , batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7b896be-14e0-4250-91fd-6c6542e974ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137809167\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in paper_model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65dd2344-c811-4b86-a76d-58aa4ef33960",
   "metadata": {},
   "source": [
    "与Transformer原始论文《Attention is all you need》中设置相同的参数时，我们的Decoder-Only架构有0.13B大小。这样的模型在运行是大约需要多少内存呢？我们可以使用以下公式计算内存占用：\n",
    "\n",
    "<center>内存占用 = 参数数量 × 每个参数的字节数}\n",
    "<br><br>\n",
    "\n",
    "大多数神经网络的参数通常以 32 位浮点数（float32）形式存储，而1个32位浮点数大约会占用4个字节，因此假设每个参数占用 4 个字节。故而有：\n",
    "\n",
    "<center>137,809,167×4字节 = 551,236,668字节 = 551.2MB\n",
    "<br><br>\n",
    "\r\n",
    "因此，这个模型的参数在内存中大约会占用 **551.2 MB**。这个数值仅考虑模型参数本身的大小，实际的内存占用还可能包括模型结构、临时变量、优化器状态等其他部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed34ff7-a63a-43aa-89fc-9e4a469c034c",
   "metadata": {},
   "source": [
    "- 参数量与显存互换的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7624acc8-4267-4d80-93bc-8509a4934071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEstimator:\n",
    "    def __init__(self, num_parameters, bytes_per_parameter=4):\n",
    "        \"\"\"\n",
    "        初始化MemoryEstimator类\n",
    "\n",
    "        参数:\n",
    "        - num_parameters (int): 模型的参数数量\n",
    "        - bytes_per_parameter (int): 每个参数占用的字节数，默认为4（即32位浮点数）\n",
    "        \"\"\"\n",
    "        self.num_parameters = num_parameters\n",
    "        self.bytes_per_parameter = bytes_per_parameter\n",
    "\n",
    "    def calculate_memory(self):\n",
    "        \"\"\"\n",
    "        计算模型的内存占用，仅考虑模型参数本身的大小。\n",
    "\n",
    "        返回:\n",
    "        - memory_in_bytes (int): 参数所占的内存，单位为字节\n",
    "        - memory_in_mb (float): 参数所占的内存，单位为MB\n",
    "        \"\"\"\n",
    "        memory_in_bytes = self.num_parameters * self.bytes_per_parameter\n",
    "        memory_in_mb = memory_in_bytes / (1024 ** 2)  # 将字节转换为MB\n",
    "        return memory_in_bytes, memory_in_mb\n",
    "\n",
    "    def estimate_additional_memory(self, factor=1.5):\n",
    "        \"\"\"\n",
    "        估计模型运行时的总内存占用，考虑模型结构、临时变量、优化器状态等额外开销。\n",
    "\n",
    "        参数:\n",
    "        - factor (float): 用于估算额外内存开销的乘数，默认为1.5\n",
    "\n",
    "        返回:\n",
    "        - estimated_memory_in_bytes (int): 总内存占用，单位为字节\n",
    "        - estimated_memory_in_mb (float): 总内存占用，单位为MB\n",
    "        \"\"\"\n",
    "        base_memory_in_bytes, _ = self.calculate_memory()\n",
    "        estimated_memory_in_bytes = base_memory_in_bytes * factor\n",
    "        estimated_memory_in_mb = estimated_memory_in_bytes / (1024 ** 2)\n",
    "        return estimated_memory_in_bytes, estimated_memory_in_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e45b842a-22bb-43cb-bf9a-4bfabf7a4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例使用\n",
    "# 以 137,809,167 参数的模型为例\n",
    "model_parameters = 137809167\n",
    "estimator = MemoryEstimator(num_parameters=model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21a87f1a-f5ae-4437-affa-6f368b5e46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数内存占用: 551236668 字节 (525.70 MB)\n"
     ]
    }
   ],
   "source": [
    "# 计算基础内存占用\n",
    "memory_in_bytes, memory_in_mb = estimator.calculate_memory()\n",
    "print(f\"模型参数内存占用: {memory_in_bytes} 字节 ({memory_in_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "172713a3-ad05-4e74-908a-a7f3976dbb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估算运行时总内存占用: 826855002.0 字节 (788.55 MB)\n"
     ]
    }
   ],
   "source": [
    "# 估算运行时总内存占用\n",
    "estimated_memory_in_bytes, estimated_memory_in_mb = estimator.estimate_additional_memory()\n",
    "print(f\"估算运行时总内存占用: {estimated_memory_in_bytes} 字节 ({estimated_memory_in_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af7d0f0d-0c1e-4ad1-b922-f801a46301b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估算运行时总内存占用: 486000000000.0 字节 (463485.72 MB)\n"
     ]
    }
   ],
   "source": [
    "# 估算运行时总内存占用\n",
    "model_parameters = 8.1 * 10**10\n",
    "estimator = MemoryEstimator(num_parameters=model_parameters)\n",
    "estimated_memory_in_bytes, estimated_memory_in_mb = estimator.estimate_additional_memory()\n",
    "print(f\"估算运行时总内存占用: {estimated_memory_in_bytes} 字节 ({estimated_memory_in_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ebdc3-b961-439d-b850-fdb4ffa10e7e",
   "metadata": {},
   "source": [
    "### 3.3.3 生成式算法的训练与预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073a2d4-4659-4ee7-b1fb-a286d307c4a6",
   "metadata": {},
   "source": [
    "- **GPU监控流程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee26c26f-730b-47ba-a1a6-bf481f6e9c3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py): started\n",
      "  Building wheel for gputil (setup.py): finished with status 'done'\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=1148b871da5cebf01a047bfa2db4c7cfc329250fcb80faf1ee34179a1d0c3741\n",
      "  Stored in directory: c:\\users\\shuyu\\appdata\\local\\pip\\cache\\wheels\\2b\\b5\\24\\fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (d:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (d:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62775bfc-9af9-4f48-948d-d5ec8df36181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import GPUtil\n",
    "\n",
    "def print_gpu_status():\n",
    "    # 获取所有 GPU 的状态\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU ID: {gpu.id}\")\n",
    "        print(f\"GPU Name: {gpu.name}\")\n",
    "        print(f\"使用率: {gpu.load * 100:.2f}%\")\n",
    "        print(f\"显存使用量: {gpu.memoryUsed}MB\")\n",
    "        print(f\"显存总量: {gpu.memoryTotal}MB\")\n",
    "        print(f\"显存占用率: {gpu.memoryUtil * 100:.2f}%\")\n",
    "        print(f\"温度: {gpu.temperature}°C\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "518078b6-01d3-4f86-8490-4c65f5204bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ID: 0\n",
      "GPU Name: NVIDIA L20\n",
      "使用率: 0.00%\n",
      "显存使用量: 0.0MB\n",
      "显存总量: 49140.0MB\n",
      "显存占用率: 0.00%\n",
      "温度: 28.0°C\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20266f-2242-4566-bad8-d7680176150f",
   "metadata": {},
   "source": [
    "- **超参数设置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39232682-907d-4e21-b0ed-d1ef4a70bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b28674fa-43ed-4abf-b553-d41cec1f83bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   3,    4,    5,  ...,  259,   31,  138],\n",
      "        [  24,  260,  147,  ...,   24,  263,  201],\n",
      "        [ 203,  421,   24,  ...,  546,   72,  165],\n",
      "        ...,\n",
      "        [  24, 3256,   31,  ...,  366, 3349,   24],\n",
      "        [3350, 1142,  218,  ..., 3262,  546,  419],\n",
      "        [  97,  177, 3409,  ..., 3215,  479,  600]]), tensor([[   4,    5,    6,  ...,   31,  138,    0],\n",
      "        [ 260,  147,  233,  ...,  263,  201,    0],\n",
      "        [ 421,   24,  150,  ...,   72,  165,    0],\n",
      "        ...,\n",
      "        [3256,   31,  445,  ..., 3349,   24,    0],\n",
      "        [1142,  218, 3268,  ...,  546,  419,    0],\n",
      "        [ 177, 3409,   33,  ...,  479,  600,    0]]))\n",
      "tensor([[   3,    4,    5,  ...,  259,   31,  138],\n",
      "        [  24,  260,  147,  ...,   24,  263,  201],\n",
      "        [ 203,  421,   24,  ...,  546,   72,  165],\n",
      "        ...,\n",
      "        [  24, 3256,   31,  ...,  366, 3349,   24],\n",
      "        [3350, 1142,  218,  ..., 3262,  546,  419],\n",
      "        [  97,  177, 3409,  ..., 3215,  479,  600]])\n",
      "torch.Size([32, 512])\n",
      "tensor([[   4,    5,    6,  ...,   31,  138,    0],\n",
      "        [ 260,  147,  233,  ...,  263,  201,    0],\n",
      "        [ 421,   24,  150,  ...,   72,  165,    0],\n",
      "        ...,\n",
      "        [3256,   31,  445,  ..., 3349,   24,    0],\n",
      "        [1142,  218, 3268,  ...,  546,  419,    0],\n",
      "        [ 177, 3409,   33,  ...,  479,  600,    0]])\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "#数据\n",
    "for batch in dataloader:\n",
    "    print(batch) # 第一个batch中的实际数据，结构为(batch_size, seq_len)\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca31ad10-f046-4ad2-b6a8-3a912349e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128  # input_dimension为128\n",
    "hidden_dim = 128  # 隐藏层的维度为128，同embedding_dim\n",
    "seq_len = 512\n",
    "num_epochs = 30\n",
    "num_head = 2\n",
    "lr = 0.05\n",
    "tgt_mask = create_look_ahead_mask(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "117edb18-09b1-4049-9760-6096b6f23fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型\n",
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim,\n",
    "                               max_len = seq_len\n",
    "                               , num_head = num_head\n",
    "                               , batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67beb1d2-7e2f-4c23-9011-c9eec47f1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75655863-98f4-4bd2-b1cc-ae21f62565c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0aee7dc5-4e51-443e-b530-aa9723c7f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71d523af-e7de-4331-8334-4f04011fdcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderOnlyTransformer(\n",
       "  (embeddings): Embedding(109839, 128)\n",
       "  (position_embedding): PositionalEncoding()\n",
       "  (transformer): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=128, out_features=109839, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模式\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab077998-e28f-4115-aac5-4dcb8023f439",
   "metadata": {},
   "source": [
    "最初的30个epochs——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2f67475-5d6f-46a2-aa10-487c933fca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Average Loss: 7.941801412216085\n",
      "Epoch 2 completed, Average Loss: 7.544951659954147\n",
      "Epoch 3 completed, Average Loss: 7.499847399477927\n",
      "Epoch 4 completed, Average Loss: 7.507823615674152\n",
      "Epoch 5 completed, Average Loss: 7.50566768330454\n",
      "Epoch 6 completed, Average Loss: 7.4923299322065136\n",
      "Epoch 7 completed, Average Loss: 7.474970719672196\n",
      "Epoch 8 completed, Average Loss: 7.46843152014625\n",
      "Epoch 9 completed, Average Loss: 7.459803669657928\n",
      "Epoch 10 completed, Average Loss: 7.450328501644513\n",
      "Epoch 11 completed, Average Loss: 7.439466245916505\n",
      "Epoch 12 completed, Average Loss: 7.42191742271777\n",
      "Epoch 13 completed, Average Loss: 7.4130392169320825\n",
      "Epoch 14 completed, Average Loss: 7.419463953435026\n",
      "Epoch 15 completed, Average Loss: 7.424558645842091\n",
      "Epoch 16 completed, Average Loss: 7.411503318129786\n",
      "Epoch 17 completed, Average Loss: 7.404833882060272\n",
      "Epoch 18 completed, Average Loss: 7.4143220604650235\n",
      "Epoch 19 completed, Average Loss: 7.409639080628654\n",
      "Epoch 20 completed, Average Loss: 7.404845291415588\n",
      "Epoch 21 completed, Average Loss: 7.403811467404397\n",
      "Epoch 22 completed, Average Loss: 7.402470749735043\n",
      "Epoch 23 completed, Average Loss: 7.412486483719175\n",
      "Epoch 24 completed, Average Loss: 7.398349206179183\n",
      "Epoch 25 completed, Average Loss: 7.390827718949476\n",
      "Epoch 26 completed, Average Loss: 7.385059558792619\n",
      "Epoch 27 completed, Average Loss: 7.383252548066196\n",
      "Epoch 28 completed, Average Loss: 7.38320958851189\n",
      "Epoch 29 completed, Average Loss: 7.380754123460378\n",
      "Epoch 30 completed, Average Loss: 7.385093360547199\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计损失\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #if (batch_idx + 1) % 50 == 0:\n",
    "            #print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "        # 每个 batch 后删除不需要的变量，释放 GPU 内存\n",
    "        del inputs, targets, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    average_loss = total_loss/ len(dataloader)\n",
    "    loss_records.append(average_loss)\n",
    "    print(f\"Epoch {epoch+1} completed, Average Loss: {average_loss}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # 保存模型权重\n",
    "        torch.save(model.state_dict(), f'Decoder_weights_epoch_{epoch+1}.pth')\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa0122-dc00-439b-8ed8-01c816487753",
   "metadata": {},
   "source": [
    "第二个30个epochs——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9503c551-55ea-46eb-bd66-583224b66668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Average Loss: 7.385047359971811\n",
      "Epoch 2 completed, Average Loss: 7.373056102272691\n",
      "Epoch 3 completed, Average Loss: 7.381831797542951\n",
      "Epoch 4 completed, Average Loss: 7.385854531597618\n",
      "Epoch 5 completed, Average Loss: 7.388751844696651\n",
      "Epoch 6 completed, Average Loss: 7.377240844120253\n",
      "Epoch 7 completed, Average Loss: 7.3794955765174715\n",
      "Epoch 8 completed, Average Loss: 7.380100228139106\n",
      "Epoch 9 completed, Average Loss: 7.366091500844387\n",
      "Epoch 10 completed, Average Loss: 7.364723445563916\n",
      "Epoch 11 completed, Average Loss: 7.3687557668875385\n",
      "Epoch 12 completed, Average Loss: 7.365222381440219\n",
      "Epoch 13 completed, Average Loss: 7.363782844796086\n",
      "Epoch 14 completed, Average Loss: 7.373940916250873\n",
      "Epoch 15 completed, Average Loss: 7.378562112517704\n",
      "Epoch 16 completed, Average Loss: 7.380014747973309\n",
      "Epoch 17 completed, Average Loss: 7.373522963744915\n",
      "Epoch 18 completed, Average Loss: 7.375004421006765\n",
      "Epoch 19 completed, Average Loss: 7.37639502973746\n",
      "Epoch 20 completed, Average Loss: 7.382415702011412\n",
      "Epoch 21 completed, Average Loss: 7.387910107113668\n",
      "Epoch 22 completed, Average Loss: 7.395721489230529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 累计损失\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#if (batch_idx + 1) % 50 == 0:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item()}\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 每个 batch 后删除不需要的变量，释放 GPU 内存\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs, targets, outputs, loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计损失\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #if (batch_idx + 1) % 50 == 0:\n",
    "            #print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "        # 每个 batch 后删除不需要的变量，释放 GPU 内存\n",
    "        del inputs, targets, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    average_loss = total_loss/ len(dataloader)\n",
    "    loss_records.append(average_loss)\n",
    "    print(f\"Epoch {epoch+1} completed, Average Loss: {average_loss}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # 保存模型权重\n",
    "        torch.save(model.state_dict(), f'Decoder_weights_epoch_{epoch+31}.pth')\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eecd83fa-b668-4120-9340-d567cb9777fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型权重\n",
    "\n",
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim,\n",
    "                               max_len = seq_len\n",
    "                               , num_head = num_head\n",
    "                               , batch_first=True)\n",
    "\n",
    "checkpoint_path = 'Decoder_weights_epoch_40.pth'  # 替换为你的模型权重路径\n",
    "model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d0079df-5c8a-46a5-aa3c-773a0aa07851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderOnlyTransformer(\n",
       "  (embeddings): Embedding(100300, 128)\n",
       "  (position_embedding): PositionalEncoding()\n",
       "  (transformer): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=128, out_features=100300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9016577e-e383-4c61-a8d7-960b4cf2ece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Loss')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(loss_records) + 1), loss_records, marker='o', linestyle='-', color='b')\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415a86b-8264-4d6b-9386-82e99033e5f1",
   "metadata": {},
   "source": [
    "- **测试流程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3a4c308f-9ae1-4284-a9ae-5d71fb020038",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r\"DLdata/cnews_test_sampled.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f0565af1-cb69-43ee-8801-3b80f67fe7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_file(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "094fa850-2bbb-4afd-94c2-f7d396daffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总字符数和样本数\n",
    "cal = calculate_stats(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5cd877ed-2b08-4540-89b4-6c273900c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 4848962\n",
      "样本数量: 5000\n",
      "平均每篇文章的字数: 969.7924\n",
      "最长句子的字数:14720\n",
      "最短句子的字数:13\n",
      "句子长度的25%分位数:428.75\n",
      "句子长度的50%分位数:734.0\n",
      "句子长度的75%分位数:1177.25\n",
      "句子长度的90%分位数:1951.1000000000004\n"
     ]
    }
   ],
   "source": [
    "cal.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b4e2e00d-2d36-46b3-999b-e411e3bad055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试数据，无需进行段落重组等等操作，只需要进行分词和编码即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9becb743-3dff-4531-9ea0-ad3616d4d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词\n",
    "test_split = [jieba.lcut(sentence) for sentence in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1dc1c847-0083-4a87-9b51-26ed6d15f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加起始符号与终止符号\n",
    "processed_test_data = []\n",
    "\n",
    "for content in test_split:\n",
    "    content = [\"<sos>\"] + content + [\"<eos>\"]\n",
    "    processed_test_data.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9c6cd7fa-cfce-4d76-82cb-deebc4e6892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#无需重组，直接使用训练集做好的词汇表进行编码\n",
    "ordinal_test_token = []\n",
    "for tokens in processed_test_data:\n",
    "    ordinal_test_token.append(vocab.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "48c12d3d-57bf-4ead-af83-e7d82d20eb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_test_token.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0c8cea82-2083-47f8-8ce4-9d8782d090f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 163, 2115, 0, 867, 0, 1272, 8679, 0, 417, 928, 2360, 0, 2413, 13647, 96, 417, 8, 9, 927, 928, 0, 20, 0, 781, 159, 0, 875, 780, 0, 3823, 2405, 0, 0, 225, 23, 4059, 359, 0, 0, 1135, 25233, 25234, 0, 0, 0, 23, 839, 357, 0, 163, 2338, 2115, 0, 187, 0, 3612, 867, 3257, 121, 0, 379, 111, 0, 4513, 1306, 225, 16352, 0, 0, 50, 0, 0, 887, 1912, 14477, 7008, 0, 1380, 0, 0, 2413, 9040, 0, 0, 0, 1892, 0, 0, 824, 1250, 617, 22438, 0, 0, 0, 0, 0, 27586, 0, 1446, 0, 2413, 0, 0, 0, 0, 567, 249, 0, 7573, 0, 381, 0, 0, 1450, 567, 249, 340, 16511, 0, 0, 1466, 0, 95, 205, 0, 0, 0, 0, 0, 0, 567, 249, 1566, 0, 0, 2116, 1176, 0, 2115, 0, 0, 69937, 0, 0, 166, 0, 0, 1380, 0, 148, 14344, 0, 0, 0, 0, 0, 0, 337, 22280, 0, 2945, 0, 1013, 6380, 1047, 0, 246, 17667, 0, 0, 0, 480, 6070, 340, 0, 2413, 73051, 0, 0, 0, 166, 148, 0, 14340, 0, 443, 323, 0, 1013, 51, 0, 1650, 9127, 2413, 0, 0, 5503, 0]\n"
     ]
    }
   ],
   "source": [
    "print(ordinal_test_token[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bcee230b-79f1-4d7d-8823-22e0b0311542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def top_k_sampling(logits, top_k=10):\n",
    "    \"\"\"\n",
    "    从 logits 中进行 top-k 采样，返回采样到的标记索引。\n",
    "    \"\"\"\n",
    "    # 获取 logits 的最后一个时间步的输出\n",
    "    logits = logits[:, -1, :]  # 取最后一个时间步的 logits\n",
    "    \n",
    "    # 进行 top-k 筛选\n",
    "    top_k_logits, top_k_indices = torch.topk(logits, top_k, dim=-1)\n",
    "    \n",
    "    # 对 top-k 的 logits 进行 softmax，然后从中采样\n",
    "    probabilities = torch.nn.functional.softmax(top_k_logits, dim=-1)\n",
    "    next_token = torch.multinomial(probabilities, 1)  # 从概率分布中采样\n",
    "    \n",
    "    # 获取原始 logits 对应的索引\n",
    "    next_token = top_k_indices.gather(-1, next_token)\n",
    "    \n",
    "    return next_token.item()  # 返回标记索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c4a35d0f-6ba4-4d50-b6af-b2a2a9100366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, initial_input, eos_token_id = 2, max_length=100, device='cuda'):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    \n",
    "    # 将初始输入移到 GPU 上，并添加 batch 维度\n",
    "    input_seq = torch.tensor(initial_input).unsqueeze(0).to(device)  \n",
    "    \n",
    "    generated_seq = initial_input  # 初始化生成的序列\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # 预测下一个token\n",
    "            # 首先，model和训练时的模式一样，还是会针对每一个token都输出下一个token\n",
    "            # 我们的每一个token依然会因为注意力机制的缘故、由单一样本转变为“段落”\n",
    "            # 只有最后一行、也就是最后一个“段落”所输出的内容对我们才有意义\n",
    "            # 因为最后一行代表了整个句子的信息，依据整个句子预测出后一个字\n",
    "            log_probs = model(input_seq)\n",
    "\n",
    "            # 使用 top-k 采样策略从 log_probs 中采样下一个标记\n",
    "            next_token = top_k_sampling(log_probs, top_k=300)\n",
    "            \n",
    "            # 将生成的标记添加到序列中\n",
    "            generated_seq.append(next_token)\n",
    "            \n",
    "            # 更新输入序列，并将其移到 GPU 上\n",
    "            input_seq = torch.tensor(generated_seq).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 如果生成了 <eos> 标记，则停止\n",
    "            if next_token == eos_token_id:  # eos_token_id 是 <eos> 的标记\n",
    "                break\n",
    "    \n",
    "    return generated_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4ac3b53a-9510-4771-8d20-d01339ebc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sentence_tokens_to_ids(sentence,vocab_table):\n",
    "    \"\"\"\n",
    "    该函数只接纳一个句子作为输入，不接纳双层的列表（如一个列表中包含多个句子，每个句子单独做为一个列表）\n",
    "    \"\"\"\n",
    "    #检查是否为嵌套的列表\n",
    "    if isinstance(sentence, list) and all(isinstance(i, list) for i in sentence):\n",
    "        raise ValueError(\"该结构为嵌套列表、包含多个句子，当前函数只能接受单一句子\")\n",
    "\n",
    "    #分词\n",
    "    test_split = jieba.lcut(sentence)\n",
    "    #添加起始符号与终止符号\n",
    "    content = [\"<sos>\"] + test_split + [\"<eos>\"]\n",
    "    #直接使用训练集做好的词汇表进行编码\n",
    "    return vocab_table.convert_tokens_to_ids(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "91dcb395-4527-4860-8c84-3b2f65ae3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sentence_ids_to_tokens(content,vocab_table):\n",
    "    content = vocab_table.convert_ids_to_tokens(content)\n",
    "    remove_tokens = {'<sos>', '<eos>', '<unk>'}\n",
    "    result = ''.join([token for token in content if token not in remove_tokens])\n",
    "    return print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "07b35bad-fea4-4535-b50f-2773d2929cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sentence_test(sentence,vocab_table=vocab,model=model):\n",
    "    content = one_sentence_tokens_to_ids(sentence,vocab_table)\n",
    "    print(content)\n",
    "    generate_seq = generate_sequence(model,content)\n",
    "    print(generate_seq)\n",
    "    return one_sentence_ids_to_tokens(generate_seq,vocab_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c575528f-a152-4ebf-b525-85debb97cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = ordinal_test_token[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b2b91388-747e-416f-ad4e-41c53371e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos>三次冲突<unk>5<unk>遭驱逐<unk> 湖人悍将<unk>特里推倒教练 新浪体育讯洛杉矶湖人<unk>主场<unk>28分<unk>优势击败<unk>达拉斯小牛<unk><unk>一场比赛胜负更<unk><unk>感到血脉喷张<unk><unk><unk>比赛第四节发生<unk>'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(vocab.convert_ids_to_tokens(initial_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "db254e06-6a91-46e8-8429-5b02039eb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_seq = generate_sequence(model,initial_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bb8bbf42-5b01-4477-889c-b92029d0cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 163, 2115, 0, 867, 0, 1272, 8679, 0, 417, 928, 2360, 0, 2413, 13647, 96, 417, 8, 9, 927, 928, 0, 20, 0, 781, 159, 0, 875, 780, 0, 3823, 2405, 0, 0, 225, 23, 4059, 359, 0, 0, 1135, 25233, 25234, 0, 0, 0, 23, 839, 357, 0, 1631, 0, 878, 991, 17798, 19224, 226, 0, 0, 0, 0, 0, 0, 0, 663, 0, 258, 0, 37, 0, 0, 0, 0, 1, 38860, 0, 0, 34778, 0, 0, 2335, 0, 43930, 173, 0, 9097, 0, 6262, 0, 695, 0, 0, 0, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "76090054-2a6b-4e28-acfd-e831f2e2b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三次冲突5遭驱逐 湖人悍将特里推倒教练 新浪体育讯洛杉矶湖人主场28分优势击败达拉斯小牛一场比赛胜负更感到血脉喷张比赛第四节发生经济影响24旗下消费好交易带来中今年以来业绩明年信托世界下跌预计年\n"
     ]
    }
   ],
   "source": [
    "one_sentence_ids_to_tokens(generate_seq,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "25c69f2e-e1fd-409d-a0ef-125e980f943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 163, 2115, 0, 867, 16, 1272, 8679, 0, 417, 928, 2360, 2413, 13647, 96, 2]\n",
      "[1, 163, 2115, 0, 867, 16, 1272, 8679, 0, 417, 928, 2360, 2413, 13647, 96, 2, 0, 1035, 86, 0, 0, 47894, 1631, 47897, 0, 2300, 0, 38320, 0, 0, 0, 673, 37, 40368, 0, 0, 0, 17452, 0, 4530, 0, 2]\n",
      "三次冲突5体育遭驱逐 湖人悍将特里推倒教练去年经历银行卡经济信用卡发展增长率到期中央行股票减少\n"
     ]
    }
   ],
   "source": [
    "one_sentence_test(\"三次冲突!5体育遭驱逐! 湖人悍将特里推倒教练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e2320457-d282-421a-be78-0dddf445c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14041, 14060, 0, 2]\n",
      "[1, 14041, 14060, 0, 2, 0, 0, 0, 0, 997, 1, 653, 16715, 0, 1, 0, 9620, 0, 2]\n",
      "你好模型经理依然基金单位\n"
     ]
    }
   ],
   "source": [
    "one_sentence_test(\"你好模型！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302af06-ff02-4f7f-bab7-c246d37c3698",
   "metadata": {},
   "source": [
    "- **更多改进策略**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fab049-2367-43eb-a7cb-30964953b8c6",
   "metadata": {},
   "source": [
    "目前来看，模型存在“胡说八道”现象，出现这种现象的原因可能涉及多个因素，包括训练不足、数据集质量、模型架构或生成策略等。让我们逐步分析这些可能性，并讨论如何应对。\n",
    "\n",
    "1. **训练不足**\n",
    "   - **Epoch 数量不足**：如果模型尚未充分训练，它可能还没有完全掌握如何生成自然的、非重复的文本。增加训练的 epoch 数量可能有助于模型更好地学习数据中的语言模式和结构。\n",
    "   - **数据量不足**：如果训练数据集太小，模型可能会过度拟合训练数据，导致在生成时出现重复的现象。增加数据量可以为模型提供更多样化的输入，帮助它更好地泛化。\n",
    "\n",
    "   **改进建议**：\n",
    "   - 尝试增加 epoch 数量，并观察模型的验证损失和生成质量是否有改善。\n",
    "   - 如果可能，收集更多的数据或使用数据增强技术来扩充训练集。\n",
    "\n",
    "2. **数据集的质量**\n",
    "   - **重复的数据**：如果训练数据集中存在大量重复的句子或标记，模型可能会倾向于生成重复内容。\n",
    "   - **标点符号的过度使用**：如果训练数据中过于频繁地使用某个标点符号（如逗号），模型可能会学习到这种模式，并在生成时过度使用该符号。\n",
    "\n",
    "   **改进建议**：\n",
    "   - 清理数据集，去除重复的内容，或者平衡数据集中的不同类型内容，确保模型能够学习到多样化的语言模式。\n",
    "   - 检查训练数据中标点符号的分布，确保它们不会过度出现，从而避免模型过度学习这些标记。\n",
    "\n",
    "4. **模型的架构和参数调整**\n",
    "   - **模型容量不足**：如果模型的参数量不足，它可能无法有效捕捉复杂的语言模式，从而在生成时重复内容。\n",
    "   - **学习率设置**：学习率过高或过低都会影响模型的学习效果。适当调整学习率，确保模型能有效学习而不过拟合。\n",
    "\n",
    "   **改进建议**：\n",
    "   - 考虑增加模型的容量（如增加层数或注意力头的数量），以增强模型的表达能力。\n",
    "   - 调整学习率，观察对模型学习效果的影响。\n",
    "\n",
    "5. **过拟合问题**\n",
    "   - **过拟合**：如果模型过度拟合训练数据，它可能会在生成时表现为重复或僵化的输出。引入正则化技术，如 dropout 或 L2 正则化，可以缓解过拟合问题。\n",
    "\n",
    "   **改进建议**：\n",
    "   - 引入或增加 dropout 层的比例，避免模型过度依赖训练数据。\n",
    "   - 通过增加数据量或使用更强的正则化，来改善模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d4a68-b049-49a9-be59-eadcd8271bba",
   "metadata": {},
   "source": [
    "### 3.3.4 【选学】生成式模型的改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35a59b-9e8e-4571-acbd-9973b77f6a6a",
   "metadata": {},
   "source": [
    "**在视频讲解时，没有对改进后的模型进行训练。在课件中，对这部分模型进行了补充训练。**\n",
    "\n",
    "首先，我对模型做出了以下的改进——\n",
    "\n",
    "1. 增加数据量并改变数据组成，将原本每个领域抽样500（总样本量5000）、修改为从各个领域抽样2000（总样本量2w）\n",
    "2. 增加模型复杂度，将原本0.02B参数的模型增加到1.3B（使用Transformer原始论文中的Decoder-Only结构）\n",
    "3. 不再按照每篇新闻、而是按照句子进行分割，为每个句子的前面添加<sos>，句子后方添加<eos>\n",
    "4. 筛选过短的句子，将20字以下的句子全部筛出\n",
    "5. 没有再使用标点符号筛选和停用词，相对的，对token进行了词频统计、并对词频过高的词加以权重惩罚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977553fb-cf26-4a84-8154-f81288af911b",
   "metadata": {},
   "source": [
    "> 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf52946f-34c7-4fb3-a808-4f6b1f5fb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72280078-9f67-4bd7-9b0c-1d9158bd174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                label, content = parts\n",
    "                data.append(content) #只要content，不要label\n",
    "    return data\n",
    "\n",
    "import numpy as np\n",
    "class calculate_stats:\n",
    "    def __init__(self,data):\n",
    "        self.total_samples = len(data)\n",
    "        self.len_ = []\n",
    "        for content in data:\n",
    "            self.len_.append(len(content))\n",
    "\n",
    "        self.lower_quartile = np.percentile(self.len_, 25)\n",
    "        self.median = np.median(self.len_)\n",
    "        self.upper_quartile = np.percentile(self.len_, 75)\n",
    "        self.percentile_90 = np.percentile(self.len_, 90)\n",
    "\n",
    "    def stats(self):\n",
    "        # 输出结果\n",
    "        print(f\"总字数: {sum(self.len_)}\")\n",
    "        print(f\"样本数量: {self.total_samples}\")\n",
    "        print(f\"平均每篇文章的字数: {sum(self.len_)/self.total_samples}\")\n",
    "        print(f\"最长句子的字数:{max(self.len_)}\")\n",
    "        print(f\"最短句子的字数:{min(self.len_)}\")\n",
    "        print(f\"句子长度的25%分位数:{self.lower_quartile}\")\n",
    "        print(f\"句子长度的50%分位数:{self.median}\")\n",
    "        print(f\"句子长度的75%分位数:{self.upper_quartile}\")\n",
    "        print(f\"句子长度的90%分位数:{self.percentile_90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec985944-d40d-49c6-bdab-71f82a8d0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'DLdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39552294-90b7-491b-85d0-60a07126c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(PATH,\"cnews.train.txt\")\n",
    "                         , sep=\"\\t\", names = [\"label\",\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d901e322-c48b-4806-a4dd-438cb9e98fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1243/2812097312.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = train_data.groupby('label').apply(lambda x: x.sample(n=2000)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to DLdata/cnews_train_sampled_2000.txt\n"
     ]
    }
   ],
   "source": [
    "# 随机抽样 - 训练集\n",
    "np.random.seed(1412)\n",
    "sampled_df = train_data.groupby('label').apply(lambda x: x.sample(n=2000)).reset_index(drop=True)\n",
    "\n",
    "# 保存为txt文件\n",
    "output_file_path = os.path.join(PATH,\"cnews_train_sampled_2000.txt\")\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in sampled_df.iterrows():\n",
    "        f.write(f\"{row['label']}\\t{row['content']}\\n\")\n",
    "\n",
    "print(f\"Sampled data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ef5b08-9dd1-4efa-bc91-6ca522aba0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "file_path = r\"DLdata/cnews_train_sampled_2000.txt\"\n",
    "\n",
    "# 读取数据\n",
    "data = read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e905d3c-9e82-4734-b86a-78473f983e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 samples: ['新浪正在视频直播尼克斯vs魔术 魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？(新体)[视频直播室] [视频直播室-教育网专用] [图文直播室]', '弗老大同意终止合同 高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。北京队助理教练袁超对新华社说，“弗朗西斯下午来到首钢体育馆，告诉球队，他已经决定离开了。”33岁的弗朗西斯在上一轮对阵江苏队的比赛中，没有能出场，他在中场休息时间无故离开了更衣室。在赛后的新闻发布会上，闵鹿蕾确认了弗朗西斯中场离开的消息，并且说“这是我第一次看到有球员在比赛期间离开的。”闵鹿蕾的一番话，更加加剧了弗朗西斯离开北京队的可能性，而且他在25号缺席了球队的训练，原因是要和家里人度过圣诞节，他在接受采访时候表示：“我没有无故不训练，我给教练打过招呼了，他也答应了。”袁超在接受新华社采访时候，终于说出了今天谈判的进展，“我今天早上和弗朗西斯谈了谈关于他中场离开和圣诞节不训练的事儿，我告诉他，为了球队的利益，我们想让他离开。当时他在会谈中没有给我一个明确的答复。”“但是，当他下午出现在首钢训练馆中的时候，他说他已经准备好要离开了。”袁超说。无论北京俱乐部还是弗朗西斯，都希望双方有个圆满的结局。过去的两周，弗朗西斯一共为北京打了4场比赛，场均3分钟内得到0.5分，0.7个篮板，这和昔日的三次NBA全明星队员相比，确实相差甚远。俱乐部做出这样的决定，或许对双方都有好处。(FRANK)']\n"
     ]
    }
   ],
   "source": [
    "# 查看前2个样本\n",
    "print(f\"First 2 samples: {data[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef46104d-4408-4040-87ef-7f6254f9c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfd9415-a2a4-41f1-8582-afaac01aba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总字符数和样本数\n",
    "cal = calculate_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf40477-39cd-4194-acac-1a51fd61bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 18272972\n",
      "样本数量: 20000\n",
      "平均每篇文章的字数: 913.6486\n",
      "最长句子的字数:27467\n",
      "最短句子的字数:14\n",
      "句子长度的25%分位数:345.0\n",
      "句子长度的50%分位数:682.0\n",
      "句子长度的75%分位数:1150.25\n",
      "句子长度的90%分位数:1894.0\n"
     ]
    }
   ],
   "source": [
    "cal.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf2790-4fa5-4a58-b24d-86fa436ddbbb",
   "metadata": {},
   "source": [
    "> 句子分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05bbf1e3-e251-422f-8fc3-956355281ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "def sentence_split(text):\n",
    "    sentence_separators = ['。', '！', '？', '；', '…', '：','”',' ',]\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for i, char in enumerate(text):\n",
    "        if char in sentence_separators:\n",
    "            sentences.append(text[start:i + 1])\n",
    "            start = i + 1\n",
    "    if start < len(text):\n",
    "        sentences.append(text[start:])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a00839a-dbd2-4ab6-b856-8cf8daf71a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新浪正在视频直播尼克斯vs魔术 ',\n",
       " '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。',\n",
       " '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？',\n",
       " '(新体)[视频直播室] ',\n",
       " '[视频直播室-教育网专用] ',\n",
       " '[图文直播室]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd97fa5-2955-442a-9817-396ccb89c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#句子降维\n",
    "sentence_splited = [sentence_split(sentences) for sentences in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d501446-faf1-4e7c-9d93-7f17b36b4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['新浪正在视频直播尼克斯vs魔术 ', '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。', '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。', '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。', '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？', '(新体)[视频直播室] ', '[视频直播室-教育网专用] ', '[图文直播室]']\n"
     ]
    }
   ],
   "source": [
    "for item in sentence_splited:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df0b34ae-419c-4c51-bc2f-3c2c28f1971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = [item for sublist in sentence_splited for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405e2ce5-0a7a-400d-9ff1-8f7008991821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新浪正在视频直播尼克斯vs魔术 ',\n",
       " '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。',\n",
       " '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？',\n",
       " '(新体)[视频直播室] ',\n",
       " '[视频直播室-教育网专用] ',\n",
       " '[图文直播室]',\n",
       " '弗老大同意终止合同 ',\n",
       " '高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e94366c-0b5f-4f8f-9e2a-bf07067e0e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617810"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_list.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc778d-67fa-42e5-9e8f-ce12976a966b",
   "metadata": {},
   "source": [
    "> 句子长度筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b511ea96-4e01-4945-b1b5-999c253d523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences_by_length(sentences, min_len, max_len):\n",
    "    \"\"\"\n",
    "    筛选出字数超过指定最小长度的所有句子。\n",
    "\n",
    "    参数：\n",
    "    sentences (list of str): 输入的句子列表。\n",
    "    min_length (int): 最小字数长度。\n",
    "\n",
    "    返回：\n",
    "    List[str]: 筛选后的句子列表。\n",
    "    \"\"\"\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(sentence) > min_len and len(sentence) < max_len]\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c2e0a87-7b13-4200-ae6e-178737a5686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选掉过短的句子\n",
    "filtered_data = filter_sentences_by_length(merged_list,50,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ed5421-c2bc-4aae-8e29-dec564984394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110887"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74366589-583f-4012-b090-fab4a513ccf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。',\n",
       " '在赛后的新闻发布会上，闵鹿蕾确认了弗朗西斯中场离开的消息，并且说“这是我第一次看到有球员在比赛期间离开的。',\n",
       " '闵鹿蕾的一番话，更加加剧了弗朗西斯离开北京队的可能性，而且他在25号缺席了球队的训练，原因是要和家里人度过圣诞节，他在接受采访时候表示：',\n",
       " '袁超在接受新华社采访时候，终于说出了今天谈判的进展，“我今天早上和弗朗西斯谈了谈关于他中场离开和圣诞节不训练的事儿，我告诉他，为了球队的利益，我们想让他离开。',\n",
       " '过去的两周，弗朗西斯一共为北京打了4场比赛，场均3分钟内得到0.5分，0.7个篮板，这和昔日的三次NBA全明星队员相比，确实相差甚远。',\n",
       " '他让整个世界都不同了新浪体育讯北京时间1月16日(美国当地时间1月15日)消息，休斯敦火箭客场挑战亚特兰大老鹰，火箭克服了种种不利因素，最终以112-106战胜了对手。',\n",
       " '和昨天的怒批裁判不同，今天阿帅开起了记者的玩笑，对《休斯敦纪实报》记者费根说，“你跟队报道比赛，你告诉我(赢球的)原因吧。',\n",
       " '对于今天的比赛，阿德尔曼总结道，“我们过去两年，我告诉他们，应该坚持下去，我们有连续赢得比赛的潜力，我们需要像今晚一样终结比赛，今天大家都很努力，阿隆今天打出了一场很好的比赛，手感很好，在昨晚经历了那样一场比赛后，我为他们今晚的表现骄傲。']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3ae70-ec41-42c4-8aea-3941308ffc56",
   "metadata": {},
   "source": [
    "> 分词、起始符号、终止符号、分chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c8ee696-7c69-49e2-a493-7a6ebd144342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.674 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "#进行分词，添加起始符号与终止符号\n",
    "data_split = [jieba.lcut(sentence) for sentence in filtered_data]\n",
    "\n",
    "#为现有的句子添加起始符号与终止符号\n",
    "processed_data = []\n",
    "\n",
    "for content in data_split:\n",
    "    content = [\"<sos>\"] + content + [\"<eos>\"]\n",
    "    processed_data.append(content)\n",
    "\n",
    "def merge_and_chunk(data, chunk_size):\n",
    "    \"\"\"\n",
    "    将所有嵌套列表合并为一个长列表，然后按指定大小分块。\n",
    "    \n",
    "    参数：\n",
    "    data (list of list of str): 输入的嵌套字符串列表。\n",
    "    chunk_size (int): 每个块的最大大小。\n",
    "    \n",
    "    返回：\n",
    "    list of list of str: 分块后的字符串列表。\n",
    "    \"\"\"\n",
    "    # 合并所有列表为一个长列表\n",
    "    merged_list = []\n",
    "    for sublist in data:\n",
    "        merged_list.extend(sublist)\n",
    "    \n",
    "    # 通过索引的方式，按指定大小分块\n",
    "    chunks = [merged_list[i:i + chunk_size] for i in range(0, len(merged_list), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "chunks = merge_and_chunk(processed_data,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b8d95d-dc43-4b2a-94be-5e1040c7d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '摆脱', '了', '赛季', '初', '的', '低迷', '之后', '，', '尼克斯', '打出', '14', '胜', '1', '负', '战绩', '，', '最近', '他们', '在', '圣诞', '大战', '中', '又', '战胜', '了', '公牛', '，', '不过', '随后', '一战', '却', '再次', '被', '热火', '打败', '。', '<eos>', '<sos>', '如今', '尼克斯', '两胜', '公牛', '，', '两败', '于', '凯尔特人', '和', '热火', '，']\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40bbbc-3752-44b2-a664-70e099988496",
   "metadata": {},
   "source": [
    "> 建词汇表、编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3963a87-fdea-43cf-8691-a5ae382536da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#词频统计\n",
    "from collections import Counter\n",
    "\n",
    "flattened_data = [word for sublist in chunks for word in sublist]\n",
    "\n",
    "# 统计词频\n",
    "word_counts = Counter(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88832c9a-6076-48c5-850c-18cf60d0cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，: 386450\n",
      "的: 266212\n",
      "<sos>: 110887\n",
      "<eos>: 110887\n",
      "。: 92382\n",
      "、: 61295\n",
      "在: 57557\n",
      "了: 44477\n",
      "是: 41607\n",
      "和: 33638\n",
      "也: 22747\n",
      "有: 21299\n",
      "》: 19648\n",
      "《: 19477\n",
      "中: 15748\n",
      "都: 15303\n",
      "“: 14289\n",
      "月: 14075\n",
      "): 13909\n",
      "他: 13758\n",
      "将: 13711\n",
      "年: 13515\n",
      "为: 13499\n",
      "我们: 13434\n",
      "(: 13358\n",
      "对: 13252\n",
      "我: 12986\n",
      "一个: 12655\n",
      "就: 12538\n",
      "上: 12490\n"
     ]
    }
   ],
   "source": [
    "# 打印词频最高的前100个词\n",
    "for word, freq in word_counts.most_common(30):\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55a3bdd6-023c-468d-be9d-14b28f5a62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将高频词保存为列表，将这些词的频率也保存为列表\n",
    "high_freq_word = []\n",
    "high_freq = []\n",
    "for word, freq in word_counts.most_common(100):\n",
    "    high_freq_word.append(word)\n",
    "    high_freq.append(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac4e24ac-61e9-494c-aa37-6240e85968ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将所有的词频保存成列表，绘制频率分布图\n",
    "all_freq = list(word_counts.values())\n",
    "all_freq.sort()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 绘制直方图\n",
    "# 绘制概率密度图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(all_freq, color='blue', fill=True)\n",
    "plt.title('Log-Transformed Frequency Density of Values')\n",
    "plt.xlabel('Log(Value + 1)')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8bd6a0f-3a8e-4a4c-8aba-eb764618a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"\n",
    "    可以同时接纳Token和text两种类型的数据\n",
    "    对原始文字数据，调用build方法，进行分词、完成预处理、完成词频筛选\n",
    "    对Token数据，使用init中的流程，完成添加未知词、词汇表构建并根据词汇表进行编码\n",
    "    建好词汇表后，再调用单独的方法来进行编码\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = [\"<unk>\"] + tokens \n",
    "            if \"<sos>\" not in tokens:\n",
    "                tokens = [\"<sos>\"] + tokens\n",
    "            if \"<eos>\" not in tokens:\n",
    "                tokens = [\"<eos>\"] + tokens\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def build(cls, text\n",
    "              , min_freq = 1\n",
    "              , stopwords = set([\"的\", \"和\", \"了\", \"在\", \"是\", \"就\", \"不\", \"也\", \"有\", \"但\"])\n",
    "              , preprocessing=False\n",
    "              , reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for tokens in text:\n",
    "            if preprocessing:\n",
    "                #去除标点符号\n",
    "                tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
    "                #去除停用词\n",
    "                tokens = [token for token in tokens if token and token not in stopwords]\n",
    "            #词频筛选\n",
    "            for token in tokens:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\", \"<sos>\", \"<eos>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c2c72b5-2ffd-43e4-8327-89f9b8298bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.build(chunks,min_freq=1\n",
    "                   ,preprocessing = False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f704840-22b0-4e90-a21e-c8b6b01284d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_token = []\n",
    "for tokens in chunks:\n",
    "    ordinal_token.append(vocab.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f26748a-59d1-4a32-9c65-db1fd27bea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字数: 4896774\n",
      "样本数量: 9565\n",
      "平均每篇文章的字数: 511.94709879769994\n",
      "最长句子的字数:512\n",
      "最短句子的字数:6\n",
      "句子长度的25%分位数:512.0\n",
      "句子长度的50%分位数:512.0\n",
      "句子长度的75%分位数:512.0\n",
      "句子长度的90%分位数:512.0\n"
     ]
    }
   ],
   "source": [
    "cal = calculate_stats(ordinal_token)\n",
    "cal.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272a4dc-d0e7-45e5-aace-f4c46d3d44f0",
   "metadata": {},
   "source": [
    "> 架构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da2223ee-3150-472a-a919-40b507963034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "363c3502-3830-4a86-ad87-eca12b1461b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 初始化数据集，将传入的数据保存在实例变量data中\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 根据索引i获取数据集中的第i个样本\n",
    "        return self.data[i]\n",
    "\n",
    "# 定义collate_fn函数，用于在DataLoader中对一个batch的数据进行处理\n",
    "def collate_fn(examples):\n",
    "    # 将每个样本的输入部分转换为张量\n",
    "    seq = [torch.tensor(ex) for ex in examples]\n",
    "    y_true = [torch.tensor(ex[1:] + [0]) for ex in examples]\n",
    "    \n",
    "    # pytorch自带的padding工具\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    seq = pad_sequence(seq, batch_first=True)\n",
    "    y_true = pad_sequence(y_true, batch_first=True)\n",
    "    \n",
    "    # 返回处理后的输入和目标\n",
    "    return seq, y_true\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset = TransformerDataset(ordinal_token)  # 创建数据集\n",
    "dataloader = DataLoader(dataset\n",
    "                        , batch_size=batch_size\n",
    "                        , drop_last = False\n",
    "                        , collate_fn=collate_fn\n",
    "                        , shuffle= True)  # 允许dataloder中的batch随机排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7ce1ce2-5c72-448a-9777-be368a866001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b4c9718-5576-4fb0-84ab-1bfd25d57e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#位置编码（同样关系到是否batch_first = True）\n",
    "# 定义PositionalEncoding类，用于为输入添加位置信息\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        #有transpose，代表默认输入数据形状为(seq_len, batch_size, d_model)\n",
    "        #如果输入结构为(batch_size, seq_len, d_model)，则不需要transpose\n",
    "        if batch_first:\n",
    "            pe = pe.unsqueeze(0)\n",
    "        else:\n",
    "            pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        #如果batch_first，则需要截断的是中间的维度\n",
    "        #且用于中间维度截断的维度是seq_len\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:, :x.size(1), :]\n",
    "        else:\n",
    "            #如果没有batch_first，需要截断的是第一个维度\n",
    "            x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "#两大掩码函数\n",
    "def create_padding_mask(seq, pad_token=0):\n",
    "    # seq: (batch_size, seq_len)\n",
    "    # 创建一个与输入序列形状相同的掩码\n",
    "    padding_mask = (seq == pad_token).float() * -1e9  # (batch_size, seq_len)\n",
    "    return padding_mask\n",
    "\n",
    "def create_look_ahead_mask(seq_len, start_seq=1):\n",
    "    mask = torch.triu(torch.ones((seq_len, seq_len)), diagonal=start_seq)  # 上三角矩阵\n",
    "    mask = mask.float() * -1e9  # 将未来的位置设置为负无穷大\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim,\n",
    "                 dim_feedforward=256, num_head=2, num_layers=2,\n",
    "                 dropout=0.1, max_len=1000, activation: str = \"relu\", batch_first=True):\n",
    "        super(DecoderOnlyTransformer, self).__init__()  # 调用父类nn.Module的构造函数\n",
    "        \n",
    "        self.embedding_dim = embedding_dim  # 保存嵌入维度\n",
    "\n",
    "        # 输入，与encoder一致\n",
    "        # 定义嵌入层，将词汇ID映射到embedding表示\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 定义位置编码层，添加位置信息，注意batch_first\n",
    "        self.position_embedding = PositionalEncoding(\n",
    "            hidden_dim, dropout\n",
    "            , max_len, batch_first=batch_first)  \n",
    "        \n",
    "        # 定义一个Transformer解码器层\n",
    "        # 包括带掩码的多头注意力机制、残差链接、Layer Norm以及前馈神经网络\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            embedding_dim, num_head\n",
    "            , dim_feedforward, dropout\n",
    "            , activation\n",
    "            , batch_first=batch_first\n",
    "        )\n",
    "        # 定义多层解码器\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer\n",
    "                                                 , num_layers)\n",
    "        \n",
    "        # 输出层 - 现在是针对每个样本都进行输出\n",
    "        # 将解码器输出映射到词汇表大小\n",
    "        # 此时注意力机制的输出结构为(batch_size, seq_len, input_dim)\n",
    "        # 通常来说我们需要将 seq_len * input_dim\n",
    "        # 不过现在nn.Linear已经可以接纳三维输出\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)  \n",
    "\n",
    "    def forward(self, seq, tgt_mask=None, tgt_key_padding_mask=None):\n",
    "        # 填充掩码\n",
    "        tgt_key_padding_mask = create_padding_mask(seq)\n",
    "        \n",
    "        # 将输入的词汇ID转换为embedding表示\n",
    "        # 添加位置信息        \n",
    "        seq = self.embeddings(seq)\n",
    "        seq = self.position_embedding(seq)\n",
    "\n",
    "        #empty_memory = torch.zeros(seq.size(0), seq.size(1), self.embedding_dim, device=seq.device)\n",
    "        \n",
    "        # 通过Transformer解码器层处理输入\n",
    "        # memory = seq则是普通的掩码注意力机制\n",
    "        # memory = memory则是编码-解码器注意力层\n",
    "        # 对Decoder-only结构来说，只需要一个打包的掩码注意力层即可\n",
    "        output = self.transformer(tgt = seq\n",
    "                                  , memory = seq\n",
    "                                  , tgt_mask=tgt_mask\n",
    "                                  , tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        # 生成式算法，如果linear准备接受三维输入，则无需进行降维索引\n",
    "        # 通过输出层得到分类结果\n",
    "        output = self.output(output)  # 将解码器输出映射到词汇表大小\n",
    "\n",
    "        #log_softmax函数\n",
    "        log_probs = F.log_softmax(output, dim=-1)  # 计算log softmax以获取概率分布\n",
    "        \n",
    "        return log_probs  # 返回log概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a4e99-9506-4e51-8b9e-31b0fad27278",
   "metadata": {},
   "source": [
    "> 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb3997d5-0fd9-4367-9d7d-e5bf0654f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c14bda2-bc66-42b7-8f8a-d71d716cb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512  # input_dimension为512\n",
    "hidden_dim = 512  # 注意力机制的维度为512，同embedding_dim\n",
    "seq_len = 512\n",
    "num_epochs = 30\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "lr = 0.05\n",
    "tgt_mask = create_look_ahead_mask(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc47619b-bebe-4269-b8ce-aa794a80f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[48336,    36,    37,  ...,    11,  2612,  3824],\n",
      "        [11057, 29447,    11,  ...,   129,   216,   210],\n",
      "        [   11,   866, 67344,  ...,    11,  6188, 68296],\n",
      "        ...,\n",
      "        [13434,    11,   359,  ...,  5155,    11,  1497],\n",
      "        [   11,   958,  6115,  ...,   100,   232,   363],\n",
      "        [ 4257,   302,  6795,  ...,    11,   116,  4302]]), tensor([[   36,    37,     3,  ...,  2612,  3824,     0],\n",
      "        [29447,    11, 11057,  ...,   216,   210,     0],\n",
      "        [  866, 67344,    11,  ...,  6188, 68296,     0],\n",
      "        ...,\n",
      "        [   11,   359,   871,  ...,    11,  1497,     0],\n",
      "        [  958,  6115,     5,  ...,   232,   363,     0],\n",
      "        [  302,  6795,  3718,  ...,   116,  4302,     0]]))\n",
      "tensor([[48336,    36,    37,  ...,    11,  2612,  3824],\n",
      "        [11057, 29447,    11,  ...,   129,   216,   210],\n",
      "        [   11,   866, 67344,  ...,    11,  6188, 68296],\n",
      "        ...,\n",
      "        [13434,    11,   359,  ...,  5155,    11,  1497],\n",
      "        [   11,   958,  6115,  ...,   100,   232,   363],\n",
      "        [ 4257,   302,  6795,  ...,    11,   116,  4302]])\n",
      "torch.Size([32, 512])\n",
      "tensor([[   36,    37,     3,  ...,  2612,  3824,     0],\n",
      "        [29447,    11, 11057,  ...,   216,   210,     0],\n",
      "        [  866, 67344,    11,  ...,  6188, 68296,     0],\n",
      "        ...,\n",
      "        [   11,   359,   871,  ...,    11,  1497,     0],\n",
      "        [  958,  6115,     5,  ...,   232,   363,     0],\n",
      "        [  302,  6795,  3718,  ...,   116,  4302,     0]])\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "#数据\n",
    "for batch in dataloader:\n",
    "    print(batch) # 第一个batch中的实际数据，结构为(batch_size, seq_len)\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93159094-d382-4962-b9b9-d5a437cec7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型\n",
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim,\n",
    "                               max_len = seq_len\n",
    "                               , num_head = num_heads\n",
    "                               , num_layers = num_layers\n",
    "                               , batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5bde9f3-888a-4c87-8c70-5cb2a97e43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5648f34d-98a4-4bd0-b96b-1878d524e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import GPUtil\n",
    "\n",
    "def print_gpu_status():\n",
    "    # 获取所有 GPU 的状态\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        #print(f\"GPU ID: {gpu.id}\")\n",
    "        #print(f\"GPU Name: {gpu.name}\")\n",
    "        print(f\"GPU使用率: {gpu.load * 100:.2f}%\")\n",
    "        print(f\"显存使用量: {gpu.memoryUsed}MB\")\n",
    "        #print(f\"显存总量: {gpu.memoryTotal}MB\")\n",
    "        print(f\"显存占用率: {gpu.memoryUtil * 100:.2f}%\")\n",
    "        #print(f\"温度: {gpu.temperature}°C\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32108ede-36b2-4dd4-9610-fe85c591b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU使用率: 8.00%\n",
      "显存使用量: 928.0MB\n",
      "显存占用率: 1.89%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be00b317-f28b-4f65-b037-c0eaf981a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2764dcb-7a78-4bb2-9006-467adfbc79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "# 为高频词设置较低的权重\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "weights = torch.ones(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8cdc220-ab9f-4069-9871-d0340085d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据高频词找到相应的索引\n",
    "high_freq_indices = vocab.convert_tokens_to_ids(high_freq_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "822a78bb-bf46-4ec9-8fb2-d27dee47967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.58765688e-06, 3.75640467e-06, 9.01818969e-06, 9.01818969e-06,\n",
       "       1.08246195e-05, 1.63145444e-05, 1.73740813e-05, 2.24835308e-05,\n",
       "       2.40344173e-05, 2.97282835e-05, 4.39618411e-05, 4.69505611e-05,\n",
       "       5.08957655e-05, 5.13426092e-05, 6.35001270e-05, 6.53466641e-05,\n",
       "       6.99839037e-05, 7.10479574e-05, 7.18958947e-05, 7.26849833e-05,\n",
       "       7.29341405e-05, 7.39918609e-05, 7.40795614e-05, 7.44379932e-05,\n",
       "       7.48615062e-05, 7.54603079e-05, 7.70060065e-05, 7.90201501e-05,\n",
       "       7.97575371e-05, 8.00640512e-05, 8.13206473e-05, 8.51861317e-05,\n",
       "       9.28246542e-05, 9.29454410e-05, 9.29886554e-05, 9.34666791e-05,\n",
       "       9.39408173e-05, 1.01286336e-04, 1.02701037e-04, 1.03167234e-04,\n",
       "       1.06100796e-04, 1.06997646e-04, 1.09733348e-04, 1.12663362e-04,\n",
       "       1.21713729e-04, 1.27323657e-04, 1.28254457e-04, 1.30361100e-04,\n",
       "       1.33529176e-04, 1.35648399e-04, 1.35703623e-04, 1.36239782e-04,\n",
       "       1.40193467e-04, 1.40232786e-04, 1.41422712e-04, 1.44466917e-04,\n",
       "       1.46735143e-04, 1.48787383e-04, 1.50897842e-04, 1.51057402e-04,\n",
       "       1.53444837e-04, 1.54846702e-04, 1.58152776e-04, 1.58403295e-04,\n",
       "       1.61264312e-04, 1.64934851e-04, 1.67476135e-04, 1.72146669e-04,\n",
       "       1.73130194e-04, 1.74489618e-04, 1.74611489e-04, 1.78667143e-04,\n",
       "       1.81290790e-04, 1.82215743e-04, 1.83722212e-04, 1.85563184e-04,\n",
       "       1.85597624e-04, 1.87055743e-04, 1.98649186e-04, 1.99322304e-04,\n",
       "       2.00400802e-04, 2.01126307e-04, 2.03956761e-04, 2.04039992e-04,\n",
       "       2.06185567e-04, 2.09292591e-04, 2.11327134e-04, 2.11954218e-04,\n",
       "       2.14316331e-04, 2.14915109e-04, 2.15936083e-04, 2.16262976e-04,\n",
       "       2.19010074e-04, 2.20701832e-04, 2.21582096e-04, 2.22222222e-04,\n",
       "       2.23164472e-04, 2.23214286e-04, 2.23713647e-04, 2.24820144e-04])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.array(high_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14f1cf2d-3ec9-4334-9a13-0323a9bad9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据高频词本身设置索引位置的权重\n",
    "\n",
    "for ids, word_ids in enumerate(high_freq_indices):\n",
    "    weights[word_ids] = 1/high_freq[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b0a9631-5a44-4632-9073-7d2a86c934eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将更改好的权重放入GPU\n",
    "weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b19dae0-a1da-4ae1-b3a5-02fc1f69e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(weight = weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b0e1553-f079-451d-a194-399b99f6654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderOnlyTransformer(\n",
       "  (embeddings): Embedding(147340, 512)\n",
       "  (position_embedding): PositionalEncoding()\n",
       "  (transformer): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=512, out_features=147340, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模式\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c080bfc4-c0d7-4819-848a-5aaedfa1f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f94aeb7d-c35e-4cce-b32f-65a4fd38671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Batch 50/299, Loss: 32.38840103149414\n",
      "Epoch 1/30, Batch 100/299, Loss: 10.150578498840332\n",
      "Epoch 1/30, Batch 150/299, Loss: 8.948948860168457\n",
      "Epoch 1/30, Batch 200/299, Loss: 9.486189842224121\n",
      "Epoch 1/30, Batch 250/299, Loss: 9.581181526184082\n",
      "---------- Epoch 1 completed, Average Loss: 12.240627173994696 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 2/30, Batch 50/299, Loss: 9.56766414642334\n",
      "Epoch 2/30, Batch 100/299, Loss: 8.940828323364258\n",
      "Epoch 2/30, Batch 150/299, Loss: 9.04025650024414\n",
      "Epoch 2/30, Batch 200/299, Loss: 9.436431884765625\n",
      "Epoch 2/30, Batch 250/299, Loss: 9.490857124328613\n",
      "---------- Epoch 2 completed, Average Loss: 9.585048286412471 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 3/30, Batch 50/299, Loss: 9.992156982421875\n",
      "Epoch 3/30, Batch 100/299, Loss: 8.839676856994629\n",
      "Epoch 3/30, Batch 150/299, Loss: 8.85632610321045\n",
      "Epoch 3/30, Batch 200/299, Loss: 9.353286743164062\n",
      "Epoch 3/30, Batch 250/299, Loss: 9.309128761291504\n",
      "---------- Epoch 3 completed, Average Loss: 9.329496236947866 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 4/30, Batch 50/299, Loss: 9.307602882385254\n",
      "Epoch 4/30, Batch 100/299, Loss: 8.759021759033203\n",
      "Epoch 4/30, Batch 150/299, Loss: 8.78863525390625\n",
      "Epoch 4/30, Batch 200/299, Loss: 9.176905632019043\n",
      "Epoch 4/30, Batch 250/299, Loss: 9.226951599121094\n",
      "---------- Epoch 4 completed, Average Loss: 9.45774216795446 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 5/30, Batch 50/299, Loss: 9.594335556030273\n",
      "Epoch 5/30, Batch 100/299, Loss: 8.806763648986816\n",
      "Epoch 5/30, Batch 150/299, Loss: 8.74155044555664\n",
      "Epoch 5/30, Batch 200/299, Loss: 9.129560470581055\n",
      "Epoch 5/30, Batch 250/299, Loss: 9.31597900390625\n",
      "---------- Epoch 5 completed, Average Loss: 9.260412767978018 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 6/30, Batch 50/299, Loss: 9.73958683013916\n",
      "Epoch 6/30, Batch 100/299, Loss: 8.851445198059082\n",
      "Epoch 6/30, Batch 150/299, Loss: 8.780680656433105\n",
      "Epoch 6/30, Batch 200/299, Loss: 9.286742210388184\n",
      "Epoch 6/30, Batch 250/299, Loss: 9.277079582214355\n",
      "---------- Epoch 6 completed, Average Loss: 9.208660907171243 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 7/30, Batch 50/299, Loss: 9.497838973999023\n",
      "Epoch 7/30, Batch 100/299, Loss: 8.650105476379395\n",
      "Epoch 7/30, Batch 150/299, Loss: 8.709208488464355\n",
      "Epoch 7/30, Batch 200/299, Loss: 9.150446891784668\n",
      "Epoch 7/30, Batch 250/299, Loss: 9.255867004394531\n",
      "---------- Epoch 7 completed, Average Loss: 9.184578474548749 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 8/30, Batch 50/299, Loss: 9.760640144348145\n",
      "Epoch 8/30, Batch 100/299, Loss: 8.676957130432129\n",
      "Epoch 8/30, Batch 150/299, Loss: 8.700936317443848\n",
      "Epoch 8/30, Batch 200/299, Loss: 9.118969917297363\n",
      "Epoch 8/30, Batch 250/299, Loss: 9.185110092163086\n",
      "---------- Epoch 8 completed, Average Loss: 9.255344779993779 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 9/30, Batch 50/299, Loss: 9.224405288696289\n",
      "Epoch 9/30, Batch 100/299, Loss: 8.671306610107422\n",
      "Epoch 9/30, Batch 150/299, Loss: 8.876482009887695\n",
      "Epoch 9/30, Batch 200/299, Loss: 9.142130851745605\n",
      "Epoch 9/30, Batch 250/299, Loss: 9.153815269470215\n",
      "---------- Epoch 9 completed, Average Loss: 9.175977576137786 ------------\n",
      "GPU使用率: 97.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 10/30, Batch 50/299, Loss: 9.27345085144043\n",
      "Epoch 10/30, Batch 100/299, Loss: 8.706202507019043\n",
      "Epoch 10/30, Batch 150/299, Loss: 8.78476619720459\n",
      "Epoch 10/30, Batch 200/299, Loss: 9.125262260437012\n",
      "Epoch 10/30, Batch 250/299, Loss: 9.334566116333008\n",
      "---------- Epoch 10 completed, Average Loss: 9.176456237716419 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 11/30, Batch 50/299, Loss: 9.240965843200684\n",
      "Epoch 11/30, Batch 100/299, Loss: 8.706034660339355\n",
      "Epoch 11/30, Batch 150/299, Loss: 8.76869010925293\n",
      "Epoch 11/30, Batch 200/299, Loss: 9.302553176879883\n",
      "Epoch 11/30, Batch 250/299, Loss: 9.208073616027832\n",
      "---------- Epoch 11 completed, Average Loss: 9.13391978924091 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 12/30, Batch 50/299, Loss: 9.57020092010498\n",
      "Epoch 12/30, Batch 100/299, Loss: 8.69621753692627\n",
      "Epoch 12/30, Batch 150/299, Loss: 8.699959754943848\n",
      "Epoch 12/30, Batch 200/299, Loss: 9.184076309204102\n",
      "Epoch 12/30, Batch 250/299, Loss: 9.188553810119629\n",
      "---------- Epoch 12 completed, Average Loss: 9.129378825924467 ------------\n",
      "GPU使用率: 97.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 13/30, Batch 50/299, Loss: 9.538113594055176\n",
      "Epoch 13/30, Batch 100/299, Loss: 8.719345092773438\n",
      "Epoch 13/30, Batch 150/299, Loss: 8.700969696044922\n",
      "Epoch 13/30, Batch 200/299, Loss: 9.211570739746094\n",
      "Epoch 13/30, Batch 250/299, Loss: 9.215163230895996\n",
      "---------- Epoch 13 completed, Average Loss: 9.075951917514354 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 14/30, Batch 50/299, Loss: 9.103833198547363\n",
      "Epoch 14/30, Batch 100/299, Loss: 8.618491172790527\n",
      "Epoch 14/30, Batch 150/299, Loss: 8.696879386901855\n",
      "Epoch 14/30, Batch 200/299, Loss: 9.055170059204102\n",
      "Epoch 14/30, Batch 250/299, Loss: 9.073615074157715\n",
      "---------- Epoch 14 completed, Average Loss: 9.065551518596534 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 15/30, Batch 50/299, Loss: 9.212906837463379\n",
      "Epoch 15/30, Batch 100/299, Loss: 8.61963176727295\n",
      "Epoch 15/30, Batch 150/299, Loss: 8.714584350585938\n",
      "Epoch 15/30, Batch 200/299, Loss: 9.130971908569336\n",
      "Epoch 15/30, Batch 250/299, Loss: 9.110576629638672\n",
      "---------- Epoch 15 completed, Average Loss: 9.040045352285123 ------------\n",
      "GPU使用率: 99.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 16/30, Batch 50/299, Loss: 9.227551460266113\n",
      "Epoch 16/30, Batch 100/299, Loss: 8.676358222961426\n",
      "Epoch 16/30, Batch 150/299, Loss: 8.66960334777832\n",
      "Epoch 16/30, Batch 200/299, Loss: 9.040913581848145\n",
      "Epoch 16/30, Batch 250/299, Loss: 9.15699291229248\n",
      "---------- Epoch 16 completed, Average Loss: 9.045243521597872 ------------\n",
      "GPU使用率: 94.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 17/30, Batch 50/299, Loss: 9.031515121459961\n",
      "Epoch 17/30, Batch 100/299, Loss: 8.598932266235352\n",
      "Epoch 17/30, Batch 150/299, Loss: 8.670928001403809\n",
      "Epoch 17/30, Batch 200/299, Loss: 9.068352699279785\n",
      "Epoch 17/30, Batch 250/299, Loss: 9.175503730773926\n",
      "---------- Epoch 17 completed, Average Loss: 9.036159901315951 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 18/30, Batch 50/299, Loss: 9.126908302307129\n",
      "Epoch 18/30, Batch 100/299, Loss: 8.66491985321045\n",
      "Epoch 18/30, Batch 150/299, Loss: 8.646238327026367\n",
      "Epoch 18/30, Batch 200/299, Loss: 9.08442211151123\n",
      "Epoch 18/30, Batch 250/299, Loss: 9.22383975982666\n",
      "---------- Epoch 18 completed, Average Loss: 9.062837119086531 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 19/30, Batch 50/299, Loss: 9.167409896850586\n",
      "Epoch 19/30, Batch 100/299, Loss: 8.666190147399902\n",
      "Epoch 19/30, Batch 150/299, Loss: 8.679068565368652\n",
      "Epoch 19/30, Batch 200/299, Loss: 9.19579792022705\n",
      "Epoch 19/30, Batch 250/299, Loss: 9.120511054992676\n",
      "---------- Epoch 19 completed, Average Loss: 9.081268521056925 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 20/30, Batch 50/299, Loss: 9.109817504882812\n",
      "Epoch 20/30, Batch 100/299, Loss: 8.626689910888672\n",
      "Epoch 20/30, Batch 150/299, Loss: 8.699495315551758\n",
      "Epoch 20/30, Batch 200/299, Loss: 9.260904312133789\n",
      "Epoch 20/30, Batch 250/299, Loss: 9.303858757019043\n",
      "---------- Epoch 20 completed, Average Loss: 9.094164548510292 ------------\n",
      "GPU使用率: 100.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 21/30, Batch 50/299, Loss: 9.05826187133789\n",
      "Epoch 21/30, Batch 100/299, Loss: 8.614299774169922\n",
      "Epoch 21/30, Batch 150/299, Loss: 8.66312026977539\n",
      "Epoch 21/30, Batch 200/299, Loss: 9.209952354431152\n",
      "Epoch 21/30, Batch 250/299, Loss: 13.428202629089355\n",
      "---------- Epoch 21 completed, Average Loss: 9.70029809243703 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 22/30, Batch 50/299, Loss: 9.100849151611328\n",
      "Epoch 22/30, Batch 100/299, Loss: 8.71784782409668\n",
      "Epoch 22/30, Batch 150/299, Loss: 8.796971321105957\n",
      "Epoch 22/30, Batch 200/299, Loss: 9.129828453063965\n",
      "Epoch 22/30, Batch 250/299, Loss: 11.446978569030762\n",
      "---------- Epoch 22 completed, Average Loss: 18.186564008527775 ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10404.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n",
      "Epoch 23/30, Batch 50/299, Loss: 65.34773254394531\n",
      "Epoch 23/30, Batch 100/299, Loss: nan\n",
      "Epoch 23/30, Batch 150/299, Loss: nan\n",
      "Epoch 23/30, Batch 200/299, Loss: nan\n",
      "Epoch 23/30, Batch 250/299, Loss: nan\n",
      "---------- Epoch 23 completed, Average Loss: nan ------------\n",
      "GPU使用率: 98.00%\n",
      "显存使用量: 10402.0MB\n",
      "显存占用率: 21.17%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计损失\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "        # 每个 batch 后删除不需要的变量，释放 GPU 内存\n",
    "        del inputs, targets, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    average_loss = total_loss/ len(dataloader)\n",
    "    loss_records.append(average_loss)\n",
    "    print(f\"---------- Epoch {epoch+1} completed, Average Loss: {average_loss} ------------\")\n",
    "    print_gpu_status()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        # 保存模型权重\n",
    "        torch.save(model.state_dict(), f'Imporved_Decoder_weights_epoch_{epoch+1}.pth')\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d268cb1-cdf6-4bb7-92dc-cc35b401522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型权重\n",
    "\n",
    "#模型\n",
    "model = DecoderOnlyTransformer(vocab_size, embedding_dim, hidden_dim,\n",
    "                               max_len = seq_len\n",
    "                               , num_head = num_heads\n",
    "                               , num_layers = num_layers\n",
    "                               , batch_first=True)\n",
    "\n",
    "checkpoint_path = 'Imporved_Decoder_weights_epoch_15.pth'  # 替换为你的模型权重路径\n",
    "model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c263fe0-6c24-41b4-ab4f-9435677c8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderOnlyTransformer(\n",
       "  (embeddings): Embedding(147340, 512)\n",
       "  (position_embedding): PositionalEncoding()\n",
       "  (transformer): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=512, out_features=147340, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66bf380f-d875-420b-9390-d4d1134fade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def top_k_sampling(logits, top_k=10):\n",
    "    \"\"\"\n",
    "    从 logits 中进行 top-k 采样，返回采样到的标记索引。\n",
    "    \"\"\"\n",
    "    # 获取 logits 的最后一个时间步的输出\n",
    "    logits = logits[:, -1, :]  # 取最后一个时间步的 logits\n",
    "    \n",
    "    # 进行 top-k 筛选\n",
    "    top_k_logits, top_k_indices = torch.topk(logits, top_k, dim=-1)\n",
    "    \n",
    "    # 对 top-k 的 logits 进行 softmax，然后从中采样\n",
    "    probabilities = torch.nn.functional.softmax(top_k_logits, dim=-1)\n",
    "    next_token = torch.multinomial(probabilities, 1)  # 从概率分布中采样\n",
    "    \n",
    "    # 获取原始 logits 对应的索引\n",
    "    next_token = top_k_indices.gather(-1, next_token)\n",
    "    \n",
    "    return next_token.item()  # 返回标记索引\n",
    "\n",
    "def generate_sequence(model, initial_input, eos_token_id = 2\n",
    "                      , max_length=100\n",
    "                      , top_k = 300\n",
    "                      , device='cuda'):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    \n",
    "    # 将初始输入移到 GPU 上，并添加 batch 维度\n",
    "    input_seq = torch.tensor(initial_input).unsqueeze(0).to(device)  \n",
    "    \n",
    "    generated_seq = initial_input  # 初始化生成的序列\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # 预测下一个token\n",
    "            # 首先，model和训练时的模式一样，还是会针对每一个token都输出下一个token\n",
    "            # 我们的每一个token依然会因为注意力机制的缘故、由单一样本转变为“段落”\n",
    "            # 只有最后一行、也就是最后一个“段落”所输出的内容对我们才有意义\n",
    "            # 因为最后一行代表了整个句子的信息，依据整个句子预测出后一个字\n",
    "            log_probs = model(input_seq)\n",
    "\n",
    "            # 使用 top-k 采样策略从 log_probs 中采样下一个标记\n",
    "            next_token = top_k_sampling(log_probs, top_k=top_k)\n",
    "            \n",
    "            # 将生成的标记添加到序列中\n",
    "            generated_seq.append(next_token)\n",
    "            \n",
    "            # 更新输入序列，并将其移到 GPU 上\n",
    "            input_seq = torch.tensor(generated_seq).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 如果生成了 <eos> 标记，则停止\n",
    "            if next_token == eos_token_id:  # eos_token_id 是 <eos> 的标记\n",
    "                break\n",
    "    \n",
    "    return generated_seq\n",
    "\n",
    "def one_sentence_tokens_to_ids(sentence,vocab_table):\n",
    "    \"\"\"\n",
    "    该函数只接纳一个句子作为输入，不接纳双层的列表（如一个列表中包含多个句子，每个句子单独做为一个列表）\n",
    "    \"\"\"\n",
    "    #检查是否为嵌套的列表\n",
    "    if isinstance(sentence, list) and all(isinstance(i, list) for i in sentence):\n",
    "        raise ValueError(\"该结构为嵌套列表、包含多个句子，当前函数只能接受单一句子\")\n",
    "\n",
    "    #分词\n",
    "    test_split = jieba.lcut(sentence)\n",
    "    #添加起始符号与终止符号\n",
    "    content = [\"<sos>\"] + test_split + [\"<eos>\"]\n",
    "    #直接使用训练集做好的词汇表进行编码\n",
    "    return vocab_table.convert_tokens_to_ids(content)\n",
    "\n",
    "def one_sentence_ids_to_tokens(content,vocab_table):\n",
    "    content = vocab_table.convert_ids_to_tokens(content)\n",
    "    remove_tokens = {'<sos>', '<eos>', '<unk>'}\n",
    "    result = ''.join([token for token in content if token not in remove_tokens])\n",
    "    return print(result)\n",
    "\n",
    "def one_sentence_test(sentence,vocab_table=vocab,model=model,top_k=300):\n",
    "    content = one_sentence_tokens_to_ids(sentence,vocab_table)\n",
    "    #print(content)\n",
    "    generate_seq = generate_sequence(model,content,top_k)\n",
    "    #print(generate_seq)\n",
    "    return one_sentence_ids_to_tokens(generate_seq,vocab_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67a6e509-23ea-4506-9160-fd04c523ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三次冲突!5体育遭驱逐! 湖人悍将特里推倒教练占形成加拿大确定非常下跌一最近乔布斯稳健相关同时分红估值人民币超过净值8下跌理财成功产品资产100认为11买入国家分红业务所重仓股还是同时23规模稳定研究限制出现调整保持14消息比14所以行情预期下跌7数据12发现人民币调整创新美元最新23存款把交易美元投资收益债券开始达到影响价值跌幅过去其中可规模天最大认为采访控制行业23过去净值除了最大收益率行业于2000下降20数据30中心仍买入\n"
     ]
    }
   ],
   "source": [
    "one_sentence_test(\"三次冲突!5体育遭驱逐! 湖人悍将特里推倒教练\",top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec7c46c9-5e6b-49cc-822f-9e405ee9608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！香港自着均收于采访发行达到至规定方面资产成功非常已及时·选择选择需要通过宣布最高向告诉非常方面国家仓位记者这样家好12接近只亿份机会资金接受估值介绍仓位产品提供通过机会买入方式美元均资金跌幅之间及时这种比较月份可股票美元估值最终收藏上市不能天研究上市美元比较记者自12乔布斯非常未债券显示重仓股其他而且不会上市过去一位8可国泰证监会最大今年下跌低于盎司\n"
     ]
    }
   ],
   "source": [
    "one_sentence_test(\"你好！\",top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d6e31-355c-4abe-b25d-3acce5e0e5cb",
   "metadata": {},
   "source": [
    "相比起之前的模型，这一版模型能够输出更长的句子、且输出重复结果的情况也大幅改善，可见更大的模型、更多的数据以及降低权重的操作是有效的。然而，我们降低权重的方法可能有些过于粗暴，导致标点符号方面出现比较大的问题。同时，模型输出的句子也还并不通畅，我们还可以做出更多的改善、来不断提升模型的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150ada6-697f-48ae-8adb-6e4c8401b7ea",
   "metadata": {},
   "source": [
    "## 3.4 Huggingface入门与调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc7957-77f6-47c3-a389-ae0d57fd59e3",
   "metadata": {},
   "source": [
    "### 3.4.1 Huggingface入门与官网使用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f76069-d409-4021-af56-b0cc8296f051",
   "metadata": {},
   "source": [
    "Hugging Face是一家领先的人工智能技术落地实践公司，它搭建并开发了围绕自然语言处理（NLP）、大语言模型（LLMs）、多模态模型等各个人工智能领域的一系列落地应用开源框架，其中最为著名的是开源的Transformers库，但除此之外还有专注于图像生成的Diffusers、服务于git的Hub和Hub Python\n",
    "Library库，专门做词嵌入的Tokenizer等等。\n",
    "    \n",
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/20.png\" alt=\"描述文字\"></center>\n",
    "\n",
    "随着人工智能领域的发展，模型的体量逐渐增长、数据的体量逐渐增长、在实践中应用复杂的人工智能算法的需求日益增加，越来越多的开发者会倾向于直接使用经过预训练和封装的成熟NLP算法，而非自行构建复杂的transformers或tokernizer架构。Huggingface正是把握住了这一需求的变化，开发了**封装层次极高、调用简单、节约算力、且训练流程清晰明确的Transformers库**，这个库提供了一系列与人工智能相关的预训练模型，如BERT、GPT、T5等，这些模型都是建立在原始Transformer架构基础之上，并对其进行了扩展和优化，以适用于各种各样的NLP任务。与最初由Google提出的Transformer模型相比，Hugging Face的Transformers库提供了更为丰富、易于使用且经过精心优化的模型选择，同时支持跨多种编程语言和平台。\n",
    "\n",
    "在当代NLP领域的应用中，Huggingface的transformer库有以下三大优势：\n",
    "\n",
    "- **提供了巨量的预训练模型 & 高级多模态模型的实现**，覆盖了语言理解、生成任务、多模态任务、对话系统以及特定领域的应用。这包括了广泛使用的预训练语言模型如BERT、GPT和RoBERTa，专门用于翻译和文本摘要的序列到序列模型如BART和mT5，以及能处理文本和图像的多模态模型如CLIP和DALL-E。对话模型如DialoGPT和Blenderbot能够支持构建交互式对话系统，而DistilBERT和ALBERT等模型则提供了轻量级的解决方案，适用于资源受限的情况。此外，还有为特定领域或任务定制的模型，如SciBERT和BioBERT等，它们经过预训练能够快速适应相关的NLP任务。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/22.png)\n",
    "    \n",
    "- **高层次的封装，让Transformer及bert、GPT等更复杂的NLP模型都能被轻松调用**。Huggingface的Transformer宛如NLP领域的sklearn，为低成本、低门槛实践算法铺平了道路。\n",
    "\n",
    "- **打造了针对特定NLP任务的一系列pipeline供用户使用，让执行复杂任务的流程变得简便**。在NLP的世界中，存在着文本分类、命名实体识别、问答系统、摘要生成、文本生成、机器翻译等不同性质的任务，这些任务涉及到有监督、无监督、半监督等各类标签应用流程，同时每个任务都需要适应于任务本身的文字编码方法、模型架构、预训练权重、以及正确的预处理后处理流程。可以说在NLP的世界中，每个特定NLP任务的执行都是及其复杂而繁琐的。但在Huggingface的transformer库中，pipeline功能可以自动处理任意任务的全流程，用户只需要告诉pipeline当前执行的任务是什么，就可以轻松执行复杂任务。\n",
    "    \n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/21.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ad075-71be-4d9f-9c2c-cecde8c7bfcf",
   "metadata": {},
   "source": [
    "今天就让我们来了解下Huggingface的基本框架与运行结构，并使用Huggingface中的Transformer实践两个简单的任务。**注意，huggingface官网访问、模型加载依赖于魔法，建议使用漂亮国全局接口**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f069c-e59c-4134-8cfd-4cbdf832f8d5",
   "metadata": {},
   "source": [
    "- Huggingface主页的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdc248-5c45-4d13-9749-ebfb37079b88",
   "metadata": {},
   "source": [
    "HuggingFace 作为自然语言处理（NLP）领域的领先平台，旗下拥有众多功能强大的库，这些库相互依赖，共同构成了一个庞大而复杂的生态系统。比如，Transformers 库是核心，用于加载和使用各种预训练模型；Tokenizers 库专注于高效的文本标记化；Datasets 库提供了数据集的处理和管理工具。这些库不仅功能各异，还在架构上彼此交织，每个库内部都包含了高度模块化和复杂的设计，因此要想系统性地学习和掌握 Hugging Face 及其 Transformers 库，并不容易。学习者不仅需要理解每个库的独立功能，还要明白它们如何在不同任务中协同工作。这意味着，深入学习 Hugging Face 的工具链，需要跨越多个知识领域，包括深度学习、NLP 任务设计、数据处理和优化技术等。面对这些挑战，学习者需要准备好应对复杂的架构、庞大的文档，以及在实际应用中不断探索和实验的过程。\n",
    "\n",
    "Models模块提供了一系列与transformer架构（如BERT、GPT-2、T5等）相关的、用于加载各类模型的功能类，包括但不限于150+基于Transformer的语言模型，100+视觉模型、30+语音模型等等，你可以在[Huggingface官方文档页面](https://huggingface.co/docs/transformers/index)的左侧找到专用于各类模型的类的列表。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/25.png)\n",
    "\n",
    "在[每个模型的页面中](https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/bert#bert)，我们可以找到这个模型的系列框架的列表。**注意，这个列表中的类是依据不同需求、从不同角度调用模型的工具，而非模型本身**。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/26.png)\n",
    "\n",
    "**因此，我并不推荐“系统性地学习HuggingFace”**，而应该将HuggingFace当做有效的工具来使用。究竟应该如何使用HuggingFace呢？我们可以三步走——\n",
    "> - 认识Models，Datasets，Spaces与Doc页面\n",
    "> - 从任务出发使用Huggingface（Doc路径 + Pipeline + 首页搜索）\n",
    "> - 从模型出发使用Huggingface（从Spaces认识模型 + 首页搜索）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ec090-e5c8-487d-bc89-7a6b667a97d1",
   "metadata": {},
   "source": [
    "- 安装部署与导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee4878-9a76-4494-8f2d-8e75b9d6f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a869f5-d08b-4953-89f2-2e45ef65f3e7",
   "metadata": {},
   "source": [
    "该代码可以通用于windows、linux和MacOs系统，注意运行pip代码的时候要避开魔法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb40ed82-6e2b-492f-8029-ae4b1f054f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4679fb8-405b-4720-b300-6bdc0f9ebce1",
   "metadata": {},
   "source": [
    "### 3.4.2 加载并使用预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cb979-21b3-4251-90a6-b6ce64adf284",
   "metadata": {},
   "source": [
    "- **查找模型列表**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927d7bc-d8b7-4af6-b049-5067eeaf81cb",
   "metadata": {},
   "source": [
    "在使用具体的模型式，我们会需要下面的页面：https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787b557-2a53-47df-8b22-675b2c3ef0dd",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ddc6d-18bc-4439-86a6-1e1ebedd07ec",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e6cbd-6c23-48a1-9e5c-1cbace380a7e",
   "metadata": {},
   "source": [
    "> - **以bert为例，尝试调用bert**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebeee9-88bb-4d92-a95f-e0b8f4747733",
   "metadata": {},
   "source": [
    "我们可以通过“最多下载”、“最佳趋势”以及搜索等标签来筛选我们需要的模型。只要知道模型的名字，就可以通过transformers中的功能类来调用模型。其中，最常用的模型可以与最常用的功能匹配起来——依然是bert，gpt2，RoBERTa，T5以及DistilBERT。我们可以在对话框中搜索bert，就能够得到一系列关于bert的模型，**点开任意bert相关的模型，即可在说明文档中找到bert相关的全部模型列表**（https://huggingface.co/bert-base-uncased）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac1746-2835-41d4-bfe4-ed8a6833928c",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f1ce2-41fa-49ee-9428-5ec7d7a4e806",
   "metadata": {},
   "source": [
    "在Model Card下面可以查看到模型的信息和可用模型的列表名称，在Files and version下面可以下载可用的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a6a54-4252-419e-ac9e-184e8bd58e53",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e8427-aa9e-4d7b-bde8-9f0fddbabb47",
   "metadata": {},
   "source": [
    "在这些模型中，只有bert-base-chinese与bert-base-multilingual-cased能够支持中文："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6064fd28-2ae1-49b7-bab3-e0cea5e4b9c9",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22d4eb16-cba7-4b95-ae73-60e40cd34fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8c737b5-4447-4939-8287-941973c35056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel #加载能够导入bert模型的工具，最低至少需要BertTokenizer和BertModel\n",
    "\n",
    "PATH = r\"HuggingfaceModels/\"\n",
    "\n",
    "#加载预训练的、专用于bert的分词模型\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(PATH,'bert-base-chinese'),trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c5251-187a-480a-ab1c-2a8ef6f2b64b",
   "metadata": {},
   "source": [
    "通常来说，当我们运行上述代码时，huggingface会开始自动下载对应的模型。**该下载过程需要魔法，建议使用漂亮国去全局接口**，当你是直接下载模型时，trust_remote_code参数要设置为False。但是我们也可以直接将模型通过git，或手动下载到本地，这样就可以通过上述的代码来加载和运行与训练模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c8745-d92e-4219-bb91-beeeaa1bdec4",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/27.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf398f5-e95d-4ff7-a8f6-f82b7cbb350e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#加载预训练的bert\n",
    "model = BertModel.from_pretrained(os.path.join(PATH,'bert-base-chinese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d0e541-2c60-4d9b-9b85-b5024935089f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"虽然今天下雨了，但我拿到了心仪的offer，因此非常开心！\"\n",
    "\n",
    "#将text输入分词和编码模型\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "#将编码好的文字输入给预训练好的bert\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd0edfb-5913-43fa-8591-94231c39dc95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.1622, -0.0790,  1.8173,  ..., -0.6126,  0.6526, -0.5678],\n",
       "         [-0.0494,  0.9221,  1.3372,  ..., -0.4971, -0.0485,  0.1589],\n",
       "         [-0.0456, -0.2386,  0.2801,  ...,  0.6094,  0.5508,  0.3712],\n",
       "         ...,\n",
       "         [ 1.8941, -0.2364,  0.8497,  ..., -0.2132,  0.6206, -0.0577],\n",
       "         [ 0.7245, -0.4633,  1.7492,  ..., -0.9154,  0.7376, -0.4374],\n",
       "         [ 0.7486, -0.3318,  1.1627,  ..., -0.6981,  0.7330, -0.5773]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9999,  0.9999,  0.9996,  0.9229,  0.9680, -0.5962, -0.9971,  0.8632,\n",
       "          0.9978, -0.9995,  1.0000,  0.9999,  0.9697, -0.9845,  0.9996, -0.9999,\n",
       "         -0.9962,  0.9950,  0.7646,  0.3401,  0.9999, -1.0000, -0.8772, -0.6877,\n",
       "         -0.7054,  0.9997,  0.9414, -0.8321, -1.0000,  0.9991,  0.9465,  0.9996,\n",
       "          0.9964, -1.0000, -1.0000,  0.9912, -0.7883,  0.9957,  0.0435, -0.8159,\n",
       "         -0.9981, -0.9976,  0.8141, -0.9997, -0.9547,  0.6489, -1.0000, -1.0000,\n",
       "          0.9258,  0.9999, -0.3776, -0.9991,  0.8158, -0.9105, -0.9120,  0.9132,\n",
       "         -0.9999,  0.9962,  1.0000,  0.8233,  0.9973, -0.9482, -0.7165, -0.9999,\n",
       "          0.9998, -0.9980, -0.9891,  0.8536,  0.9999,  1.0000, -0.9872,  0.9077,\n",
       "          1.0000,  0.9635, -0.4720,  0.9999, -1.0000,  0.4113, -1.0000, -0.7166,\n",
       "          1.0000,  0.9977, -0.8823, -0.5393, -0.9940, -1.0000, -0.9993,  1.0000,\n",
       "          0.4248,  0.9492,  0.9973, -0.9999, -1.0000,  0.9975, -0.9995, -0.9973,\n",
       "         -0.9748,  0.9994, -0.4766, -0.9334,  0.2085,  0.8857, -0.9998, -0.9993,\n",
       "          0.9951,  0.9968,  0.8072, -0.9993,  1.0000,  0.7904, -1.0000, -0.7090,\n",
       "         -1.0000, -0.9663, -0.9847,  0.9998,  0.8470,  0.1070,  0.9983, -0.9997,\n",
       "          0.9317, -0.9990, -0.9928, -0.9985,  0.9986,  1.0000,  0.9996, -0.9996,\n",
       "          0.9999,  1.0000,  0.9907,  0.9951, -0.9994,  0.9906,  0.8054, -0.9374,\n",
       "         -0.0613, -0.7922,  1.0000,  0.9904,  0.9998, -0.9938,  0.9996, -0.9910,\n",
       "          1.0000, -0.9999,  0.9982, -1.0000, -0.9055,  0.9995,  0.8803,  1.0000,\n",
       "         -0.8416,  1.0000, -0.9979, -0.9998,  0.9949,  0.2561,  0.9985, -1.0000,\n",
       "          0.8699,  0.2237, -0.9526,  0.9073, -1.0000,  1.0000, -0.7147,  1.0000,\n",
       "          0.9988,  0.3732, -0.9949, -0.9991,  0.8603, -1.0000, -0.9929,  0.9921,\n",
       "         -0.5737,  0.9989, -0.9994, -0.9823,  0.3361,  0.0040, -1.0000,  0.9843,\n",
       "          0.1959,  0.9858,  0.9856,  0.7158,  0.9690,  0.9363, -0.8677,  0.9999,\n",
       "         -0.1145,  0.9989,  1.0000, -0.3110, -0.3405, -0.9791, -1.0000, -0.7058,\n",
       "          1.0000, -0.3323, -0.9999,  0.9617, -1.0000,  0.9757, -0.9909,  0.1429,\n",
       "         -0.9224, -0.9999,  0.9998, -0.9088, -0.9997, -0.2368,  0.4545,  0.9170,\n",
       "         -0.9997, -0.4378,  0.9790, -0.8380,  0.9544, -0.9972, -0.9900,  0.9806,\n",
       "         -0.8900,  0.9046,  0.9347,  1.0000,  0.9999, -0.0684, -0.7911,  1.0000,\n",
       "          0.6418, -1.0000,  0.7115, -0.9858, -0.1284,  0.9999, -0.9985,  0.9055,\n",
       "          1.0000,  0.9842,  1.0000, -0.9449, -0.9265, -0.9994,  1.0000,  0.9941,\n",
       "          0.9999, -0.9999, -0.9997, -0.3267,  0.2922, -1.0000, -0.9998, -0.6018,\n",
       "          0.9975,  0.9997, -0.3665, -0.9651, -0.9964, -0.9989,  1.0000, -0.9849,\n",
       "          1.0000,  0.8819, -0.6037, -0.9992,  0.9205, -0.7637, -0.9997, -0.4513,\n",
       "         -0.9999, -0.9977, -0.9999,  0.9656, -1.0000, -1.0000,  0.1868,  1.0000,\n",
       "          0.9788, -1.0000,  0.9998,  0.9992,  0.6255, -0.9931,  0.9811, -1.0000,\n",
       "          1.0000, -0.9989,  0.7774, -0.9922, -0.9853, -0.6548,  0.9994,  0.9998,\n",
       "         -0.9995, -0.9862, -0.9945, -0.9900, -0.4590,  0.9919, -0.9124,  0.7898,\n",
       "         -0.9493, -0.9880,  0.9795, -0.9965, -0.9986,  0.4766,  1.0000, -0.9714,\n",
       "          1.0000,  0.9866,  1.0000,  0.9741, -0.9994,  0.9995, -0.3418, -0.6257,\n",
       "         -0.9769, -0.9990,  0.9897, -0.1939,  0.9039, -0.9999,  1.0000,  0.9996,\n",
       "          0.8430,  0.5315, -0.1414,  0.4149,  0.9893, -0.9955,  0.9985, -0.9998,\n",
       "          0.8975,  0.9991,  1.0000,  0.9868,  0.3208, -0.9335,  0.9995, -0.9989,\n",
       "          0.9994, -1.0000,  1.0000, -0.9997,  0.8746, -0.9834, -0.9979,  1.0000,\n",
       "          0.9926, -0.9770,  0.9999, -0.8931,  0.9742,  0.9996,  0.9928,  0.9978,\n",
       "          0.9850,  1.0000, -0.9993, -0.9907, -0.9923, -0.9974, -0.9975, -1.0000,\n",
       "          0.4436, -1.0000, -0.9882, -0.9703,  0.9198,  0.2743, -0.6266,  0.3111,\n",
       "          0.3086,  0.4562, -0.9981,  0.1838, -0.1098, -0.9868, -0.9953, -1.0000,\n",
       "         -0.9984,  0.9426,  1.0000, -1.0000,  0.9999, -1.0000, -0.9929,  0.9920,\n",
       "          0.4623,  0.4120,  0.9999, -1.0000,  0.6884,  0.9999,  1.0000,  0.9971,\n",
       "          0.9998, -0.9029, -1.0000, -0.9999, -1.0000, -1.0000, -0.9999,  0.8299,\n",
       "          0.8746, -1.0000,  0.6857,  0.8167,  1.0000,  0.9843, -0.9986,  0.6651,\n",
       "         -0.9999,  0.1387,  0.9997, -0.8381, -0.9999,  0.9953,  0.1102,  0.9999,\n",
       "         -0.9288,  0.9696,  0.9680,  0.7198,  0.9970, -1.0000,  0.9359,  1.0000,\n",
       "         -0.4057, -1.0000, -0.9893, -0.8902, -1.0000, -0.1799,  0.8824,  0.9999,\n",
       "         -1.0000, -0.9748, -0.9891,  0.7139,  0.9777,  0.9999,  0.9972,  0.9868,\n",
       "          0.8126,  0.9786, -0.0429,  1.0000,  0.6781, -0.9981,  0.9991, -0.3622,\n",
       "          0.2483, -1.0000,  0.9998, -0.7315,  1.0000,  0.9820, -0.8251, -0.9572,\n",
       "         -0.9882,  0.9951,  1.0000, -0.2685, -0.5616, -0.9992, -1.0000, -0.9974,\n",
       "          0.4538, -0.3495, -0.9666, -0.9999,  0.7218,  0.2307,  1.0000,  1.0000,\n",
       "          0.9993, -0.9451, -0.9719,  0.9970, -0.8050,  0.9988, -0.8898, -1.0000,\n",
       "         -0.9680, -1.0000,  0.9999, -0.9884, -0.9613, -0.9865, -0.7220,  0.1987,\n",
       "         -1.0000, -0.4702, -0.9981,  0.9791,  1.0000, -0.9997,  0.9865, -0.9987,\n",
       "          0.4586,  0.8345,  0.9401,  0.9905, -0.6663, -0.5311, -0.4764, -0.9152,\n",
       "          0.9791,  0.9972, -0.9939, -0.6357,  0.9999,  0.0665,  0.9990,  0.5756,\n",
       "          0.6408,  0.7963,  1.0000,  0.8529,  1.0000,  0.9591,  1.0000,  0.9997,\n",
       "         -0.9786,  0.7649,  0.7720, -0.9328,  0.7567,  0.9743,  0.9997,  0.7648,\n",
       "         -0.9935, -0.9979,  0.9992,  1.0000,  1.0000, -0.2828,  0.9712, -0.7205,\n",
       "          0.9797,  0.7427,  0.9923, -0.3301,  0.1327,  0.9912,  0.9997, -1.0000,\n",
       "         -1.0000, -1.0000,  1.0000,  0.9995, -0.5934, -1.0000,  0.9998, -0.1446,\n",
       "          0.8538,  0.9962,  0.8618, -0.9634,  0.5338, -0.9995,  0.0059,  0.9770,\n",
       "          0.9604,  0.7619,  0.9998, -0.9977,  0.2957,  1.0000, -0.0509,  1.0000,\n",
       "         -0.0818, -0.9961,  0.9978, -0.9969, -0.9998, -0.9456,  0.9999,  0.9986,\n",
       "         -0.8621, -0.9619,  0.9997, -0.9999,  0.9999, -0.9992,  0.9291, -0.9963,\n",
       "          0.9999, -0.9839, -0.9989,  0.2370,  0.9802,  0.9554, -0.9553,  1.0000,\n",
       "         -0.9811, -0.9453,  0.9361, -0.9635, -0.9959, -0.9489, -0.8201, -1.0000,\n",
       "          0.8508, -0.2446, -0.1463, -0.9993, -1.0000,  1.0000, -0.9938, -0.9420,\n",
       "          0.9999, -0.9983, -1.0000,  0.9921, -0.9999, -0.7295,  0.7488,  0.0109,\n",
       "          0.6090, -1.0000,  0.5628,  1.0000, -0.9996, -0.8930, -0.9803, -0.9127,\n",
       "         -0.1761,  0.8842,  0.9782, -0.9193,  0.8943,  0.9700,  0.9355, -0.1486,\n",
       "         -0.5998, -0.9992, -0.9606, -0.7243, -0.9995, -1.0000, -0.9999,  1.0000,\n",
       "          1.0000,  1.0000, -0.6652,  0.5267,  0.6701,  0.9887, -0.9998,  0.8237,\n",
       "          0.6136,  0.9919, -0.6469, -0.9999, -0.9167, -1.0000,  0.5655,  0.1916,\n",
       "         -0.8672,  0.9920,  1.0000,  0.9998, -0.9997, -0.9994, -0.9995, -0.9990,\n",
       "          0.9999,  0.9997,  0.9999, -0.9785, -0.4907,  0.9997,  0.9238,  0.4152,\n",
       "         -0.9999, -0.9974, -1.0000,  0.7109, -0.9638, -0.9998,  0.9997,  1.0000,\n",
       "          0.5260, -0.9999, -0.9564,  1.0000,  0.9997,  1.0000, -0.0463,  0.9999,\n",
       "         -0.9901,  0.9977, -0.9994,  1.0000, -1.0000,  1.0000,  0.9999,  0.9997,\n",
       "          0.9976, -0.9895,  0.9706, -0.9989, -0.7258,  0.9973, -0.4013, -0.9899,\n",
       "          0.9931,  0.9993, -0.9399,  1.0000,  0.9571,  0.3304,  0.5215,  0.8508,\n",
       "          0.8761, -0.7202, -0.9999,  0.1561,  0.9990,  0.9858,  1.0000,  0.9755,\n",
       "          1.0000, -0.9856, -0.9997,  0.9983, -0.6808,  0.0311, -0.9999,  1.0000,\n",
       "          1.0000, -1.0000, -0.9871,  0.6541, -0.1459,  1.0000,  0.9996,  0.9998,\n",
       "          0.9616,  0.6005,  0.9981, -0.9998,  0.2359, -0.9978, -0.9988,  1.0000,\n",
       "         -0.9917,  0.9999, -0.9967,  1.0000, -0.9640,  0.9853,  0.9951,  0.9141,\n",
       "         -0.9986,  1.0000,  0.6972, -0.9961, -0.2598, -0.9045, -0.9999,  0.0485]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output #此时bert输出的是针对我们输入的文字进行的判断，注意这不是生成式的结果，而是语义理解的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce515d8-6405-4003-bce8-08da5ee369da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1622, -0.0790,  1.8173,  ..., -0.6126,  0.6526, -0.5678],\n",
       "         [-0.0494,  0.9221,  1.3372,  ..., -0.4971, -0.0485,  0.1589],\n",
       "         [-0.0456, -0.2386,  0.2801,  ...,  0.6094,  0.5508,  0.3712],\n",
       "         ...,\n",
       "         [ 1.8941, -0.2364,  0.8497,  ..., -0.2132,  0.6206, -0.0577],\n",
       "         [ 0.7245, -0.4633,  1.7492,  ..., -0.9154,  0.7376, -0.4374],\n",
       "         [ 0.7486, -0.3318,  1.1627,  ..., -0.6981,  0.7330, -0.5773]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state #最后一个时间步的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1b912-0654-446a-a0d9-79ced93a9ee1",
   "metadata": {},
   "source": [
    "这里的确已经输出了bert的结果，然而预训练的 BERT 模型（如 BertModel）并没有直接针对具体的任务（如句子分类）进行训练。预训练模型只是通过在大规模文本上进行无监督学习，掌握了语言的基本结构和语义关系。但是，BERT 模型本身并不知道具体的分类标签，也没有针对分类任务进行过训练。\n",
    "\n",
    "> **如何知道模型的训练任务和标签？**\n",
    "- 查看模型卡（Model Card）：在 Hugging Face Model Hub 上，每个模型都有一个详细描述的页面，通常称为“模型卡”。模型卡会包含模型的训练任务、使用的数据集、任务类型（如分类、生成、翻译等）以及性能指标等信息。\n",
    "\n",
    "你可以通过阅读模型卡来了解模型是否经过针对你所需任务的训练。\n",
    "\n",
    "- 从预训练模型到任务特定模型：\n",
    "\n",
    "预训练模型（如 BertModel）只是学习了语言的基本表示，但它并没有被训练来执行特定任务，如句子分类、问答、命名实体识别等。任务特定模型 是基于预训练模型，进一步在特定任务的数据集上进行了微调（Fine-tuning），这样模型不仅能够理解语义，还能进行特定任务的推理。例如，BertForSequenceClassification 就是一个基于 BERT 的模型，专门针对分类任务进行了微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a95fcf-bc09-41ce-84c1-024c76abc0b0",
   "metadata": {},
   "source": [
    "> **怎么让预训练模型被应用于具体的任务的推理？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f341695-a704-49d1-b29e-312df70bec76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.5286,  0.7087]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.2249, 0.7751]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "# 加载BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(PATH,'bert-base-chinese'))\n",
    "model = BertModel.from_pretrained(os.path.join(PATH,'bert-base-chinese'))\n",
    "\n",
    "# 定义句子分类器\n",
    "class BertSentenceClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertSentenceClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 获取BERT的输出\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # 获取[CLS] token的表示\n",
    "        pooler_output = outputs.pooler_output\n",
    "        # 将其输入到分类器中\n",
    "        logits = self.classifier(pooler_output)\n",
    "        return logits\n",
    "\n",
    "# 示例文本\n",
    "text = \"虽然今天下雨了，但我拿到了心仪的offer，因此非常开心！\"\n",
    "\n",
    "# 将文本转化为BERT的输入格式\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# 初始化分类器，假设我们有两个分类标签（如：积极和消极）\n",
    "classifier = BertSentenceClassifier(model, num_classes=2)\n",
    "\n",
    "# 获取分类结果\n",
    "logits = classifier(encoded_input['input_ids'], encoded_input['attention_mask'])\n",
    "\n",
    "# 将logits转换为概率（如果需要）\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "# 打印分类结果\n",
    "print(\"Logits:\", logits)\n",
    "print(\"Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4afd16-9325-460b-afa5-552ef2dcb70f",
   "metadata": {},
   "source": [
    "输出为1的概率为0.7751，句子被判断为“积极”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86233d7f-9718-45c4-8bc3-bef548a2258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"虽然我拿到了心仪的offer，但是今天下了暴雨，我整个人都被淋湿了，offer也湿了，简直太糟了！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "563ce33d-7ab0-4242-ba53-a697ae4dbaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ 0.0376, -0.7682]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.6912, 0.3088]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 将文本转化为BERT的输入格式\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# 初始化分类器，假设我们有两个分类标签（如：积极和消极）\n",
    "classifier = BertSentenceClassifier(model, num_classes=2)\n",
    "\n",
    "# 获取分类结果\n",
    "logits = classifier(encoded_input['input_ids'], encoded_input['attention_mask'])\n",
    "\n",
    "# 将logits转换为概率（如果需要）\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "# 打印分类结果\n",
    "print(\"Logits:\", logits)\n",
    "print(\"Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05846b09-646f-4a77-a5b2-6320d2335818",
   "metadata": {},
   "source": [
    "随着情绪的变化，输出的概率也发生了变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5ba40-50b4-4ca3-a085-7c0018031578",
   "metadata": {},
   "source": [
    "- **尝试调用GPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ffd90-1e3f-49c8-bb25-7eb88bc8be7e",
   "metadata": {},
   "source": [
    "目前为止Huggingface依然只支持调用GPT2，如果要调用GPT3.5甚至4.0则需要直接使用OpenAI所提供的API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5231760b-4227-4e15-b166-37ceb9436af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "PATH = r\"HuggingfaceModels/\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(os.path.join(PATH,'gpt2'))\n",
    "model = GPT2Model.from_pretrained(os.path.join(PATH,'gpt2'))\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ec7aa07-a134-42da-937d-3cf6c7eb7a87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.1629, -0.2166, -0.1410,  ..., -0.2619, -0.0819,  0.0092],\n",
       "         [ 0.4628,  0.0248, -0.0785,  ..., -0.0859,  0.5122, -0.3939],\n",
       "         [-0.0644,  0.1551, -0.6306,  ...,  0.2488,  0.3691,  0.0833],\n",
       "         ...,\n",
       "         [-0.5591, -0.4490, -1.4540,  ...,  0.1650, -0.1302, -0.3740],\n",
       "         [ 0.1400, -0.3875, -0.7916,  ..., -0.1780,  0.1824,  0.2185],\n",
       "         [ 0.1721, -0.2420, -0.1124,  ..., -0.1068,  0.1205, -0.3213]]],\n",
       "       grad_fn=<ViewBackward0>), past_key_values=((tensor([[[[-1.0719,  2.4170,  0.9660,  ..., -0.4787, -0.3316,  1.7925],\n",
       "          [-2.2897,  2.5424,  0.8317,  ..., -0.5299, -2.4828,  1.3537],\n",
       "          [-2.2856,  2.7125,  2.4725,  ..., -1.4911, -1.8427,  1.6493],\n",
       "          ...,\n",
       "          [-3.3203,  2.3325,  2.7061,  ..., -1.1569, -1.5586,  2.4076],\n",
       "          [-2.9917,  2.2701,  2.1742,  ..., -0.8670, -1.6410,  1.9237],\n",
       "          [-2.5066,  2.6140,  2.1347,  ..., -0.0627, -2.0542,  1.6568]],\n",
       "\n",
       "         [[ 0.4796, -0.1131, -1.4854,  ...,  1.1607,  1.8412,  1.3682],\n",
       "          [-0.7273, -1.1362, -1.0850,  ..., -0.6736,  3.2618,  0.2099],\n",
       "          [-1.4441, -3.0647, -4.1612,  ..., -1.4788,  3.2718, -0.2803],\n",
       "          ...,\n",
       "          [ 0.8515, -0.1599,  0.1157,  ..., -0.8959,  4.1178,  0.7133],\n",
       "          [-0.0769, -1.7673, -1.1207,  ..., -1.6276,  3.1095,  1.0237],\n",
       "          [-0.9118, -0.3267, -2.0409,  ..., -0.3527,  1.1626,  0.3733]],\n",
       "\n",
       "         [[-0.2338, -0.8688,  1.6542,  ..., -1.5964, -1.5636,  1.0931],\n",
       "          [ 0.3698,  0.4929,  1.4155,  ..., -2.0162, -1.0246,  1.9822],\n",
       "          [ 0.4509,  1.0144,  0.1189,  ..., -3.1880,  0.4529,  1.3746],\n",
       "          ...,\n",
       "          [ 0.3303,  0.8695, -0.6507,  ..., -2.7196,  0.2950,  1.9827],\n",
       "          [ 0.5777,  0.4363,  1.1029,  ..., -3.2317,  0.9627,  2.1703],\n",
       "          [-0.2861, -0.2032,  0.7289,  ..., -2.3039,  1.2637,  1.9519]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4012, -0.0278, -0.1031,  ...,  0.2614,  0.9767,  0.5994],\n",
       "          [ 0.2222,  0.3167, -0.2024,  ...,  0.9616,  0.3658,  1.0162],\n",
       "          [ 0.3276,  0.0629,  0.1905,  ...,  1.0855,  0.8707,  0.0940],\n",
       "          ...,\n",
       "          [ 0.2403, -0.0951,  0.1646,  ...,  0.3345,  0.2687,  0.2159],\n",
       "          [ 0.2873,  0.0887, -0.0544,  ...,  1.0306,  0.3196,  0.5268],\n",
       "          [-0.0552, -0.0461,  0.0765,  ...,  1.0465,  0.2690,  0.4687]],\n",
       "\n",
       "         [[ 0.9759,  1.3121, -0.6612,  ..., -0.3228,  1.1476, -1.2349],\n",
       "          [ 1.0862,  0.3406, -0.6767,  ..., -1.0748,  1.4611,  0.6789],\n",
       "          [ 0.6566,  0.1325, -0.5036,  ..., -1.9292,  1.4180,  0.0719],\n",
       "          ...,\n",
       "          [ 1.1746, -0.0249, -1.0666,  ..., -0.9283,  1.2044, -0.7485],\n",
       "          [ 1.2952,  0.0145, -0.4903,  ..., -1.0618,  0.9241,  0.0928],\n",
       "          [ 0.9810,  0.0274, -0.2624,  ..., -0.8447,  0.3484, -0.2251]],\n",
       "\n",
       "         [[ 0.6922,  0.4421,  0.2786,  ..., -0.2213,  0.2488,  1.8778],\n",
       "          [-0.1203, -0.2795, -0.0287,  ..., -0.2255,  0.5681,  1.2821],\n",
       "          [ 0.3923,  0.6569,  0.0967,  ..., -0.0928,  0.2676,  2.2244],\n",
       "          ...,\n",
       "          [ 0.4983, -0.2781,  0.9789,  ...,  0.5424,  1.0169,  1.1159],\n",
       "          [-0.8550,  0.5215, -0.2168,  ..., -0.1893,  0.9473,  0.7673],\n",
       "          [-0.9623,  0.1968,  1.1720,  ..., -0.4878,  0.9685, -0.6823]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.5844e-02,  4.5047e-02, -3.2349e-02,  ...,  1.1302e-01,\n",
       "            3.4111e-03, -7.3823e-02],\n",
       "          [ 2.4216e-02, -2.3168e-01,  7.9895e-02,  ..., -3.9604e-02,\n",
       "            1.3466e-01, -8.8950e-02],\n",
       "          [ 1.3182e-01,  4.2661e-02,  7.7161e-03,  ...,  1.1645e-01,\n",
       "            1.4362e-01, -3.0297e-02],\n",
       "          ...,\n",
       "          [ 5.1271e-02, -1.0683e-02,  1.3832e-01,  ...,  4.6392e-02,\n",
       "           -7.1929e-02,  3.3192e-01],\n",
       "          [ 4.0427e-02,  3.1326e-02,  7.5804e-03,  ...,  6.6739e-02,\n",
       "           -9.5121e-02,  2.2703e-02],\n",
       "          [-2.5431e-01,  9.7892e-02, -3.1401e-01,  ..., -5.9719e-02,\n",
       "            8.7119e-02, -1.5292e-01]],\n",
       "\n",
       "         [[ 4.6511e-01,  2.9299e-01, -2.6004e-01,  ..., -4.8896e-01,\n",
       "           -3.9832e-01,  5.1992e-02],\n",
       "          [ 3.6216e-01, -2.1008e-01,  2.3111e-01,  ...,  1.2695e-02,\n",
       "           -9.8508e-03, -1.9051e-01],\n",
       "          [ 5.0594e-01, -2.8700e-01, -3.7256e-02,  ...,  1.3379e-01,\n",
       "            1.4818e-01, -7.0381e-02],\n",
       "          ...,\n",
       "          [ 4.5519e-01,  2.2482e-01,  2.7037e-02,  ..., -7.6202e-02,\n",
       "            1.3018e-01,  1.1114e-01],\n",
       "          [ 4.3946e-01,  5.6358e-02, -2.8075e-01,  ...,  3.8331e-02,\n",
       "            2.8041e-01, -1.0264e-01],\n",
       "          [ 5.5593e-01, -7.1407e-02,  8.1584e-03,  ...,  7.4966e-02,\n",
       "            5.5887e-01, -1.0753e-01]],\n",
       "\n",
       "         [[-3.5264e-02,  5.7019e-02, -7.3887e-02,  ..., -1.2185e-02,\n",
       "           -8.9059e-02, -1.0759e-01],\n",
       "          [-1.4517e-01, -1.1093e-01, -3.1237e-01,  ...,  7.9632e-03,\n",
       "            1.0515e-01, -6.8205e-02],\n",
       "          [-2.9723e-01, -1.0871e-01, -3.7647e-01,  ..., -4.4998e-01,\n",
       "           -3.9353e-01, -5.8729e-02],\n",
       "          ...,\n",
       "          [ 3.6986e-01,  3.6383e-01,  8.8384e-02,  ..., -2.8474e-01,\n",
       "           -2.1211e-01, -4.2789e-01],\n",
       "          [ 5.1485e-01,  1.4955e-02,  1.9848e-01,  ...,  1.8763e-03,\n",
       "           -4.4840e-02, -1.9523e-01],\n",
       "          [-3.1557e-01, -7.7205e-02,  1.2237e-01,  ..., -9.9081e-03,\n",
       "           -9.1467e-02, -1.1786e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6929e-01, -1.6863e-01, -1.3075e-01,  ..., -4.5507e-02,\n",
       "            1.6489e-02, -4.9244e-03],\n",
       "          [-1.8289e-01, -7.3011e-02,  8.9083e-02,  ...,  2.8579e-01,\n",
       "            1.6520e-01,  3.9901e-01],\n",
       "          [ 1.8149e-02,  1.4864e-01,  1.3995e-01,  ..., -2.0186e-01,\n",
       "           -3.1164e-01,  1.8832e-01],\n",
       "          ...,\n",
       "          [ 1.8829e-01,  3.7086e-01,  2.2190e-02,  ..., -4.3816e-01,\n",
       "           -4.5873e-02, -2.3247e-01],\n",
       "          [-6.9325e-02,  2.2089e-01, -5.2158e-02,  ..., -5.8085e-05,\n",
       "           -4.4376e-02, -2.3630e-02],\n",
       "          [-1.4491e-01, -7.6687e-01, -1.0080e-02,  ...,  1.4490e-01,\n",
       "           -1.4273e-01,  1.1995e-02]],\n",
       "\n",
       "         [[ 1.1663e-01, -9.5174e-02, -8.0097e-02,  ...,  1.1799e-01,\n",
       "            1.4442e-01,  8.0563e-02],\n",
       "          [-4.0979e-01,  1.7985e-01,  6.2052e-02,  ..., -4.6011e-01,\n",
       "           -1.5909e-01,  1.6538e-01],\n",
       "          [ 1.0707e-01, -1.4439e-01, -3.8615e-02,  ..., -3.1468e-01,\n",
       "           -1.1422e-01,  1.1694e-01],\n",
       "          ...,\n",
       "          [-8.9047e-02, -5.7536e-02, -1.4755e-01,  ..., -4.0699e-01,\n",
       "           -1.5711e-01, -2.4647e-01],\n",
       "          [-5.0915e-02,  8.4827e-02,  5.0269e-02,  ..., -2.7516e-02,\n",
       "           -2.4682e-01, -1.2400e-01],\n",
       "          [-4.0786e-02, -6.3005e-02, -5.9178e-02,  ...,  1.9072e-01,\n",
       "            2.5695e-01,  1.3483e-01]],\n",
       "\n",
       "         [[-1.4032e-01, -2.1724e-01,  2.1163e-01,  ...,  1.1325e-02,\n",
       "           -1.6940e-01, -5.6700e-02],\n",
       "          [ 1.6501e-01,  1.4751e-01,  1.2316e-01,  ...,  5.2810e-01,\n",
       "            3.7520e-01,  5.6596e-02],\n",
       "          [-1.6167e-01, -9.5173e-02, -3.0007e-01,  ..., -1.3899e-01,\n",
       "            7.6265e-02,  1.5000e-01],\n",
       "          ...,\n",
       "          [ 1.9036e-02, -4.1325e-01, -5.3456e-02,  ...,  1.0850e-01,\n",
       "            3.1322e-01,  7.4104e-02],\n",
       "          [ 4.7433e-02,  8.3881e-02, -5.8630e-02,  ...,  5.6656e-02,\n",
       "           -1.4553e-01,  1.3967e-01],\n",
       "          [ 1.1568e-01, -1.1512e-01, -3.7184e-02,  ...,  9.3072e-02,\n",
       "            9.4980e-02,  5.2496e-03]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3234e-01,  1.7469e+00, -1.3506e+00,  ...,  1.3035e+00,\n",
       "           -1.1436e+00,  1.3027e+00],\n",
       "          [ 3.7144e-01,  1.5962e+00, -9.8959e-01,  ..., -3.7702e-01,\n",
       "           -1.6238e+00,  4.9728e-01],\n",
       "          [ 1.5475e+00,  1.7371e+00, -1.1542e+00,  ...,  2.6362e-02,\n",
       "           -2.4185e+00,  6.0650e-02],\n",
       "          ...,\n",
       "          [ 1.1640e+00,  2.7594e-01, -3.8811e-01,  ...,  9.9817e-01,\n",
       "           -2.4461e-01, -2.2513e+00],\n",
       "          [ 9.1530e-02,  1.3589e+00,  5.4383e-02,  ...,  9.0260e-01,\n",
       "           -2.1145e+00, -1.0515e+00],\n",
       "          [-2.3758e-01,  4.2933e-01,  2.5327e-01,  ...,  6.8149e-01,\n",
       "           -7.0189e-01, -1.3681e-01]],\n",
       "\n",
       "         [[-1.4716e+00, -7.0062e-01, -8.4053e-01,  ..., -3.4795e-01,\n",
       "            9.0868e-01, -5.7943e-01],\n",
       "          [-6.7887e-01, -8.5541e-01, -1.9801e+00,  ..., -1.3131e+00,\n",
       "           -2.7207e-01,  1.9432e-01],\n",
       "          [-8.6449e-01,  1.6245e-02, -1.5927e+00,  ..., -1.5577e-01,\n",
       "            4.3638e-01,  3.4525e-01],\n",
       "          ...,\n",
       "          [-8.9806e-01,  3.8957e-01, -1.8324e+00,  ..., -3.9667e-01,\n",
       "           -9.1773e-01, -5.6276e-01],\n",
       "          [-5.7540e-01,  9.9297e-01, -1.6385e+00,  ..., -2.2806e-01,\n",
       "            3.7440e-01, -1.2218e+00],\n",
       "          [-5.3996e-01,  1.2337e+00, -1.4777e+00,  ..., -1.9485e-01,\n",
       "           -7.1104e-01, -6.1031e-01]],\n",
       "\n",
       "         [[ 3.3298e-01,  1.1988e-01, -2.9469e-02,  ..., -1.2560e+00,\n",
       "            1.5321e-01, -2.1866e-01],\n",
       "          [ 3.3311e-01,  6.0988e-01, -3.2191e-01,  ..., -1.2439e+00,\n",
       "           -7.9251e-02,  7.9439e-02],\n",
       "          [-1.3959e-01,  2.9871e-01, -1.1090e-01,  ..., -8.7817e-01,\n",
       "           -2.1968e-01,  5.7344e-01],\n",
       "          ...,\n",
       "          [-1.1917e-01, -1.2049e-01,  8.8956e-02,  ..., -1.0531e+00,\n",
       "            2.7097e-01,  2.8109e-01],\n",
       "          [-1.6320e-01, -2.1190e-01, -2.8066e-01,  ..., -1.1110e+00,\n",
       "           -1.1413e-01,  3.4103e-01],\n",
       "          [-1.9088e-01, -2.2637e-01, -1.9520e-01,  ..., -1.3609e+00,\n",
       "            7.7477e-03,  5.4753e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1961e-01, -5.4149e-01, -6.5129e-01,  ..., -1.3049e-01,\n",
       "            6.4293e-01, -1.0648e+00],\n",
       "          [-1.1139e+00,  1.7472e+00,  1.9236e+00,  ..., -5.2888e-01,\n",
       "           -8.8113e-01, -1.1274e+00],\n",
       "          [-3.5029e-02,  1.6498e+00,  1.5704e+00,  ...,  1.8705e+00,\n",
       "            4.4842e-01,  1.7473e-01],\n",
       "          ...,\n",
       "          [ 2.8044e-02,  1.5038e+00,  1.7172e+00,  ..., -1.5435e-01,\n",
       "           -7.6511e-01, -8.1489e-01],\n",
       "          [-6.5315e-01,  1.2453e+00,  1.9217e+00,  ...,  6.9396e-01,\n",
       "           -1.3474e+00, -1.1424e+00],\n",
       "          [-4.9458e-01,  1.4317e+00,  1.6529e+00,  ...,  5.9429e-01,\n",
       "           -1.7269e+00, -3.5413e-01]],\n",
       "\n",
       "         [[-1.2016e+00, -2.7812e+00,  1.2903e-01,  ...,  1.6795e+00,\n",
       "            1.5993e+00, -1.5680e+00],\n",
       "          [-2.4824e-01,  9.6243e-01, -6.0818e-01,  ..., -6.4028e-01,\n",
       "            7.3015e-01,  1.6933e-03],\n",
       "          [ 3.7342e-01,  7.0263e-01, -5.0011e-01,  ..., -6.0883e-01,\n",
       "            4.8429e-01, -9.1718e-02],\n",
       "          ...,\n",
       "          [-2.1023e-01, -1.1352e-01, -8.6533e-01,  ..., -4.3357e-01,\n",
       "            1.0432e+00,  2.3951e-01],\n",
       "          [-3.5406e-01,  3.6508e-01, -7.0875e-01,  ..., -1.5285e-01,\n",
       "            9.8004e-01,  3.0699e-01],\n",
       "          [-3.1061e-01,  2.6206e-01, -7.0317e-01,  ..., -3.8614e-01,\n",
       "            7.4612e-01, -1.0789e-01]],\n",
       "\n",
       "         [[ 1.2471e+00,  1.8337e+00,  1.4891e+00,  ..., -2.7984e-01,\n",
       "            8.3699e-02, -4.6373e-01],\n",
       "          [-7.5648e-03,  2.5955e+00,  5.7040e-01,  ...,  1.0415e+00,\n",
       "           -1.6044e-01, -3.6244e-01],\n",
       "          [ 7.7530e-02,  2.8104e+00,  1.5624e+00,  ...,  1.5091e+00,\n",
       "           -1.8090e-02, -1.2300e+00],\n",
       "          ...,\n",
       "          [-4.7830e-01,  2.4190e+00,  2.3556e+00,  ...,  1.7733e+00,\n",
       "           -1.6757e+00, -2.5219e+00],\n",
       "          [ 9.0538e-02,  3.3119e+00, -3.6678e-01,  ...,  2.4436e+00,\n",
       "           -1.6148e+00, -2.1822e+00],\n",
       "          [ 5.6891e-01,  1.7215e+00,  7.9348e-01,  ..., -6.3631e-01,\n",
       "           -4.2486e-01,  1.1764e-02]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 1.8121e-01, -1.3411e-01, -2.1478e-01,  ...,  7.0410e-02,\n",
       "            2.1432e-01, -4.1736e-01],\n",
       "          [-3.4722e-01, -2.4165e-01, -3.5845e-01,  ..., -4.0393e-03,\n",
       "            6.8928e-01,  6.3408e-01],\n",
       "          [ 1.8921e-01,  1.1412e-01, -3.7454e-01,  ..., -6.1886e-01,\n",
       "            1.5584e-01, -3.3977e-01],\n",
       "          ...,\n",
       "          [-9.8094e-01, -3.1039e-01, -4.3409e-02,  ...,  8.2431e-01,\n",
       "            1.2980e-02,  3.8810e-03],\n",
       "          [ 3.3090e-01, -8.1123e-02,  1.0761e-01,  ..., -2.8871e-01,\n",
       "            4.1475e-01,  4.9912e-01],\n",
       "          [ 6.5354e-01,  1.7933e-01,  9.7152e-02,  ..., -9.8650e-02,\n",
       "           -1.9800e-01, -7.1575e-02]],\n",
       "\n",
       "         [[-1.2948e-01, -1.3113e-01,  3.0471e-01,  ..., -9.5208e-02,\n",
       "           -5.2637e-01,  2.0391e-02],\n",
       "          [-5.2768e-01, -2.4699e-01, -1.2828e-01,  ..., -1.3858e-01,\n",
       "            1.6376e-01,  3.1491e-01],\n",
       "          [ 3.4299e-02,  2.9798e-01, -1.8136e-01,  ...,  3.7112e-01,\n",
       "           -1.1525e-02, -2.1673e-01],\n",
       "          ...,\n",
       "          [-8.4663e-03, -1.8613e-01,  2.7562e-01,  ...,  4.4664e-01,\n",
       "           -1.5165e-01, -5.9345e-01],\n",
       "          [ 2.7736e-01, -5.3698e-01,  1.0314e+00,  ...,  1.0592e-01,\n",
       "           -1.0284e-01, -2.0281e-01],\n",
       "          [ 3.6434e-01, -1.9135e-02,  1.0105e-01,  ...,  1.8952e-01,\n",
       "            2.6101e-01, -4.4438e-02]],\n",
       "\n",
       "         [[ 4.5340e-02, -4.0817e-01,  5.3539e-02,  ..., -4.7963e-01,\n",
       "           -2.8298e-01,  2.7899e-02],\n",
       "          [ 8.4529e-01,  9.4444e-02,  2.4181e-02,  ..., -7.5536e-01,\n",
       "           -4.6340e-02,  1.8064e-01],\n",
       "          [ 8.0320e-01,  1.4924e-01,  5.8457e-01,  ..., -8.3811e-01,\n",
       "            1.0063e-01,  2.5599e-01],\n",
       "          ...,\n",
       "          [ 9.6557e-01, -9.7738e-02,  2.9157e-02,  ..., -3.4948e-01,\n",
       "            1.6999e-01, -1.4430e-01],\n",
       "          [ 8.1042e-01, -2.8220e-02, -1.2203e-01,  ..., -3.2469e-01,\n",
       "           -2.2869e-01,  4.6458e-01],\n",
       "          [ 4.8326e-01,  1.9731e-01,  2.5365e-01,  ..., -9.5574e-02,\n",
       "           -1.1013e-01, -3.0431e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4653e-01,  6.2398e-01, -1.6506e-01,  ...,  1.2628e-01,\n",
       "           -9.4077e-01, -1.0024e-01],\n",
       "          [ 8.5481e-02, -3.7416e-01,  6.1154e-02,  ...,  2.1396e-01,\n",
       "           -6.8562e-01, -1.3296e-01],\n",
       "          [-2.7189e-01,  7.6011e-02,  5.0749e-01,  ...,  6.4782e-02,\n",
       "           -6.3529e-01, -3.4742e-01],\n",
       "          ...,\n",
       "          [-1.5075e-01,  1.6193e-01,  4.4225e-01,  ...,  5.5478e-01,\n",
       "            9.6686e-02,  1.3932e-02],\n",
       "          [ 2.9651e-02, -3.2289e-01, -3.7855e-01,  ...,  2.1001e-01,\n",
       "           -5.2798e-01,  7.2306e-01],\n",
       "          [ 5.7423e-02, -8.9264e-01,  3.6512e-01,  ...,  2.4724e-01,\n",
       "           -7.7394e-01, -2.8834e-01]],\n",
       "\n",
       "         [[ 1.9841e-01, -1.6214e-01,  8.8751e-02,  ...,  3.8060e-01,\n",
       "           -3.5175e+00, -4.8737e-02],\n",
       "          [ 4.8521e-02, -4.2689e-01,  2.9560e-03,  ...,  4.1736e-01,\n",
       "            3.3645e-02, -1.3576e-01],\n",
       "          [-2.3386e-01,  4.3437e-02,  1.9538e-01,  ...,  2.6902e-02,\n",
       "            7.1384e-02,  8.4704e-02],\n",
       "          ...,\n",
       "          [-1.4845e-03,  1.7191e-01, -5.1814e-01,  ...,  2.2445e-01,\n",
       "           -1.5839e-01,  1.5118e-01],\n",
       "          [ 1.7462e-02, -2.2360e-03,  4.6600e-01,  ...,  6.4922e-02,\n",
       "            3.4853e-02,  1.8072e-01],\n",
       "          [ 4.1400e-01,  1.7019e-01,  2.7337e-02,  ...,  1.4135e-01,\n",
       "           -1.5423e-01,  7.8442e-02]],\n",
       "\n",
       "         [[-5.0851e-02, -5.9927e-02, -5.6214e-02,  ..., -2.0252e-01,\n",
       "            1.2368e-01, -3.3855e-02],\n",
       "          [-1.1510e-02, -7.6934e-02,  2.3691e-01,  ...,  6.5874e-02,\n",
       "            1.5217e-02,  1.8671e-01],\n",
       "          [ 1.5296e-01, -1.3156e-01,  1.3923e-01,  ...,  1.8831e-01,\n",
       "           -8.2086e-02,  1.2744e-01],\n",
       "          ...,\n",
       "          [ 3.9660e-02,  2.4684e-01,  1.9528e-01,  ..., -9.5808e-02,\n",
       "            1.7549e-01, -6.6854e-03],\n",
       "          [ 8.3237e-02,  1.1592e-01, -5.2513e-02,  ..., -3.2532e-02,\n",
       "            2.5978e-01,  1.4565e-01],\n",
       "          [ 1.2382e-01, -1.1883e-02,  5.0095e-01,  ..., -1.0735e-02,\n",
       "            1.1066e-01,  1.8190e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1322, -1.1527,  0.3087,  ..., -0.6205, -0.1060, -0.0181],\n",
       "          [ 0.5456, -2.5518, -0.2942,  ..., -1.2907,  0.0803,  0.1253],\n",
       "          [ 0.9459, -2.5900,  0.3366,  ...,  0.2387,  0.0244, -0.0984],\n",
       "          ...,\n",
       "          [-1.4713, -1.8862, -0.5822,  ..., -0.4205, -0.2317, -0.3811],\n",
       "          [-0.4795, -1.7547,  0.5800,  ...,  1.0587,  0.7753, -1.0023],\n",
       "          [-0.2153, -2.2462, -0.5551,  ...,  1.7418,  0.0601, -0.8750]],\n",
       "\n",
       "         [[-0.4981,  0.4839, -0.4288,  ...,  1.2952, -0.4981, -0.4568],\n",
       "          [-1.4536, -0.2465, -0.9163,  ...,  0.4530,  0.6458,  0.4874],\n",
       "          [-1.6652, -0.9680, -1.0875,  ..., -0.0277,  1.3271, -0.3510],\n",
       "          ...,\n",
       "          [-2.1762, -0.6636, -1.8135,  ..., -0.9017,  1.3285,  0.1540],\n",
       "          [-1.3590, -1.9787, -1.5488,  ..., -1.1410,  1.3344, -0.2104],\n",
       "          [-1.4276, -0.6944, -0.5667,  ...,  1.1990,  0.8454, -0.3241]],\n",
       "\n",
       "         [[ 1.3747,  3.0648,  3.7658,  ...,  0.6805,  1.6251, -0.7113],\n",
       "          [-3.6194,  2.6739, -2.5109,  ..., -3.2047,  2.9450, -0.3144],\n",
       "          [-3.1928,  1.5469, -3.1628,  ..., -2.9214,  3.4801,  1.2360],\n",
       "          ...,\n",
       "          [-4.6832, -1.4904, -4.8171,  ..., -3.4247,  1.8220,  0.7462],\n",
       "          [-4.9916, -1.4019, -5.5591,  ..., -3.7371,  2.9422,  0.6384],\n",
       "          [-3.3272, -1.9141, -4.6821,  ..., -3.4394,  3.4462,  0.7966]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3571, -2.6940, -2.5864,  ...,  0.9747,  0.4724,  2.7245],\n",
       "          [-3.2790,  1.4895,  0.4607,  ...,  0.6635, -1.8444, -0.3443],\n",
       "          [-3.4600,  2.6956,  1.3558,  ..., -0.1266, -2.7145,  0.0972],\n",
       "          ...,\n",
       "          [-3.1993,  4.0702,  1.9383,  ..., -0.9552, -3.1067, -1.4688],\n",
       "          [-3.8521,  4.6710,  2.9112,  ..., -2.2364, -3.9045, -1.5241],\n",
       "          [-3.5332,  4.3554,  2.3162,  ..., -0.6138, -2.1636, -1.3958]],\n",
       "\n",
       "         [[ 1.7131,  0.4496,  0.9466,  ...,  0.0104, -0.9866, -0.3256],\n",
       "          [ 2.1683,  0.8876,  1.4803,  ...,  0.1768, -1.8011, -1.9908],\n",
       "          [ 2.0806,  1.0288,  1.1972,  ..., -0.0733, -1.5057, -1.4346],\n",
       "          ...,\n",
       "          [ 1.9361,  0.8342,  1.0479,  ..., -0.0835, -1.9249, -1.2110],\n",
       "          [ 2.2447,  0.3010,  1.0368,  ..., -0.2990, -1.8205, -1.2766],\n",
       "          [ 1.7111,  0.2756,  0.7408,  ...,  0.0539, -1.9953, -0.9998]],\n",
       "\n",
       "         [[-0.2538,  0.1160, -0.5586,  ...,  0.2681,  0.2844,  0.1296],\n",
       "          [-0.2222,  0.8479, -0.4422,  ..., -0.2732,  0.8777,  0.8108],\n",
       "          [-0.6727,  0.5071,  0.0572,  ...,  0.0786,  0.3229,  0.3834],\n",
       "          ...,\n",
       "          [ 0.2167, -0.1937, -1.1421,  ..., -0.4700,  0.8094, -0.1040],\n",
       "          [-0.4399,  0.3740,  0.0801,  ..., -0.2625,  0.2348, -0.2820],\n",
       "          [-0.7647, -0.3623, -0.5461,  ...,  0.6692,  0.6866,  0.8584]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.6110e-02, -6.3370e-03, -1.2897e-01,  ..., -2.7515e-02,\n",
       "            3.0886e-02, -5.4642e-01],\n",
       "          [ 2.8421e-01, -8.6539e-01, -2.9025e-01,  ...,  2.3311e-01,\n",
       "           -8.4891e-01,  1.3338e+00],\n",
       "          [ 2.4186e-01, -2.5358e-01, -8.4709e-01,  ..., -4.7114e-01,\n",
       "           -4.3807e-01,  8.2508e-01],\n",
       "          ...,\n",
       "          [ 5.8147e-01, -8.3756e-01,  1.4188e-02,  ...,  6.5366e-01,\n",
       "            3.2311e-01,  1.0884e+00],\n",
       "          [ 2.4318e-02, -4.3096e-01, -1.3149e-01,  ..., -2.2943e-01,\n",
       "            4.7279e-01,  6.5807e-01],\n",
       "          [ 1.6472e-01,  1.1389e+00, -1.3656e+00,  ...,  3.6690e-01,\n",
       "            5.6864e-01, -9.9857e-01]],\n",
       "\n",
       "         [[ 3.3488e-02, -2.1709e-02,  3.1775e-02,  ..., -3.6363e-02,\n",
       "           -2.0804e-02,  7.0153e-02],\n",
       "          [-2.9799e-02,  6.2118e-01, -3.6438e-01,  ...,  4.9335e-02,\n",
       "           -1.8000e-01,  3.8404e-01],\n",
       "          [-4.7976e-01,  1.9055e-02, -1.4230e+00,  ..., -4.2935e-01,\n",
       "            4.5856e-01,  1.0601e-01],\n",
       "          ...,\n",
       "          [-1.1260e+00, -6.7430e-02, -1.2505e+00,  ...,  9.8989e-01,\n",
       "            2.0997e-01,  6.6872e-01],\n",
       "          [-3.0780e-01, -2.7036e-02,  7.3606e-01,  ..., -1.8043e-01,\n",
       "           -6.6422e-02, -4.7701e-01],\n",
       "          [-5.7836e-02, -1.4135e-02,  2.8287e-01,  ..., -1.8417e-01,\n",
       "           -1.4725e-01,  1.0323e-01]],\n",
       "\n",
       "         [[ 6.9997e-03, -7.2047e-01, -1.4875e-02,  ...,  5.4531e-02,\n",
       "            3.6829e-02, -1.3042e-02],\n",
       "          [ 7.3096e-01, -1.3004e+00,  2.5491e-02,  ..., -2.0688e-01,\n",
       "            2.1388e-01, -1.9886e-01],\n",
       "          [-5.9057e-01, -1.3042e+00,  1.9017e-01,  ..., -1.8207e-01,\n",
       "           -3.5321e-03,  3.4668e-01],\n",
       "          ...,\n",
       "          [ 4.1662e-01, -4.3040e-01,  4.1711e-01,  ..., -7.3938e-01,\n",
       "           -1.8402e-01, -3.6389e-01],\n",
       "          [-1.5217e-02, -1.5639e+00, -5.2417e-01,  ..., -2.4254e-01,\n",
       "           -2.1576e-01,  3.0141e-01],\n",
       "          [ 1.0562e-01, -1.4539e+00, -1.0584e-01,  ..., -1.0705e-01,\n",
       "            3.9389e-02, -1.4812e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0108e-02, -5.6756e-02,  1.3052e+00,  ...,  1.0925e-03,\n",
       "            1.9278e-01, -2.0602e-03],\n",
       "          [-2.6232e-02,  3.2866e-01,  1.9221e+00,  ...,  1.4766e-01,\n",
       "           -6.7259e-02,  2.4187e-01],\n",
       "          [-4.8278e-01, -4.2951e-01,  1.8054e+00,  ...,  3.6253e-01,\n",
       "           -3.1257e-01,  3.7770e-01],\n",
       "          ...,\n",
       "          [-1.0864e+00, -7.8481e-01,  2.2155e+00,  ..., -2.1905e-01,\n",
       "            1.4895e-01,  3.9424e-02],\n",
       "          [ 1.1841e-01, -5.9558e-01,  1.9721e+00,  ...,  4.6364e-01,\n",
       "           -2.0958e-01,  1.8704e-01],\n",
       "          [ 8.8032e-02, -3.0378e-01,  2.5235e+00,  ..., -1.3628e-01,\n",
       "            2.6798e-01,  3.4488e-01]],\n",
       "\n",
       "         [[-1.5290e-02, -6.3416e-02, -1.4310e-01,  ...,  1.6105e-01,\n",
       "            1.1368e-01,  1.8954e-01],\n",
       "          [-9.1473e-01,  2.2297e-01,  1.4207e-01,  ...,  3.7581e-02,\n",
       "           -3.2340e-01, -1.5199e-01],\n",
       "          [ 3.7227e-01, -4.9001e-01,  1.7333e-01,  ..., -1.4885e-01,\n",
       "           -6.3321e-01, -2.0094e-01],\n",
       "          ...,\n",
       "          [-4.8509e-01,  2.7552e-01,  4.1076e-01,  ...,  7.9583e-02,\n",
       "           -1.2452e-02, -6.0336e-01],\n",
       "          [ 1.9530e-01,  2.1733e-01,  3.4654e-01,  ...,  3.8038e-01,\n",
       "           -1.0907e+00, -8.6067e-02],\n",
       "          [ 6.8279e-01,  6.9183e-01,  2.1597e-01,  ...,  2.1290e-01,\n",
       "           -1.1599e-01,  4.2206e-01]],\n",
       "\n",
       "         [[ 2.3022e-02,  2.4736e-02,  1.4599e-02,  ..., -1.3392e-02,\n",
       "            2.2758e-01, -6.3206e-03],\n",
       "          [ 4.9218e-02,  5.3240e-01,  9.0467e-01,  ...,  1.1255e-01,\n",
       "           -2.0287e+00,  9.8514e-01],\n",
       "          [-4.7997e-01, -7.5515e-02, -1.9737e-01,  ..., -6.4949e-02,\n",
       "           -1.9641e+00,  1.0550e-01],\n",
       "          ...,\n",
       "          [ 5.7662e-01,  1.3777e-01,  3.1310e-02,  ...,  1.8253e-01,\n",
       "           -2.1296e+00, -1.7676e-01],\n",
       "          [ 2.4730e-01,  8.7524e-02, -3.3989e-01,  ...,  8.7951e-02,\n",
       "           -2.2735e+00, -1.8762e-01],\n",
       "          [ 3.9984e-01, -2.0190e-01,  1.6420e-02,  ..., -2.5319e-01,\n",
       "           -1.3256e+00, -2.3872e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.1604e-03, -1.8791e-01,  1.4746e-01,  ..., -8.8068e-01,\n",
       "            7.5894e-01, -1.1973e+00],\n",
       "          [-2.5677e+00,  1.7679e+00, -3.9106e+00,  ...,  1.2833e+00,\n",
       "           -1.2259e+00,  2.1156e+00],\n",
       "          [-1.6822e+00, -3.9114e-01, -1.4672e+00,  ..., -1.2825e-01,\n",
       "            5.9892e-01,  4.3527e-01],\n",
       "          ...,\n",
       "          [-1.5596e+00, -3.2880e-02,  6.3978e-01,  ...,  1.7795e+00,\n",
       "           -1.6521e+00,  2.0406e+00],\n",
       "          [-6.5270e-01, -5.5162e-01,  1.0236e+00,  ..., -5.6010e-01,\n",
       "           -1.9103e+00,  1.2966e+00],\n",
       "          [-1.0920e-01, -8.7920e-01,  1.5120e-02,  ...,  6.2073e-01,\n",
       "           -2.7510e-01,  2.1425e-01]],\n",
       "\n",
       "         [[ 8.0498e-01,  2.0352e-01,  1.7896e-02,  ..., -1.6228e-01,\n",
       "           -1.0867e+00, -2.0632e-01],\n",
       "          [ 6.3069e-01, -1.4465e+00,  5.0411e-01,  ...,  3.4637e-01,\n",
       "            5.0468e+00,  2.1150e+00],\n",
       "          [-1.1162e+00, -1.3258e+00,  6.3189e-01,  ...,  1.2063e+00,\n",
       "            4.4761e+00,  1.0679e+00],\n",
       "          ...,\n",
       "          [ 2.2878e-01, -2.3659e+00,  7.8082e-01,  ...,  1.5353e+00,\n",
       "            4.7206e+00,  1.8281e+00],\n",
       "          [-4.8325e-01, -2.4448e+00,  2.4398e-01,  ..., -2.1931e-01,\n",
       "            4.3510e+00,  2.2534e+00],\n",
       "          [-1.7464e+00, -2.7804e-02, -1.4060e+00,  ..., -8.7864e-02,\n",
       "            4.2460e+00,  1.9398e+00]],\n",
       "\n",
       "         [[ 3.3238e-01, -3.5263e-01, -3.3511e-01,  ...,  3.3173e-01,\n",
       "            1.4302e+00,  2.7422e-01],\n",
       "          [-3.7069e-01, -6.1829e+00, -2.2466e+00,  ..., -3.6439e+00,\n",
       "           -2.1060e+00, -7.4567e+00],\n",
       "          [-4.5128e-01, -5.9982e+00, -2.4673e+00,  ..., -4.1265e+00,\n",
       "           -3.8545e+00, -6.1227e+00],\n",
       "          ...,\n",
       "          [-2.1317e+00, -6.2376e+00, -4.9529e+00,  ..., -3.5573e+00,\n",
       "           -2.2995e+00, -4.4041e+00],\n",
       "          [-2.2614e+00, -7.2026e+00, -3.0679e+00,  ..., -2.5467e+00,\n",
       "           -3.5838e+00, -3.2058e+00],\n",
       "          [-3.0414e+00, -6.8481e+00, -1.5457e+00,  ..., -3.4928e+00,\n",
       "           -2.2893e+00, -5.9958e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3405e-01,  1.8003e+00,  5.3820e-01,  ...,  2.6242e-01,\n",
       "            4.4859e-01, -1.6709e+00],\n",
       "          [ 1.3520e+00, -5.1191e+00,  2.9198e+00,  ..., -8.6180e-01,\n",
       "           -1.6337e+00,  5.9583e+00],\n",
       "          [-8.9200e-02, -6.2376e+00,  4.5249e-01,  ..., -1.8860e+00,\n",
       "           -2.1434e+00,  7.1481e+00],\n",
       "          ...,\n",
       "          [ 3.8247e-01, -7.7788e+00,  2.1529e+00,  ..., -2.9409e+00,\n",
       "           -1.4936e+00,  6.4806e+00],\n",
       "          [ 5.7257e-01, -6.5320e+00,  3.4520e-01,  ..., -4.8911e+00,\n",
       "           -1.1043e+00,  6.2615e+00],\n",
       "          [ 2.3119e-02, -7.1271e+00,  1.8783e+00,  ..., -2.4430e+00,\n",
       "           -1.0648e+00,  5.3935e+00]],\n",
       "\n",
       "         [[ 7.0162e-02, -5.0270e-02,  1.6436e-01,  ..., -8.4555e-02,\n",
       "           -8.5299e-02, -1.4128e-01],\n",
       "          [ 4.7663e-01, -5.4246e-01,  6.5545e-01,  ...,  4.4172e-01,\n",
       "           -1.1501e+00, -1.4259e+00],\n",
       "          [ 1.6341e+00, -1.9560e+00, -1.2453e+00,  ..., -1.1005e+00,\n",
       "           -1.0474e-01, -3.4483e-01],\n",
       "          ...,\n",
       "          [-1.4072e-01, -1.0868e+00, -9.5867e-02,  ...,  9.9929e-01,\n",
       "            1.2154e+00,  1.0204e+00],\n",
       "          [-5.3142e-01, -5.1684e-01, -7.8924e-01,  ..., -4.3379e-01,\n",
       "           -5.0606e-01, -1.4453e-01],\n",
       "          [-1.6270e-01, -6.7944e-01,  3.7796e-02,  ..., -8.0383e-02,\n",
       "           -2.0414e-01,  3.0041e-01]],\n",
       "\n",
       "         [[ 4.0545e-01, -3.8652e-02,  1.8953e+00,  ..., -2.2526e-01,\n",
       "           -1.9901e-01, -9.9290e-01],\n",
       "          [ 3.7929e+00,  9.7979e-01, -1.5706e+00,  ...,  8.7371e-01,\n",
       "            1.3123e+00,  4.0946e+00],\n",
       "          [ 2.6437e+00,  2.8533e+00, -1.1851e+00,  ...,  1.4979e+00,\n",
       "            1.7340e+00,  2.7878e+00],\n",
       "          ...,\n",
       "          [ 3.7213e+00,  4.2312e-01, -4.0639e+00,  ...,  3.0060e+00,\n",
       "            1.1026e+00,  4.5419e+00],\n",
       "          [ 4.2811e+00,  3.5972e-01, -3.0493e+00,  ...,  3.7985e+00,\n",
       "            1.4962e+00,  5.2126e+00],\n",
       "          [ 2.6493e+00,  1.5411e+00, -3.0109e+00,  ..., -5.3203e-01,\n",
       "            6.5990e-01,  4.2414e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 3.9765e-02,  6.3191e-02,  6.3381e-04,  ...,  1.9104e-02,\n",
       "            9.9082e-02,  3.4521e-02],\n",
       "          [ 1.1378e+00, -1.2861e+00, -1.2908e-01,  ..., -3.3004e-01,\n",
       "           -1.3635e+00, -2.2904e+00],\n",
       "          [-8.1626e-02,  9.3745e-02, -2.8481e-01,  ...,  2.1468e-01,\n",
       "           -9.6816e-01,  2.9894e-01],\n",
       "          ...,\n",
       "          [ 2.1699e-01, -1.8662e-01,  3.1800e-01,  ...,  7.8086e-02,\n",
       "           -1.3018e+00,  2.1320e-01],\n",
       "          [ 7.9638e-01,  2.0152e-01,  1.0130e-01,  ...,  2.5974e-01,\n",
       "           -7.7726e-01, -7.3524e-01],\n",
       "          [-2.1013e-01, -6.6706e-01,  1.7082e-01,  ...,  4.4625e-02,\n",
       "           -2.1095e-01,  1.0726e+00]],\n",
       "\n",
       "         [[-4.9772e-02,  4.5372e-03,  8.2704e-02,  ..., -5.1366e-02,\n",
       "           -3.5350e-02, -4.1695e-02],\n",
       "          [ 9.3125e-01,  4.8477e-01,  1.2721e-02,  ...,  2.5011e-01,\n",
       "            5.0911e-01,  7.7029e-02],\n",
       "          [ 5.3607e-01,  3.6338e-01,  5.9256e-01,  ...,  1.3317e-01,\n",
       "            2.4218e-01,  5.0219e-01],\n",
       "          ...,\n",
       "          [ 9.9435e-01,  8.4734e-01, -1.4116e-02,  ..., -2.2738e-01,\n",
       "           -3.3423e-01,  7.2092e-01],\n",
       "          [ 7.0013e-01,  4.3563e-02,  9.8745e-02,  ..., -4.9008e-01,\n",
       "           -1.1142e-01,  2.7808e-01],\n",
       "          [-2.6422e-01,  3.3482e-02,  4.0394e-02,  ...,  2.1468e-01,\n",
       "            2.0354e-01, -5.8808e-02]],\n",
       "\n",
       "         [[ 2.8733e-02, -1.1324e-01, -6.5474e-02,  ..., -2.8632e-02,\n",
       "            7.8444e-02, -1.6102e-01],\n",
       "          [-4.5820e-01,  4.7828e-01,  7.0546e-02,  ...,  5.3585e-01,\n",
       "           -4.5617e-01, -2.3535e-01],\n",
       "          [-3.3743e-01, -4.2131e-02,  5.9882e-01,  ...,  2.5610e-01,\n",
       "            7.7897e-02, -4.0960e-01],\n",
       "          ...,\n",
       "          [ 7.5842e-01, -5.6218e-02, -7.4135e-01,  ...,  5.3671e-02,\n",
       "           -4.3988e-01,  1.1196e+00],\n",
       "          [-8.5638e-01,  1.0162e+00, -1.6276e+00,  ..., -5.2393e-01,\n",
       "           -5.1775e-01,  2.8000e-01],\n",
       "          [ 3.0931e-01,  9.2681e-02, -5.2069e-01,  ..., -2.1601e-01,\n",
       "           -2.4954e-01, -6.8193e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.0445e-02,  1.2575e-01, -8.2247e-03,  ..., -3.0457e-02,\n",
       "            6.6124e-02, -3.3832e-02],\n",
       "          [-7.7384e-01,  4.6625e-01, -8.6402e-01,  ...,  1.1561e+00,\n",
       "            1.9820e-01, -3.0625e-01],\n",
       "          [-2.7791e-04,  6.3935e-01, -1.8950e-01,  ...,  2.0117e-01,\n",
       "           -1.7873e-02,  5.5499e-01],\n",
       "          ...,\n",
       "          [ 7.8662e-01, -5.6376e-02,  4.7865e-01,  ..., -4.2434e-01,\n",
       "           -1.5718e-01, -4.8276e-01],\n",
       "          [ 6.4126e-01, -9.5627e-02, -9.7531e-03,  ...,  1.4783e-02,\n",
       "            3.4626e-01,  1.4248e-01],\n",
       "          [ 1.3236e-01,  2.3395e-01,  8.1249e-02,  ...,  4.1129e-01,\n",
       "            2.2832e-01,  5.4297e-02]],\n",
       "\n",
       "         [[-1.7626e-01, -1.0919e-01, -8.4360e-02,  ..., -2.3040e-01,\n",
       "           -1.7456e-02, -4.5445e-02],\n",
       "          [-7.3267e-01,  3.0908e-01, -6.8270e-01,  ...,  1.1911e+00,\n",
       "            6.0792e-01, -5.9669e-01],\n",
       "          [ 3.2711e-01, -8.1702e-01, -6.7690e-01,  ..., -1.4106e-01,\n",
       "            5.1631e-01,  1.7033e+00],\n",
       "          ...,\n",
       "          [ 6.9877e-01,  2.1668e-01,  2.2550e+00,  ...,  7.3070e-01,\n",
       "            1.5383e-01, -1.6586e-01],\n",
       "          [-1.2518e-01,  2.8480e-03,  1.7571e-01,  ...,  1.3301e-01,\n",
       "            1.5198e-01, -2.0101e-02],\n",
       "          [ 3.2786e-01,  4.0679e-01,  6.3502e-01,  ..., -9.9532e-01,\n",
       "            2.8010e-01,  1.7276e-01]],\n",
       "\n",
       "         [[ 1.2476e-01, -6.5556e-02, -2.6808e-02,  ..., -8.9693e-03,\n",
       "           -9.2486e-02, -8.6446e-02],\n",
       "          [-3.6288e-01, -4.0901e-01,  4.7382e-02,  ...,  7.5869e-01,\n",
       "            2.6507e-01, -2.3738e-01],\n",
       "          [-3.1819e-01,  4.7386e-01,  2.4661e-01,  ...,  1.0666e-02,\n",
       "            2.0598e-01, -6.8917e-01],\n",
       "          ...,\n",
       "          [-5.9656e-02,  5.2958e-01, -5.8517e-01,  ...,  2.4241e-01,\n",
       "            7.2702e-02,  4.3875e-01],\n",
       "          [-2.8286e-01, -2.9105e-01, -5.9394e-01,  ..., -1.3986e-01,\n",
       "            3.1039e-01, -5.7179e-01],\n",
       "          [ 4.7208e-01, -1.1132e-01,  2.8569e-02,  ..., -8.4543e-02,\n",
       "           -4.1679e-01,  1.1348e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-8.9410e-01, -1.4102e-01,  3.3448e-01,  ..., -9.8900e-01,\n",
       "            2.4201e-02, -2.9690e+00],\n",
       "          [ 2.0739e+00, -6.6276e-01, -9.6401e-01,  ..., -2.2700e+00,\n",
       "           -2.5282e+00,  5.5307e+00],\n",
       "          [ 1.4538e+00,  9.1335e-01, -1.2821e+00,  ..., -1.7829e+00,\n",
       "           -2.5922e+00,  7.0503e+00],\n",
       "          ...,\n",
       "          [-7.4860e-02, -1.2873e+00, -4.2342e+00,  ..., -1.1139e+00,\n",
       "           -4.1929e-01,  7.9390e+00],\n",
       "          [ 6.1465e-01,  1.4598e+00, -3.6137e+00,  ...,  1.9781e-01,\n",
       "           -5.2970e-01,  7.9857e+00],\n",
       "          [ 4.4373e-01, -2.1877e-01, -2.2024e+00,  ..., -2.1846e+00,\n",
       "           -1.8394e+00,  8.6313e+00]],\n",
       "\n",
       "         [[ 3.3228e-01, -5.2100e-02,  4.4828e-01,  ..., -1.3505e-01,\n",
       "           -6.7878e-02, -2.2125e+00],\n",
       "          [-1.9308e+00,  1.9478e-01,  3.7004e+00,  ..., -7.5413e-01,\n",
       "           -1.4453e+00,  5.9218e+00],\n",
       "          [-2.3695e+00,  6.8371e-01,  3.6881e+00,  ...,  4.3966e-01,\n",
       "           -1.1369e+00,  6.4070e+00],\n",
       "          ...,\n",
       "          [-1.4517e+00,  3.6522e-01,  2.4737e+00,  ..., -7.0429e-01,\n",
       "           -9.3994e-01,  6.8221e+00],\n",
       "          [-2.4442e+00,  5.6834e-01,  2.1406e+00,  ..., -1.6725e-02,\n",
       "           -2.8341e+00,  6.6074e+00],\n",
       "          [-1.7411e+00,  1.0740e-01,  2.9581e+00,  ..., -5.2872e-01,\n",
       "           -4.2821e-01,  6.4365e+00]],\n",
       "\n",
       "         [[ 1.3868e-01, -6.5963e-01, -2.3258e-01,  ...,  1.4861e-01,\n",
       "            2.7447e-01, -1.6060e-01],\n",
       "          [ 8.7125e-02,  1.5625e+00,  8.7948e-01,  ..., -5.6050e-02,\n",
       "            6.4115e-01, -2.2401e-02],\n",
       "          [-1.3730e+00,  1.8783e+00,  1.0146e+00,  ..., -7.2353e-01,\n",
       "           -1.0071e+00, -1.1916e-01],\n",
       "          ...,\n",
       "          [-1.4432e+00,  2.3373e+00, -7.6812e-02,  ...,  1.3016e-01,\n",
       "           -3.4882e-01,  1.0060e+00],\n",
       "          [ 3.4654e-01,  2.0433e+00,  1.0946e+00,  ..., -1.9423e-01,\n",
       "            5.6170e-01,  8.5613e-01],\n",
       "          [ 3.7556e-01,  2.7165e+00,  1.5422e+00,  ..., -6.2141e-01,\n",
       "            2.8909e-01, -1.2470e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8548e-01,  3.3657e-02, -8.6123e-04,  ...,  1.2389e+00,\n",
       "            4.4031e-02,  1.7787e+00],\n",
       "          [-3.3900e-01, -1.1665e+00, -1.6126e+00,  ..., -2.2094e+00,\n",
       "           -1.2285e+00, -8.3998e-01],\n",
       "          [ 1.1457e+00, -1.9595e+00, -2.7776e+00,  ..., -2.5459e+00,\n",
       "           -2.1862e+00, -6.8517e-01],\n",
       "          ...,\n",
       "          [ 2.7297e+00, -5.4906e-01,  6.4908e-01,  ..., -2.9931e+00,\n",
       "           -1.2364e+00, -2.9284e+00],\n",
       "          [ 9.0714e-01, -2.5425e-01,  1.0949e+00,  ..., -4.2778e+00,\n",
       "           -7.9689e-01, -2.4453e+00],\n",
       "          [ 5.2888e-01, -4.7623e-01, -1.0388e+00,  ..., -4.2955e+00,\n",
       "           -1.3179e+00, -6.7411e-01]],\n",
       "\n",
       "         [[-3.5278e-01, -1.6115e-01,  2.2002e-01,  ...,  2.5153e-01,\n",
       "           -2.5440e-02,  2.5464e-02],\n",
       "          [-5.8535e-01, -1.6797e+00, -9.7090e-02,  ...,  1.3156e+00,\n",
       "           -4.3526e-01, -3.6301e-01],\n",
       "          [-1.4276e+00, -4.4909e-01,  4.2122e-01,  ...,  8.0923e-01,\n",
       "            2.0564e+00,  5.5882e-01],\n",
       "          ...,\n",
       "          [ 2.3271e+00,  3.7035e-01, -1.2498e-01,  ...,  1.6023e+00,\n",
       "            7.8902e-01,  8.7364e-01],\n",
       "          [ 1.0688e+00,  6.8914e-01,  1.0407e+00,  ...,  1.1552e+00,\n",
       "           -4.6404e-01,  5.0676e-01],\n",
       "          [-5.4183e-01,  2.2367e-01,  1.1283e+00,  ...,  4.9600e-01,\n",
       "            4.4041e-01,  1.2166e+00]],\n",
       "\n",
       "         [[ 3.4287e+00,  2.1075e+00, -2.1753e+00,  ..., -2.8384e+00,\n",
       "           -3.9170e+00, -1.1987e+00],\n",
       "          [-2.3681e+00,  6.4387e-01,  2.7032e+00,  ...,  9.6174e-01,\n",
       "            5.6489e+00, -3.8173e+00],\n",
       "          [-1.7256e+00, -6.4345e-01,  3.3742e+00,  ...,  1.0353e-01,\n",
       "            1.0917e+01, -2.0007e+00],\n",
       "          ...,\n",
       "          [-2.4372e+00, -3.5694e+00,  5.2531e+00,  ..., -2.7536e+00,\n",
       "            1.4675e+01,  2.3681e+00],\n",
       "          [-5.4330e+00, -3.3473e+00,  6.1980e+00,  ..., -1.9572e+00,\n",
       "            1.3900e+01,  2.5586e+00],\n",
       "          [-5.6755e+00, -3.2005e+00,  9.5993e+00,  ..., -1.9898e-01,\n",
       "            1.4622e+01, -1.6569e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-9.6097e-04, -5.7273e-02,  1.4961e-02,  ...,  5.1007e-02,\n",
       "            2.4101e-02,  6.1853e-02],\n",
       "          [ 8.1719e-01,  3.1389e-01,  4.9729e-01,  ..., -4.4034e-01,\n",
       "           -5.6994e-01,  1.1864e+00],\n",
       "          [ 9.6669e-03, -1.2195e-01,  9.2736e-02,  ..., -8.4646e-01,\n",
       "            1.8833e-01, -2.2715e-02],\n",
       "          ...,\n",
       "          [-8.3899e-02, -1.7438e-01,  8.2991e-01,  ...,  4.0479e-01,\n",
       "           -5.2889e-01, -1.2070e+00],\n",
       "          [ 3.9354e-01,  4.8803e-02,  1.7574e-01,  ...,  1.7612e-01,\n",
       "            3.2382e-01, -6.9690e-01],\n",
       "          [-4.1270e-01,  1.0351e-01,  1.8573e-02,  ...,  6.5982e-02,\n",
       "           -2.0056e-01, -4.9836e-02]],\n",
       "\n",
       "         [[-5.8025e-02, -2.3602e-02, -1.3654e-01,  ..., -3.6943e-02,\n",
       "            4.6139e-02, -3.2085e-04],\n",
       "          [ 5.3729e-01,  2.3709e-01,  3.6851e-01,  ...,  3.0927e-01,\n",
       "           -7.5684e-01,  6.9841e-01],\n",
       "          [ 8.7619e-02, -3.0468e-01, -4.1744e-01,  ...,  4.6823e-01,\n",
       "           -5.7566e-01,  6.2960e-01],\n",
       "          ...,\n",
       "          [ 4.8862e-01,  6.7331e-01, -1.3201e-01,  ..., -4.5718e-01,\n",
       "            4.0848e-01,  3.6935e-01],\n",
       "          [ 1.3514e-01,  3.2320e-02, -1.7488e-01,  ...,  2.5361e-01,\n",
       "            6.0363e-01,  3.6989e-01],\n",
       "          [-3.1217e-01,  6.9661e-02, -1.0854e-01,  ..., -3.3014e-01,\n",
       "           -1.8350e-01,  1.7417e-01]],\n",
       "\n",
       "         [[ 5.9868e-02,  9.4087e-02,  8.9803e-02,  ...,  1.8043e-02,\n",
       "           -8.2018e-02, -7.6688e-03],\n",
       "          [ 4.6113e-03, -1.3464e-01,  5.5771e-01,  ..., -1.0991e+00,\n",
       "           -1.0160e-01, -4.8283e-01],\n",
       "          [-5.1055e-01, -3.0271e-01, -7.6251e-01,  ..., -5.6934e-02,\n",
       "           -4.8848e-01,  6.0689e-02],\n",
       "          ...,\n",
       "          [-5.6406e-01, -3.3250e-01,  5.2524e-01,  ...,  3.8864e-01,\n",
       "            6.4106e-01,  2.6506e-02],\n",
       "          [-2.4166e-01,  6.7879e-01, -5.6899e-01,  ...,  5.1277e-01,\n",
       "            8.9496e-01, -3.2001e-01],\n",
       "          [ 1.9636e-01, -1.2071e-01, -1.2509e-01,  ..., -2.6019e-01,\n",
       "           -2.9595e-01,  3.1047e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.9281e-03,  8.4553e-02, -7.0813e-02,  ...,  4.7958e-02,\n",
       "            4.0231e-02, -1.3932e-01],\n",
       "          [-6.4524e-02, -1.8763e-01, -5.0959e-01,  ...,  1.2311e-01,\n",
       "            9.9802e-01, -5.4559e-01],\n",
       "          [ 2.7483e-01,  5.9988e-01, -8.3259e-01,  ...,  2.9059e-01,\n",
       "           -1.6327e-01,  5.9452e-01],\n",
       "          ...,\n",
       "          [ 1.1946e+00,  3.1072e-01, -2.8942e-01,  ...,  4.8221e-01,\n",
       "            1.0371e+00, -1.0225e+00],\n",
       "          [ 5.3250e-01, -1.2834e+00, -4.2687e-01,  ...,  1.3547e+00,\n",
       "           -1.9295e-01,  4.6109e-01],\n",
       "          [-2.1219e-01,  5.5494e-01, -4.9708e-01,  ...,  1.8992e-01,\n",
       "           -1.3037e-01, -9.2226e-01]],\n",
       "\n",
       "         [[-1.4771e-01, -5.4743e-02,  1.0354e-01,  ..., -6.4467e-02,\n",
       "            5.0235e-02, -4.7105e-03],\n",
       "          [ 2.0542e-01,  7.5674e-01, -3.8195e-01,  ...,  7.9123e-01,\n",
       "            3.3666e-01,  3.1182e-01],\n",
       "          [ 1.7717e-02, -2.9456e-01, -4.1132e-01,  ..., -3.7352e-02,\n",
       "           -5.0875e-01,  7.6014e-01],\n",
       "          ...,\n",
       "          [ 4.6112e-01,  1.3695e+00,  4.5065e-01,  ..., -6.2355e-01,\n",
       "            2.1478e-01,  1.1362e+00],\n",
       "          [-4.8438e-02,  1.9276e-02, -2.2616e-01,  ...,  6.6443e-02,\n",
       "           -1.4004e-01,  1.5982e-02],\n",
       "          [ 3.6793e-01, -4.4020e-01,  3.2716e-01,  ...,  5.6387e-01,\n",
       "            6.9215e-01,  6.9416e-02]],\n",
       "\n",
       "         [[-1.8205e-02, -3.0886e-03, -1.9086e-02,  ..., -2.5844e-02,\n",
       "            8.7407e-03, -1.7466e-02],\n",
       "          [-7.2501e-01, -4.0966e-01, -5.0878e-02,  ...,  7.9444e-01,\n",
       "           -4.2704e-01, -3.8911e-01],\n",
       "          [-2.3777e-01,  1.8286e-01, -1.1924e-01,  ...,  3.9829e-01,\n",
       "           -9.7823e-02, -7.2584e-01],\n",
       "          ...,\n",
       "          [-4.2147e-01, -4.4072e-01,  1.3276e-01,  ..., -3.9426e-01,\n",
       "            5.9784e-01, -5.9402e-01],\n",
       "          [-1.1911e+00, -2.2353e-01, -5.2611e-01,  ..., -6.8117e-01,\n",
       "            4.3145e-01, -6.0661e-01],\n",
       "          [ 5.7201e-01, -2.1513e-01, -2.0821e-02,  ..., -2.6662e-01,\n",
       "            4.3591e-01,  9.3393e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.7386e-02, -2.9366e-01,  2.2930e-01,  ...,  1.6992e+00,\n",
       "           -2.1956e-01, -6.9672e-02],\n",
       "          [ 1.3258e+00,  4.3525e-03, -4.5178e-01,  ..., -3.3861e+00,\n",
       "            6.0934e-01, -9.7995e-02],\n",
       "          [-3.8396e-03,  6.8534e-01, -4.5098e-01,  ..., -3.5777e+00,\n",
       "            4.3510e-01, -1.0692e+00],\n",
       "          ...,\n",
       "          [ 1.0944e+00, -1.3281e-01, -8.4928e-01,  ..., -4.4945e+00,\n",
       "           -8.8708e-01, -7.0986e-01],\n",
       "          [-4.0466e-01,  1.8280e-01,  7.3278e-02,  ..., -3.9964e+00,\n",
       "            5.3101e-01, -8.9631e-01],\n",
       "          [-2.8022e-01,  2.4591e-01, -9.5407e-01,  ..., -3.1422e+00,\n",
       "            5.9489e-01, -6.9649e-01]],\n",
       "\n",
       "         [[ 1.4856e-01,  9.7933e-01, -1.4228e+00,  ..., -1.2427e-01,\n",
       "            2.7183e-01,  9.2512e-01],\n",
       "          [-4.5280e+00, -5.5021e+00,  7.7566e-01,  ...,  3.7734e-02,\n",
       "            2.0070e+00, -6.6960e-01],\n",
       "          [-1.8428e+00, -5.4617e+00, -1.5096e+00,  ..., -1.3806e-01,\n",
       "           -1.6786e+00, -1.6976e+00],\n",
       "          ...,\n",
       "          [-1.0155e+00, -4.1935e+00,  9.1143e-01,  ..., -6.7730e-01,\n",
       "            8.5889e-01, -2.9881e+00],\n",
       "          [ 3.6602e-01, -2.7849e+00,  1.7301e+00,  ...,  8.3982e-01,\n",
       "            1.8913e+00, -1.8723e+00],\n",
       "          [ 1.8487e-01, -2.9940e+00,  3.7968e-01,  ..., -6.0796e-01,\n",
       "            1.2830e+00, -1.7956e+00]],\n",
       "\n",
       "         [[-6.7567e-01,  2.5791e-01, -4.4622e-02,  ...,  1.8188e-01,\n",
       "            3.5410e-02, -2.7977e-01],\n",
       "          [ 7.9076e-01, -6.6335e-01, -1.7585e+00,  ..., -1.6750e+00,\n",
       "           -1.0765e+00, -1.3595e+00],\n",
       "          [ 2.1679e+00, -6.9919e-02,  4.3477e-01,  ...,  1.2724e-01,\n",
       "           -4.9424e-01, -1.1511e+00],\n",
       "          ...,\n",
       "          [ 1.8131e+00, -2.6902e-01,  1.9496e-01,  ..., -7.7712e-02,\n",
       "           -1.8967e+00,  9.0248e-02],\n",
       "          [ 1.1712e+00, -1.0126e+00, -8.9855e-01,  ..., -8.4999e-01,\n",
       "           -1.0316e+00, -2.0615e+00],\n",
       "          [ 6.7570e-01,  3.8597e-01, -3.9110e-01,  ..., -8.8802e-02,\n",
       "           -3.7925e-01,  9.4493e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6750e-02,  1.1317e-01,  1.4411e-01,  ..., -9.5337e-02,\n",
       "            2.8758e-02,  1.7906e-01],\n",
       "          [ 5.2997e-01, -2.4246e-01, -8.6433e-03,  ...,  1.7977e+00,\n",
       "           -1.2685e+00,  6.6169e-01],\n",
       "          [ 1.3688e+00, -5.8446e-01, -1.0249e+00,  ...,  6.1781e-01,\n",
       "           -1.2555e+00,  1.8549e-01],\n",
       "          ...,\n",
       "          [-4.0208e-01, -3.9943e-01,  9.0350e-01,  ..., -8.4163e-02,\n",
       "            2.9849e-01,  1.3064e+00],\n",
       "          [ 8.7521e-01, -5.4618e-01,  6.0006e-01,  ..., -4.2599e-01,\n",
       "            9.5319e-01,  4.6232e-02],\n",
       "          [ 6.7025e-01, -2.4473e-02,  6.4640e-01,  ...,  9.7068e-01,\n",
       "            5.1276e-01,  1.2734e-01]],\n",
       "\n",
       "         [[-3.0175e+00,  3.9929e-01, -3.6378e-02,  ..., -4.7122e-01,\n",
       "           -3.4804e-01,  1.2437e+00],\n",
       "          [ 5.1598e+00, -6.4113e-01, -1.2113e+00,  ..., -5.4299e-01,\n",
       "           -6.3423e-01, -2.7112e+00],\n",
       "          [ 3.9647e+00, -4.5005e-01, -8.1767e-01,  ...,  1.3302e+00,\n",
       "            1.0222e+00, -3.6523e-01],\n",
       "          ...,\n",
       "          [ 6.9698e+00,  1.0402e-01, -1.2673e+00,  ...,  1.4771e+00,\n",
       "           -3.9454e-01, -1.3275e+00],\n",
       "          [ 5.9740e+00, -3.1729e-01, -3.0471e-01,  ..., -1.6971e+00,\n",
       "            1.9964e+00, -5.9249e-01],\n",
       "          [ 4.3904e+00,  3.9197e-01, -6.1715e-01,  ..., -1.7761e+00,\n",
       "            3.8099e-01,  9.8363e-02]],\n",
       "\n",
       "         [[-1.4068e-02, -2.3846e-01,  2.5290e-02,  ..., -1.6074e-01,\n",
       "            3.3649e-01,  8.6691e-02],\n",
       "          [ 2.8668e-02, -2.1868e+00,  1.7570e-01,  ...,  3.2765e-01,\n",
       "            3.8849e-01, -1.7206e+00],\n",
       "          [-2.3774e-02, -1.9333e+00, -1.1854e-01,  ..., -5.0054e-01,\n",
       "            1.4996e+00, -2.0566e-01],\n",
       "          ...,\n",
       "          [-1.6754e-01, -7.2157e-01,  6.8358e-01,  ...,  2.4385e-01,\n",
       "            1.1955e+00, -2.1362e+00],\n",
       "          [-1.7204e-01, -1.5373e+00,  4.9301e-01,  ...,  1.1556e-01,\n",
       "            1.8178e+00, -1.0164e+00],\n",
       "          [ 2.1786e-01, -1.8928e+00,  4.4174e-01,  ...,  4.2819e-01,\n",
       "            1.5182e-01, -2.0864e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0283, -0.0237, -0.0065,  ..., -0.0032, -0.0248,  0.3515],\n",
       "          [ 0.8264,  0.2939, -0.5176,  ..., -0.2927, -0.2171,  0.0181],\n",
       "          [ 1.9226, -0.7101,  0.3985,  ...,  0.1594,  0.7347, -0.2097],\n",
       "          ...,\n",
       "          [ 0.3205, -0.6643,  0.0532,  ..., -0.3513, -0.3939, -1.5316],\n",
       "          [ 0.0561, -0.2875, -0.6101,  ...,  1.2166,  0.5898, -1.2971],\n",
       "          [ 0.1016,  0.4254, -0.1121,  ...,  0.1045,  0.3800, -1.0232]],\n",
       "\n",
       "         [[ 0.0052, -0.0295,  0.0151,  ..., -0.0267,  0.0140,  0.0122],\n",
       "          [-0.5628, -0.9254,  0.9794,  ..., -0.2008,  1.3605, -0.3241],\n",
       "          [ 0.7993,  0.5138, -0.2952,  ..., -0.7700,  0.4493, -0.8436],\n",
       "          ...,\n",
       "          [-0.0907,  0.4751,  1.4920,  ..., -0.6118,  0.6339, -0.4834],\n",
       "          [ 1.1835, -0.9603,  1.0771,  ..., -0.7290,  0.1659, -1.8319],\n",
       "          [-0.7705,  0.0071, -1.1086,  ..., -0.2116,  1.5475, -1.0844]],\n",
       "\n",
       "         [[-0.0587,  0.0065, -0.0385,  ..., -0.0367,  0.0108, -0.0737],\n",
       "          [-0.3782,  0.4603, -0.0197,  ..., -0.0948, -0.1734, -0.0478],\n",
       "          [-1.0508, -0.9034, -0.1986,  ...,  0.7021,  0.1026,  0.6465],\n",
       "          ...,\n",
       "          [ 0.6918, -0.7151,  0.4399,  ..., -0.5258,  0.4609,  0.3265],\n",
       "          [-0.5982, -0.3842, -0.2050,  ..., -0.3919, -0.2597, -0.3368],\n",
       "          [-0.2127,  0.2818,  1.1315,  ..., -0.4063,  0.3917,  0.4088]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3268, -0.1926, -0.0725,  ..., -0.4884,  0.2164,  0.0924],\n",
       "          [ 2.4077, -2.1106,  0.0814,  ...,  2.1166,  0.7840, -0.3542],\n",
       "          [ 0.7914, -2.0034, -1.2725,  ...,  0.1668,  0.2048, -0.0149],\n",
       "          ...,\n",
       "          [ 0.1624,  0.0656,  0.3339,  ...,  1.6880,  0.5858, -0.4577],\n",
       "          [ 0.3699, -2.1781, -0.6363,  ...,  1.6692, -0.0237,  0.6235],\n",
       "          [ 1.1835, -1.2606, -0.3178,  ...,  0.8860, -0.2557, -1.0127]],\n",
       "\n",
       "         [[-0.0743, -0.1376, -0.0477,  ..., -0.1892, -0.1411,  0.1259],\n",
       "          [-0.8208, -0.8386,  0.6731,  ...,  0.6332,  0.0199, -0.7615],\n",
       "          [ 0.2827,  0.3740, -0.2432,  ...,  0.1827, -0.3376,  0.5142],\n",
       "          ...,\n",
       "          [ 0.9158,  0.1738,  0.1931,  ..., -0.3132, -0.0828,  0.6322],\n",
       "          [-1.2725,  0.6167, -0.2177,  ..., -0.5662, -0.9483,  0.7020],\n",
       "          [-0.4237, -0.4396, -0.7444,  ..., -0.1120, -0.1108,  0.0457]],\n",
       "\n",
       "         [[-0.0376, -0.0407,  0.1040,  ...,  0.0808, -0.0425,  0.0137],\n",
       "          [ 0.1663, -0.5093,  0.4754,  ..., -0.8001, -0.2647, -0.0260],\n",
       "          [ 0.8517, -0.0424,  0.2084,  ..., -0.4614, -0.3543, -0.4421],\n",
       "          ...,\n",
       "          [ 0.8837, -0.2089, -1.3849,  ...,  0.0321,  0.3742,  0.3700],\n",
       "          [ 1.5021,  0.3024, -1.6816,  ...,  0.2755, -0.4314,  1.2684],\n",
       "          [ 0.8986, -0.4031, -0.7551,  ...,  0.2049,  0.5642,  0.3766]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-3.4242e-01,  8.8585e-01, -1.5804e-01,  ...,  1.1261e+00,\n",
       "           -1.9518e-01,  1.4177e-01],\n",
       "          [-1.9220e+00, -3.5766e+00,  1.0735e+00,  ..., -2.9989e+00,\n",
       "            2.4456e-01,  1.6964e+00],\n",
       "          [ 2.0634e-01, -4.5545e+00, -3.9479e-01,  ..., -2.3682e+00,\n",
       "            7.5262e-01,  1.9643e+00],\n",
       "          ...,\n",
       "          [ 4.1850e-02, -3.6175e+00, -3.7537e-01,  ..., -3.7409e+00,\n",
       "           -2.5598e+00,  1.3602e+00],\n",
       "          [ 9.7942e-01, -4.3081e+00, -8.1837e-01,  ..., -3.9368e+00,\n",
       "           -3.5577e-01,  6.4094e-01],\n",
       "          [-1.1241e+00, -4.2882e+00,  9.7364e-01,  ..., -3.9289e+00,\n",
       "            3.2482e-01,  1.0470e+00]],\n",
       "\n",
       "         [[ 4.3837e-02,  8.5526e-01, -6.5018e-01,  ..., -4.8066e-02,\n",
       "            2.9846e-01,  1.3144e-02],\n",
       "          [ 1.8581e+00, -8.6762e-01,  1.1911e-01,  ...,  1.4102e+00,\n",
       "           -1.5516e+00, -8.9818e-01],\n",
       "          [ 3.9744e-01, -7.4263e-01, -8.7026e-01,  ...,  2.1461e+00,\n",
       "            6.7020e-01, -5.7750e-01],\n",
       "          ...,\n",
       "          [-1.8549e+00,  4.0110e-01,  1.0519e+00,  ..., -6.1303e-01,\n",
       "            1.0524e+00, -1.9586e+00],\n",
       "          [-1.6497e+00,  1.7422e+00,  2.8445e+00,  ..., -4.2254e-01,\n",
       "            1.4167e+00,  2.2798e-02],\n",
       "          [ 3.9260e-01,  5.7385e-01,  6.0347e-01,  ...,  1.8517e+00,\n",
       "            1.6710e-01, -8.4147e-03]],\n",
       "\n",
       "         [[-3.0691e-01,  1.4184e-01, -9.7711e-01,  ..., -3.5239e-01,\n",
       "           -6.5329e-02, -1.5691e-01],\n",
       "          [ 5.4449e-01,  2.6089e-01,  3.3700e+00,  ...,  5.8992e-01,\n",
       "            3.0752e-01,  1.6272e-01],\n",
       "          [ 1.8183e-01, -4.2966e-01,  3.6656e+00,  ...,  6.5348e-01,\n",
       "            1.6247e-01,  1.1807e+00],\n",
       "          ...,\n",
       "          [ 6.0342e-01, -2.8373e-02,  4.0457e+00,  ...,  1.4485e-01,\n",
       "           -3.0530e-01, -1.8585e-02],\n",
       "          [ 8.4563e-01, -6.5223e-02,  3.8245e+00,  ...,  4.2785e-02,\n",
       "            8.7348e-01,  8.6994e-01],\n",
       "          [-4.1458e-01,  9.7909e-01,  2.9803e+00,  ..., -3.9050e-01,\n",
       "           -1.2682e-01,  4.7121e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7623e-01,  8.8415e-02, -6.9547e-02,  ..., -4.7736e-02,\n",
       "            2.2840e-01,  1.9032e-02],\n",
       "          [ 7.1144e-01,  1.8763e-01, -3.9937e-01,  ..., -4.9091e-01,\n",
       "           -1.2776e+00,  6.4044e-01],\n",
       "          [-3.3112e-01,  1.5726e+00, -1.1476e-01,  ...,  1.2293e+00,\n",
       "           -3.2792e-01,  1.3483e+00],\n",
       "          ...,\n",
       "          [-1.2218e+00,  1.0106e+00,  1.5841e+00,  ...,  2.4095e-01,\n",
       "            1.8157e+00,  2.5419e-01],\n",
       "          [-7.0075e-01, -2.0352e+00,  3.5377e-01,  ..., -2.1763e-01,\n",
       "            1.2933e+00,  3.9608e-01],\n",
       "          [-1.2331e+00, -2.5181e-01,  9.9036e-01,  ..., -7.5638e-02,\n",
       "            1.3286e+00,  6.3743e-01]],\n",
       "\n",
       "         [[ 1.9031e-01,  5.9438e-02,  3.3524e-01,  ...,  4.2277e-01,\n",
       "            1.9401e-02,  2.2399e-01],\n",
       "          [ 5.9327e-01,  2.8811e-01, -1.4083e-01,  ..., -1.5039e+00,\n",
       "           -2.3323e-01,  3.1527e-01],\n",
       "          [ 1.1468e+00, -2.1674e-01,  1.2189e+00,  ..., -4.9551e-01,\n",
       "            2.9952e-01,  4.2660e-01],\n",
       "          ...,\n",
       "          [ 1.2327e+00,  1.9132e-01,  9.7667e-01,  ..., -3.9745e-01,\n",
       "           -8.6595e-01,  1.6085e-01],\n",
       "          [ 1.5555e+00,  1.2641e-01,  1.5087e+00,  ..., -2.6383e-01,\n",
       "           -1.4203e+00, -3.3963e-01],\n",
       "          [ 2.5104e+00, -4.2117e-01,  9.7204e-01,  ...,  7.9411e-02,\n",
       "           -1.9639e+00,  1.2759e+00]],\n",
       "\n",
       "         [[-3.0269e+00,  5.5620e-01,  5.7562e-01,  ..., -9.3499e-01,\n",
       "            3.1438e-01,  1.8537e-01],\n",
       "          [ 6.4035e+00, -2.6480e-01, -1.7831e+00,  ...,  9.5199e-01,\n",
       "           -1.3967e+00, -1.9981e-02],\n",
       "          [ 6.5658e+00, -5.8532e-01, -3.0053e+00,  ...,  1.1486e+00,\n",
       "           -8.4129e-01, -1.1981e+00],\n",
       "          ...,\n",
       "          [ 8.7470e+00,  4.9102e-01, -8.1829e-01,  ...,  9.2144e-01,\n",
       "           -1.9827e-01, -2.1748e+00],\n",
       "          [ 8.8249e+00,  7.7651e-01, -9.9607e-01,  ...,  1.0463e-01,\n",
       "           -8.5053e-01, -1.0812e+00],\n",
       "          [ 9.4365e+00, -1.1869e+00, -5.3457e-01,  ...,  2.5683e+00,\n",
       "            4.1110e-01, -7.9529e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 4.2588e-02, -5.0356e-02,  8.1063e-03,  ..., -7.2504e-02,\n",
       "            9.6370e-03, -9.2134e-02],\n",
       "          [-4.3344e-01,  1.3342e-01, -4.7552e-02,  ...,  4.4079e-01,\n",
       "            2.6153e-01,  1.0634e+00],\n",
       "          [ 3.0987e-01, -1.2253e-01, -8.2554e-01,  ..., -5.1116e-01,\n",
       "           -7.1061e-01,  9.2578e-01],\n",
       "          ...,\n",
       "          [-8.3976e-01,  2.3753e-01,  2.7464e-01,  ...,  2.1087e-01,\n",
       "            2.5149e-01,  4.4114e-01],\n",
       "          [-1.1380e+00,  2.7989e-01, -2.8601e-01,  ..., -3.8907e-02,\n",
       "            6.6291e-01, -1.5787e-01],\n",
       "          [ 2.5615e-01, -1.8164e-01,  3.2558e-01,  ..., -7.4514e-02,\n",
       "            1.2012e-01, -5.7117e-01]],\n",
       "\n",
       "         [[ 7.9494e-02,  1.9629e-02, -1.4942e-02,  ..., -3.9482e-02,\n",
       "            2.1056e-02, -1.7007e-02],\n",
       "          [ 4.6344e-01, -1.4725e-01,  8.2258e-01,  ...,  3.4143e-01,\n",
       "            6.6487e-02, -1.0046e+00],\n",
       "          [ 4.0347e-01, -8.7195e-01, -1.1793e+00,  ...,  1.0580e+00,\n",
       "            5.7153e-01,  5.3592e-01],\n",
       "          ...,\n",
       "          [-6.6896e-01,  1.4602e-01,  1.4269e+00,  ..., -1.1985e-01,\n",
       "            1.1612e+00,  2.0802e+00],\n",
       "          [-2.0435e-01,  2.5427e-01,  8.5200e-01,  ..., -8.8234e-01,\n",
       "            9.5405e-01,  4.8340e-01],\n",
       "          [ 8.2470e-01,  1.2348e-01, -1.8964e-02,  ..., -2.7635e-01,\n",
       "            3.8721e-01,  7.9089e-01]],\n",
       "\n",
       "         [[ 6.5061e-02,  1.7394e-02, -1.3197e-02,  ...,  1.9595e-02,\n",
       "           -6.2144e-02, -6.3763e-02],\n",
       "          [-1.1358e-02,  6.8293e-01, -8.8521e-01,  ..., -8.8195e-01,\n",
       "           -9.2533e-01,  1.0995e+00],\n",
       "          [ 7.2526e-01, -6.4550e-01, -1.0321e-01,  ..., -6.4715e-01,\n",
       "           -5.5848e-01,  1.3314e+00],\n",
       "          ...,\n",
       "          [-6.7675e-01, -1.5009e-01, -6.6685e-01,  ..., -4.3112e-01,\n",
       "           -8.0608e-01, -2.0868e-01],\n",
       "          [-6.1433e-01, -2.4865e-01, -3.9539e-01,  ..., -1.8268e+00,\n",
       "            3.9165e-01, -1.5418e+00],\n",
       "          [-3.6172e-01, -6.2750e-01, -3.1816e-01,  ..., -9.2306e-02,\n",
       "            2.7719e-01,  3.6233e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2369e-03,  2.0590e-02,  1.8059e-02,  ..., -6.7566e-02,\n",
       "           -2.1130e-02,  1.0344e-02],\n",
       "          [-2.6505e-01,  6.8230e-02, -5.8063e-01,  ...,  2.0919e+00,\n",
       "           -2.0487e-01, -6.2631e-02],\n",
       "          [-1.1090e+00, -4.0114e-01,  6.4974e-01,  ...,  1.8533e+00,\n",
       "           -5.9498e-01, -1.5189e+00],\n",
       "          ...,\n",
       "          [-1.7999e-01, -1.3203e+00, -4.0722e-01,  ...,  5.0378e-01,\n",
       "           -6.4837e-01,  2.0433e-01],\n",
       "          [ 1.6616e-01, -6.4842e-02,  4.4673e-01,  ..., -1.3760e+00,\n",
       "           -1.5886e+00,  1.6740e+00],\n",
       "          [-2.3218e-01, -1.0700e+00, -2.0870e-01,  ...,  4.2789e-01,\n",
       "            1.3457e-01,  4.9070e-01]],\n",
       "\n",
       "         [[ 4.5884e-02, -1.3652e-02,  3.3538e-02,  ...,  4.2297e-02,\n",
       "           -1.0650e-02,  1.3725e-02],\n",
       "          [ 6.7968e-01, -6.1345e-01, -5.1771e-01,  ...,  3.9566e-01,\n",
       "           -6.3267e-01, -7.4087e-01],\n",
       "          [ 3.2294e-01, -5.0785e-01, -2.0838e+00,  ...,  1.2406e+00,\n",
       "            3.0909e-01,  7.6786e-01],\n",
       "          ...,\n",
       "          [ 6.6215e-01,  1.4883e+00, -1.3764e+00,  ..., -8.5867e-01,\n",
       "           -9.7664e-01,  7.5940e-02],\n",
       "          [-3.7327e-01,  1.0781e+00, -1.1749e+00,  ...,  1.5869e-02,\n",
       "           -8.2584e-01, -8.5889e-01],\n",
       "          [-1.0721e-01, -2.9212e-01, -1.0636e+00,  ...,  4.9721e-01,\n",
       "           -3.1656e-02, -7.9184e-02]],\n",
       "\n",
       "         [[ 7.6791e-02, -2.0113e-01, -8.1943e-02,  ..., -2.3764e-02,\n",
       "            2.0464e-01, -5.6837e-02],\n",
       "          [ 9.9648e-02, -2.1344e+00,  4.2548e-02,  ...,  4.3812e-01,\n",
       "           -7.9336e-01,  4.1660e-01],\n",
       "          [-1.0473e-01, -8.4763e-01, -1.0118e-01,  ...,  7.0098e-01,\n",
       "           -6.8366e-02, -1.1925e-01],\n",
       "          ...,\n",
       "          [ 8.6354e-02,  2.0148e+00, -7.8215e-01,  ...,  1.2433e+00,\n",
       "           -1.2465e+00,  8.4486e-02],\n",
       "          [ 2.1874e-01,  1.7080e+00, -7.7510e-01,  ...,  2.0696e-01,\n",
       "            1.1355e-02,  1.2248e-01],\n",
       "          [-9.0595e-01, -7.8929e-01,  2.8047e-02,  ...,  1.5975e-01,\n",
       "           -3.9888e-01,  8.6554e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0446, -0.2861, -0.1417,  ...,  0.6163,  0.7392, -0.3206],\n",
       "          [-3.9079, -2.3097,  2.2869,  ..., -1.0490, -3.9810,  0.3166],\n",
       "          [-4.8613, -0.9516,  2.6062,  ..., -0.0303, -3.9882, -0.5383],\n",
       "          ...,\n",
       "          [-3.5566, -2.6193,  0.7828,  ...,  0.6872, -4.4898, -0.6281],\n",
       "          [-4.2590, -1.7552,  2.8268,  ..., -0.6523, -4.0929, -0.2955],\n",
       "          [-4.9762, -1.9708,  0.0080,  ..., -0.3365, -3.7900, -0.1139]],\n",
       "\n",
       "         [[-0.1387, -0.0569,  0.1582,  ..., -0.0465, -0.8847, -0.2043],\n",
       "          [-0.5542, -0.0729, -0.3130,  ..., -0.0560, -0.7031,  1.6099],\n",
       "          [-1.3839,  1.4181, -0.2936,  ...,  1.3373, -1.0466,  1.9511],\n",
       "          ...,\n",
       "          [-1.8806,  0.3803, -1.2217,  ...,  1.7803,  0.9103,  0.4690],\n",
       "          [-1.2040,  1.6865, -0.4972,  ...,  0.5542, -0.4544,  1.0700],\n",
       "          [-2.2268,  0.3460, -1.5116,  ...,  0.5357, -0.8997,  0.5252]],\n",
       "\n",
       "         [[ 0.1924,  0.3075,  1.1360,  ..., -0.4682,  0.4283, -0.5042],\n",
       "          [ 1.1163, -0.8514, -1.3363,  ..., -0.5048, -2.3173,  1.4079],\n",
       "          [-0.4352, -0.6518, -1.4657,  ...,  0.3762, -3.2430,  2.4583],\n",
       "          ...,\n",
       "          [-1.2546, -1.4138, -1.6076,  ..., -2.2605, -1.6244, -0.5993],\n",
       "          [-0.4396, -2.4026, -0.8960,  ..., -1.1734, -1.3114,  0.8956],\n",
       "          [ 0.6041, -1.4925, -0.8934,  ..., -1.4043, -2.3182,  1.5456]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1552,  0.0680, -0.2229,  ..., -0.0112,  0.1523,  0.0379],\n",
       "          [-1.4715, -0.2699, -1.0010,  ...,  0.9816, -0.0131, -0.5940],\n",
       "          [-2.8031, -0.0749, -0.5765,  ...,  1.4030,  0.5713, -0.3813],\n",
       "          ...,\n",
       "          [-0.7421,  0.1682,  1.1091,  ...,  0.2662, -1.0974, -1.7564],\n",
       "          [ 0.5485,  0.4741,  1.4970,  ..., -0.3822, -0.6439, -1.4745],\n",
       "          [-1.9331,  1.2431, -0.7142,  ...,  0.8943, -0.3290, -0.2887]],\n",
       "\n",
       "         [[-0.3520, -2.1820,  0.1305,  ..., -0.0781, -0.0452,  0.9126],\n",
       "          [-0.1676,  0.7424,  0.8457,  ..., -0.0430, -0.6897,  0.9972],\n",
       "          [-1.0619,  3.2376,  2.5831,  ...,  0.4896,  0.5569,  1.1650],\n",
       "          ...,\n",
       "          [ 0.1921,  4.7669, -0.9619,  ...,  0.1920,  0.0281, -1.6348],\n",
       "          [-0.3346,  4.0043,  0.8320,  ...,  1.9739,  0.4835,  0.2861],\n",
       "          [-0.4076,  1.6655, -1.2985,  ...,  1.3795, -0.0910,  1.3841]],\n",
       "\n",
       "         [[ 0.3705,  0.0804, -0.1422,  ...,  0.6539,  0.1286,  0.2599],\n",
       "          [ 0.2785, -0.1845, -0.7767,  ..., -0.6425,  0.7165, -1.3394],\n",
       "          [-0.0426, -1.2866, -0.2084,  ...,  0.4318,  1.4718,  0.1445],\n",
       "          ...,\n",
       "          [-2.9565, -2.3736, -1.0456,  ...,  0.5869, -0.2452, -0.1996],\n",
       "          [-2.0673, -1.9636,  0.6296,  ..., -1.2112, -0.6369,  2.2856],\n",
       "          [-1.5174, -0.1974,  1.0155,  ...,  0.1546,  0.5188,  1.0438]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.2128e-02,  4.2769e-02, -6.2959e-02,  ..., -2.4990e-02,\n",
       "           -5.5757e-04,  1.9665e-02],\n",
       "          [ 5.3965e-01,  1.5681e-02, -8.6195e-01,  ..., -6.3801e-01,\n",
       "            3.3482e-02,  2.0060e-01],\n",
       "          [-2.2824e-02,  1.7671e-01, -1.9057e-01,  ..., -6.8474e-01,\n",
       "           -7.3559e-01,  5.6330e-01],\n",
       "          ...,\n",
       "          [-5.3655e-01, -6.8141e-01, -2.7338e-01,  ..., -8.9929e-01,\n",
       "            6.7783e-01, -7.7594e-02],\n",
       "          [-6.6500e-02, -2.1919e-01,  7.2967e-01,  ...,  3.1051e-01,\n",
       "           -9.1984e-01,  1.6034e+00],\n",
       "          [-4.6005e-02,  1.7540e-01, -1.4991e-01,  ..., -3.8299e-01,\n",
       "           -1.2224e-01,  3.0644e-01]],\n",
       "\n",
       "         [[ 8.2081e-03, -2.1715e-02,  3.5759e-02,  ...,  2.5119e-02,\n",
       "           -4.6394e-02,  1.3449e-02],\n",
       "          [-5.6013e-01, -4.7914e-01, -7.3465e-01,  ...,  2.4955e-01,\n",
       "           -2.2302e-01,  1.7230e-02],\n",
       "          [-2.6670e-01, -5.7561e-02, -1.0933e+00,  ...,  6.9103e-01,\n",
       "            8.8651e-01,  2.3363e-01],\n",
       "          ...,\n",
       "          [ 1.4549e+00,  6.2701e-01,  3.4483e-01,  ..., -2.6119e-01,\n",
       "           -1.8188e-01,  2.0104e-01],\n",
       "          [ 9.1125e-01, -5.0901e-01,  1.7518e-01,  ...,  4.0393e-02,\n",
       "           -8.2184e-03, -6.1320e-01],\n",
       "          [-3.7897e-01, -1.3483e-01,  9.1873e-02,  ...,  3.8443e-01,\n",
       "            4.2697e-01, -3.3593e-01]],\n",
       "\n",
       "         [[ 5.1188e-02, -3.5194e-02,  2.7533e-02,  ...,  1.4181e-02,\n",
       "           -6.4940e-03,  2.2787e-02],\n",
       "          [ 5.1446e-01, -1.3208e+00, -1.0446e+00,  ...,  1.7528e-02,\n",
       "            1.7641e+00, -3.5737e-01],\n",
       "          [-2.7716e-01,  6.2414e-02, -1.8526e+00,  ..., -4.1313e-01,\n",
       "           -5.6179e-01,  1.0078e+00],\n",
       "          ...,\n",
       "          [ 4.1809e-01, -5.0762e-02, -3.4584e-01,  ..., -1.2960e+00,\n",
       "           -5.4343e-01, -1.4812e-01],\n",
       "          [ 1.5966e-01, -1.5908e-01, -2.6501e-01,  ..., -2.6891e-01,\n",
       "            1.3304e+00, -6.3225e-01],\n",
       "          [ 4.6884e-01, -2.5218e-01, -6.3545e-01,  ..., -2.6028e+00,\n",
       "            3.5557e-02, -2.5807e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8817e-01,  7.5630e-02,  5.1482e-02,  ...,  6.3044e-02,\n",
       "            4.5983e-02, -1.2272e-01],\n",
       "          [-4.8166e-01, -8.0081e-01,  4.7553e-01,  ...,  9.2073e-01,\n",
       "            1.4889e+00, -4.9100e-01],\n",
       "          [ 3.1190e-01, -1.7164e+00, -6.4195e-01,  ..., -3.0160e-01,\n",
       "            9.8333e-01, -1.3910e+00],\n",
       "          ...,\n",
       "          [ 2.6295e-01,  1.7654e-01, -2.2927e-01,  ..., -5.6709e-01,\n",
       "           -4.2602e-01,  1.8268e-01],\n",
       "          [-1.2287e+00, -8.8129e-01, -4.9618e-01,  ...,  5.7656e-01,\n",
       "           -9.3973e-02,  9.1813e-01],\n",
       "          [-5.2435e-01, -5.0482e-01, -6.5543e-01,  ..., -9.4711e-02,\n",
       "            2.7462e-01, -4.3348e-01]],\n",
       "\n",
       "         [[-5.8365e-01, -2.0280e-02,  4.3795e-02,  ..., -1.2728e-02,\n",
       "            1.4847e-02, -1.1488e-02],\n",
       "          [ 2.1189e-01,  6.3309e-01, -8.5212e-01,  ...,  1.7114e-02,\n",
       "           -1.6814e-01,  3.3735e-01],\n",
       "          [-5.0398e-01,  1.2201e-01, -9.9508e-01,  ...,  1.0425e+00,\n",
       "            5.1320e-01,  8.6971e-01],\n",
       "          ...,\n",
       "          [-1.4073e+00,  4.5373e-01, -1.8495e-01,  ...,  1.0106e-01,\n",
       "            1.1485e+00, -5.4967e-02],\n",
       "          [-7.8669e-01, -4.6793e-01,  8.1497e-02,  ..., -6.6191e-01,\n",
       "            9.3902e-01, -4.7145e-01],\n",
       "          [-2.6530e+00, -1.3969e-01,  2.4383e-01,  ..., -2.2311e-01,\n",
       "            4.6452e-01,  3.6028e-01]],\n",
       "\n",
       "         [[ 1.8879e-02,  8.3848e-02, -5.0716e-02,  ...,  5.5664e-02,\n",
       "            2.9355e-02, -4.1401e-02],\n",
       "          [-3.1205e-01,  3.7567e-01,  3.4224e-01,  ...,  7.1520e-01,\n",
       "            7.5321e-01, -1.1299e-01],\n",
       "          [-1.0119e+00,  3.3448e-01, -1.2705e+00,  ..., -8.8392e-01,\n",
       "           -2.3355e+00, -2.2953e-01],\n",
       "          ...,\n",
       "          [ 1.9422e-01,  1.2625e+00,  6.1021e-01,  ...,  1.0141e+00,\n",
       "           -1.3892e-01, -3.8717e-01],\n",
       "          [-1.6888e+00,  1.0561e+00,  6.2911e-01,  ..., -7.9248e-01,\n",
       "           -1.2793e+00,  2.5450e-02],\n",
       "          [-6.8985e-01,  3.8036e-01,  1.1172e+00,  ..., -3.2169e-01,\n",
       "           -9.4463e-01,  8.1670e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-3.0739e-02, -2.3328e+00,  1.6444e-01,  ..., -2.4874e-01,\n",
       "           -2.1955e-01,  6.7818e-02],\n",
       "          [ 6.6502e-01,  3.8897e+00,  2.5626e-01,  ..., -1.2447e+00,\n",
       "           -5.1476e-01,  1.7491e-01],\n",
       "          [ 2.3555e-01,  4.3144e+00,  1.5203e+00,  ..., -1.0305e+00,\n",
       "           -2.7401e-01, -2.9700e-01],\n",
       "          ...,\n",
       "          [-7.4795e-01,  6.0315e+00,  1.4481e+00,  ..., -1.7219e+00,\n",
       "            1.5043e-01,  3.6441e-02],\n",
       "          [-1.1906e+00,  6.0815e+00,  7.5815e-01,  ...,  7.6931e-03,\n",
       "            1.6461e+00, -4.0052e-01],\n",
       "          [-7.7746e-01,  4.0435e+00,  8.6778e-01,  ..., -1.0730e+00,\n",
       "            3.5681e-01, -7.8314e-01]],\n",
       "\n",
       "         [[-8.1230e-01,  2.0313e-01,  4.6825e-01,  ..., -5.1517e-01,\n",
       "            1.0709e+00,  1.1254e+00],\n",
       "          [ 1.9943e-01,  7.3408e-02,  1.8181e+00,  ..., -3.0854e-01,\n",
       "            1.3158e+00,  6.8892e-02],\n",
       "          [ 3.2874e-01, -6.4358e-01,  2.3493e+00,  ..., -1.5555e-01,\n",
       "            2.4417e+00,  1.8911e-01],\n",
       "          ...,\n",
       "          [ 6.9653e-01,  1.3289e+00, -4.7835e-01,  ..., -1.1337e+00,\n",
       "            6.5288e-01, -2.0380e+00],\n",
       "          [ 2.1073e-01,  1.0003e+00,  1.2394e+00,  ..., -6.3918e-01,\n",
       "            8.0475e-01, -1.5733e+00],\n",
       "          [ 3.1132e-01,  2.8403e-01,  2.9093e-01,  ..., -1.5865e+00,\n",
       "            3.1738e+00, -7.4550e-01]],\n",
       "\n",
       "         [[-8.3052e-01,  4.9202e-01,  1.5700e-02,  ...,  5.0540e-01,\n",
       "           -2.3221e-01,  1.1760e+00],\n",
       "          [ 1.8285e+00, -1.1218e+00, -6.0110e-01,  ...,  1.7362e-01,\n",
       "            1.3459e+00,  1.1774e-01],\n",
       "          [ 1.6429e+00, -2.1772e+00,  1.7248e+00,  ...,  3.0036e-01,\n",
       "            7.7876e-01,  9.9057e-01],\n",
       "          ...,\n",
       "          [ 1.0010e+00, -1.7313e+00,  1.9045e+00,  ...,  8.0702e-01,\n",
       "            5.2974e-01, -6.8052e-01],\n",
       "          [ 1.5992e+00, -2.7915e+00,  1.0877e+00,  ...,  7.4602e-01,\n",
       "            3.0333e-02, -1.3237e+00],\n",
       "          [ 1.6438e+00, -9.9109e-01,  9.2324e-01,  ...,  1.1409e+00,\n",
       "            5.9684e-01, -3.3019e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0107e-01, -1.1655e-01,  1.3441e-01,  ...,  1.8965e-01,\n",
       "            1.7320e+00, -2.8680e+00],\n",
       "          [ 1.9154e+00,  1.2091e+00,  2.8645e-01,  ...,  1.3748e-01,\n",
       "           -3.8644e+00,  3.9812e+00],\n",
       "          [ 9.2973e-01, -1.0160e-01, -1.3098e-02,  ..., -3.6517e-01,\n",
       "           -4.1451e+00,  4.7426e+00],\n",
       "          ...,\n",
       "          [ 5.7876e-01, -5.6903e-01, -9.7981e-01,  ..., -1.5678e+00,\n",
       "           -5.4191e+00,  5.7578e+00],\n",
       "          [-1.9895e-01, -5.5637e-01, -4.0058e-01,  ..., -1.3523e+00,\n",
       "           -5.3991e+00,  5.7263e+00],\n",
       "          [ 1.0074e-01,  9.1534e-01,  5.5960e-01,  ..., -1.0116e+00,\n",
       "           -5.7379e+00,  5.5124e+00]],\n",
       "\n",
       "         [[ 1.8309e-01,  3.5898e-01,  2.1865e-01,  ..., -2.1976e-01,\n",
       "            3.2432e-02, -1.3621e-01],\n",
       "          [-1.1902e+00,  2.5967e-01,  1.3770e+00,  ...,  1.6082e+00,\n",
       "            5.3296e-01,  1.0141e-01],\n",
       "          [-1.6201e+00,  3.1865e-01,  5.4789e-01,  ...,  7.9333e-01,\n",
       "            4.1223e-01, -9.2892e-01],\n",
       "          ...,\n",
       "          [-1.7144e+00,  2.9198e-01, -6.5764e-01,  ...,  1.4415e+00,\n",
       "           -4.7544e-02,  6.2226e-01],\n",
       "          [-1.0669e+00,  9.0313e-01, -9.0604e-01,  ...,  1.4476e+00,\n",
       "           -3.0205e-01, -8.2349e-01],\n",
       "          [-6.1682e-01,  4.0207e-01, -2.7279e-01,  ...,  1.9482e+00,\n",
       "           -5.3192e-01, -1.6915e-01]],\n",
       "\n",
       "         [[ 3.8544e-01,  1.1505e-01,  6.3900e-01,  ...,  5.3104e-01,\n",
       "            5.7931e-01, -3.3185e-01],\n",
       "          [ 4.0666e-01, -9.3643e-01, -1.0314e+00,  ..., -6.5106e-01,\n",
       "           -3.1251e+00, -3.6745e-01],\n",
       "          [ 9.7926e-01, -9.1059e-01,  2.0969e-01,  ..., -1.8782e+00,\n",
       "           -3.4683e+00,  2.0600e-01],\n",
       "          ...,\n",
       "          [-1.4226e-01, -9.7476e-01, -5.4240e-01,  ..., -2.8039e+00,\n",
       "           -4.1771e+00,  1.9208e+00],\n",
       "          [-7.5886e-01, -6.7514e-01, -4.4393e-02,  ..., -2.4649e+00,\n",
       "           -4.5963e+00,  6.7639e-01],\n",
       "          [-6.9450e-01,  4.6576e-01, -7.3801e-01,  ..., -2.1795e+00,\n",
       "           -4.2150e+00,  2.8132e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 5.3734e-02, -1.4238e-02, -3.5810e-02,  ...,  1.2174e-01,\n",
       "           -5.9948e-02, -4.3049e-02],\n",
       "          [-4.0712e-01,  2.3952e-01, -1.4630e-01,  ..., -4.0966e-01,\n",
       "            8.4789e-01, -2.2644e-01],\n",
       "          [-1.4474e+00, -8.4849e-01, -9.8838e-02,  ..., -2.0224e-01,\n",
       "            6.6301e-01,  7.1867e-01],\n",
       "          ...,\n",
       "          [-6.3025e-01, -9.1939e-01,  1.5612e+00,  ...,  6.4965e-01,\n",
       "            2.6919e+00,  8.4095e-01],\n",
       "          [-5.2483e-01, -1.3637e+00,  1.8403e+00,  ...,  3.8219e-01,\n",
       "            1.4497e+00,  1.0674e-03],\n",
       "          [-2.9674e-02,  1.7135e-01, -7.6390e-01,  ..., -3.9354e-01,\n",
       "            4.4974e-01, -9.9768e-01]],\n",
       "\n",
       "         [[ 1.7320e-02,  2.3816e-02,  4.7974e-02,  ..., -4.7309e-03,\n",
       "           -6.8244e-03,  3.2884e-03],\n",
       "          [ 5.4060e-01,  1.3387e+00,  1.0772e+00,  ..., -4.1183e-01,\n",
       "           -7.2695e-02,  7.3047e-01],\n",
       "          [ 1.6604e+00, -1.0405e+00, -4.6418e-02,  ..., -1.5549e-01,\n",
       "            4.8930e-01,  2.6706e-01],\n",
       "          ...,\n",
       "          [-2.6609e-02,  1.4448e+00, -9.6232e-02,  ...,  1.4043e+00,\n",
       "           -2.1171e-01,  6.2546e-01],\n",
       "          [ 1.7877e+00, -7.9523e-01,  3.4070e-01,  ..., -1.0215e+00,\n",
       "            5.2032e-01, -7.5460e-01],\n",
       "          [-6.6356e-01,  7.8232e-01,  8.1055e-01,  ..., -6.7723e-01,\n",
       "           -5.3983e-01, -7.7323e-01]],\n",
       "\n",
       "         [[ 5.1727e-02, -3.2729e-02,  6.2676e-02,  ...,  3.5751e-02,\n",
       "           -7.1613e-02, -5.9328e-02],\n",
       "          [-3.5343e-01,  7.5885e-01, -4.1293e-02,  ...,  2.4424e-01,\n",
       "           -6.9912e-01, -5.4976e-01],\n",
       "          [ 7.8512e-02, -4.0856e-01,  5.3512e-01,  ..., -8.2215e-01,\n",
       "            1.6115e-03, -5.0301e-01],\n",
       "          ...,\n",
       "          [-7.4352e-01,  2.1682e-01,  5.4941e-01,  ..., -7.3409e-01,\n",
       "            5.1859e-01,  4.1630e-02],\n",
       "          [-3.8653e-01,  1.1920e+00, -2.0321e-01,  ..., -1.3421e-01,\n",
       "           -2.3149e-01, -1.5669e-01],\n",
       "          [-6.5035e-01,  1.6409e-01, -2.7168e-01,  ..., -5.6858e-02,\n",
       "            3.0423e-01,  6.7127e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.5711e-02, -3.3712e-02,  3.5806e-02,  ..., -9.8101e-02,\n",
       "            3.3037e-02,  2.1276e-02],\n",
       "          [-1.0548e+00,  1.0086e+00,  3.5336e-01,  ...,  1.4173e-01,\n",
       "            1.1533e+00, -5.7750e-01],\n",
       "          [ 3.0501e-01,  3.8879e-01,  1.4593e+00,  ..., -1.5761e+00,\n",
       "            6.6029e-01, -2.4784e+00],\n",
       "          ...,\n",
       "          [ 2.1433e-01,  3.0902e-01, -1.5677e-01,  ..., -1.4376e+00,\n",
       "            3.1234e-01, -1.5930e-01],\n",
       "          [ 9.2115e-02,  1.3849e+00, -3.5478e-01,  ..., -2.0249e+00,\n",
       "            1.7484e+00,  1.5088e+00],\n",
       "          [ 1.0588e+00,  5.0693e-02,  1.6494e-02,  ..., -3.3868e-01,\n",
       "            6.8473e-01,  6.6574e-02]],\n",
       "\n",
       "         [[ 1.5089e-01, -6.4248e-02,  1.3481e-01,  ...,  7.3110e-02,\n",
       "            4.8974e-03, -1.2889e-01],\n",
       "          [ 6.8720e-01,  5.7469e-02, -1.7870e-01,  ..., -1.1156e+00,\n",
       "           -1.2297e+00,  1.5926e-02],\n",
       "          [ 4.6848e-01,  6.8089e-01,  4.5960e-01,  ..., -3.4666e-01,\n",
       "           -8.2155e-01,  7.9261e-01],\n",
       "          ...,\n",
       "          [-6.8295e-01, -4.1632e-01, -3.1648e-01,  ..., -1.0120e+00,\n",
       "           -1.2630e+00,  4.1550e-01],\n",
       "          [ 3.2674e-02, -5.2766e-01, -1.6868e+00,  ..., -9.0995e-01,\n",
       "           -2.2853e-01,  1.4612e+00],\n",
       "          [ 2.0993e-01, -2.2174e-01,  1.0833e+00,  ..., -6.0768e-01,\n",
       "            6.2882e-01,  8.7862e-02]],\n",
       "\n",
       "         [[ 2.1724e-01, -6.2232e-02, -5.5712e-02,  ...,  2.1461e-02,\n",
       "            4.3089e-02,  3.7415e-02],\n",
       "          [ 1.3125e+00, -4.4910e-01, -7.5738e-01,  ...,  3.2747e-01,\n",
       "           -9.8979e-02, -8.0641e-02],\n",
       "          [-1.6063e-01, -7.7957e-01, -1.6312e-01,  ..., -4.8402e-01,\n",
       "            8.7137e-01, -2.5966e-01],\n",
       "          ...,\n",
       "          [-3.6798e-01,  5.0565e-01,  2.8998e-01,  ...,  2.5920e-01,\n",
       "           -1.9344e+00,  7.5728e-01],\n",
       "          [ 4.9458e-02, -4.9568e-01,  8.4527e-01,  ..., -3.3127e-01,\n",
       "            6.4243e-01, -3.5335e-01],\n",
       "          [ 1.1826e-01, -1.5026e-01,  9.7509e-01,  ...,  4.7501e-01,\n",
       "           -8.4105e-01,  6.5077e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.3000e-02, -2.4427e-01, -4.4500e-01,  ...,  3.0083e-01,\n",
       "            3.2684e-01,  3.6586e-01],\n",
       "          [-3.1921e-01,  1.1035e+00, -8.1620e-01,  ..., -1.0129e+00,\n",
       "           -1.0356e-01, -3.4720e-01],\n",
       "          [ 1.2050e-01,  8.5493e-01, -4.7644e-01,  ...,  2.5663e-01,\n",
       "           -7.2198e-01,  7.0494e-01],\n",
       "          ...,\n",
       "          [-3.0341e-01,  2.8499e-03,  4.0952e-01,  ...,  2.3109e+00,\n",
       "           -8.2102e-01, -3.8004e-01],\n",
       "          [-3.2073e-03,  2.9617e-01, -1.1835e-01,  ...,  3.1173e+00,\n",
       "            4.8563e-01,  1.0006e+00],\n",
       "          [ 4.6373e-01, -9.1020e-02, -9.6269e-01,  ...,  6.1472e-01,\n",
       "           -6.0768e-01,  9.6789e-01]],\n",
       "\n",
       "         [[-2.7947e-01,  1.5264e-01,  1.2265e-01,  ...,  6.3867e-02,\n",
       "           -1.1406e+00, -1.3803e-01],\n",
       "          [ 7.5797e-01,  7.3406e-01,  2.4232e+00,  ..., -1.7083e-01,\n",
       "           -1.2876e+00,  6.4982e-01],\n",
       "          [ 5.9163e-01, -2.5393e-01,  9.1645e-01,  ...,  1.4073e+00,\n",
       "           -9.9605e-01,  1.3304e+00],\n",
       "          ...,\n",
       "          [ 2.9273e-01, -3.5706e-01,  1.8072e+00,  ...,  5.2217e-01,\n",
       "           -1.9019e+00, -1.5489e+00],\n",
       "          [-3.1271e-02,  1.4249e-01,  1.4840e+00,  ...,  4.6309e-01,\n",
       "           -1.1398e+00, -3.6930e-01],\n",
       "          [-1.5090e-01,  1.7000e+00,  1.0501e+00,  ...,  4.5167e-01,\n",
       "            8.9898e-01,  2.7553e-01]],\n",
       "\n",
       "         [[-1.2364e+00, -1.0861e-01,  5.7612e-01,  ..., -6.5710e-01,\n",
       "            4.6449e-01, -2.9151e-01],\n",
       "          [ 5.4201e-01,  4.5983e-01, -1.3218e-01,  ...,  6.8797e-01,\n",
       "            3.7853e-01,  7.0102e-01],\n",
       "          [ 1.0557e+00,  3.7951e-01,  9.9993e-02,  ...,  1.0149e+00,\n",
       "           -8.0011e-02,  3.1117e-01],\n",
       "          ...,\n",
       "          [ 2.7617e+00,  9.2056e-01,  2.5572e+00,  ..., -2.7046e-01,\n",
       "           -2.6543e-01,  4.2675e-01],\n",
       "          [ 3.2526e+00,  2.6459e+00,  1.0609e+00,  ...,  4.3606e-01,\n",
       "           -1.4836e-01,  5.3356e-01],\n",
       "          [ 1.2066e+00,  2.9331e+00,  7.7201e-03,  ...,  6.1325e-01,\n",
       "           -1.2444e+00,  4.3294e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.8954e-01, -9.0881e-01, -3.9374e-01,  ..., -1.0515e+00,\n",
       "           -4.3844e-01,  4.8402e-01],\n",
       "          [ 1.0609e+00, -1.1448e+00, -7.7390e-01,  ..., -4.1185e-01,\n",
       "           -8.2883e-01, -6.0351e-01],\n",
       "          [ 5.0185e-01, -6.5957e-01, -5.7257e-02,  ..., -1.2351e+00,\n",
       "           -6.1601e-01, -5.3572e-01],\n",
       "          ...,\n",
       "          [ 2.8482e-01,  9.0139e-01, -4.6547e-01,  ..., -1.0758e+00,\n",
       "            5.9336e-01, -1.4398e+00],\n",
       "          [-1.4410e+00,  1.8157e+00, -1.4097e-01,  ..., -1.1282e+00,\n",
       "            1.1474e+00, -1.1473e+00],\n",
       "          [ 9.0526e-01,  2.4593e-01, -1.1596e+00,  ...,  3.7836e-01,\n",
       "           -1.2631e+00, -4.5477e-01]],\n",
       "\n",
       "         [[-9.2652e-01,  2.5459e+00,  3.0600e-01,  ...,  3.4490e-01,\n",
       "            1.9553e+00, -5.4894e-01],\n",
       "          [ 4.5858e-01, -2.1932e+00,  1.7457e-01,  ...,  1.7436e+00,\n",
       "           -2.5849e+00,  2.2585e+00],\n",
       "          [ 1.7932e-02, -2.7316e+00,  2.1564e-01,  ...,  6.8611e-01,\n",
       "           -4.1920e+00,  1.6138e+00],\n",
       "          ...,\n",
       "          [ 2.3517e-01, -6.8795e+00,  2.4382e+00,  ...,  1.0712e+00,\n",
       "           -3.7377e+00,  2.1150e+00],\n",
       "          [-5.6485e-01, -5.2606e+00,  1.9043e+00,  ...,  6.5478e-01,\n",
       "           -4.0746e+00,  7.2067e-01],\n",
       "          [-4.5101e-02, -3.6478e+00,  1.7280e-01,  ..., -7.5855e-01,\n",
       "           -4.0225e+00,  1.6237e+00]],\n",
       "\n",
       "         [[-2.0252e+00, -3.5049e-01, -1.1153e+00,  ..., -3.9788e-01,\n",
       "            6.0882e-02,  2.5314e-01],\n",
       "          [ 2.0696e+00, -4.9512e-01,  1.0584e+00,  ...,  7.4010e-01,\n",
       "            4.9070e-01,  5.7455e-01],\n",
       "          [ 2.5638e+00,  1.1148e+00, -5.5302e-01,  ...,  1.2067e-01,\n",
       "            3.6514e-01, -1.7264e-01],\n",
       "          ...,\n",
       "          [ 4.7496e+00, -1.1327e+00,  3.4154e+00,  ...,  1.0882e+00,\n",
       "            5.4831e-01, -2.3920e-01],\n",
       "          [ 3.7342e+00, -7.3702e-01,  2.6068e+00,  ...,  3.8731e-01,\n",
       "           -4.0681e-01, -8.3097e-01],\n",
       "          [ 2.0753e+00,  1.0187e+00,  2.0027e+00,  ...,  5.9608e-01,\n",
       "           -1.2866e-01, -3.3630e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.9407e-02, -8.5679e-02,  1.7006e-02,  ...,  1.0696e-01,\n",
       "           -2.7256e-02,  1.2712e-02],\n",
       "          [-1.1028e-01, -2.6695e-01, -2.7972e-01,  ...,  7.3320e-02,\n",
       "            8.1304e-02,  9.9563e-01],\n",
       "          [ 2.2058e-01,  5.5391e-01, -1.4877e+00,  ..., -2.8705e-01,\n",
       "            3.1862e-01,  8.9564e-01],\n",
       "          ...,\n",
       "          [-2.2597e+00,  4.0054e-01,  3.5313e-01,  ..., -3.1097e-01,\n",
       "           -6.2333e-01,  6.2799e-02],\n",
       "          [-4.0290e-01,  4.4471e-01, -5.3869e-01,  ...,  3.8806e-01,\n",
       "            7.7051e-01, -8.9604e-02],\n",
       "          [-6.9789e-02,  9.6001e-01, -1.9557e-01,  ...,  1.2244e+00,\n",
       "           -4.5771e-01, -4.4116e-01]],\n",
       "\n",
       "         [[ 1.9984e-02,  9.9455e-03, -1.8535e-02,  ...,  2.8180e-02,\n",
       "            3.0411e-02,  5.3314e-02],\n",
       "          [ 5.9644e-01,  5.1996e-01, -1.2417e+00,  ..., -7.3600e-02,\n",
       "            1.1116e+00,  4.7234e-01],\n",
       "          [ 9.7821e-01, -1.1090e+00, -1.6003e-01,  ...,  1.1247e+00,\n",
       "           -1.9147e-01,  2.4299e-01],\n",
       "          ...,\n",
       "          [-2.4673e+00,  2.1871e+00,  1.5703e+00,  ..., -4.3630e-01,\n",
       "           -1.2542e-01, -6.9803e-01],\n",
       "          [ 2.0129e-01,  7.3901e-01, -9.9507e-01,  ..., -1.5172e+00,\n",
       "           -4.1022e-01, -5.7266e-01],\n",
       "          [ 2.5452e-02,  8.2747e-01, -5.4466e-01,  ..., -5.8290e-01,\n",
       "           -9.6744e-01, -4.3227e-01]],\n",
       "\n",
       "         [[ 3.0771e-02,  3.3925e-02, -9.5088e-02,  ...,  2.0078e-02,\n",
       "           -1.8055e-03,  3.6985e-03],\n",
       "          [-7.0360e-01,  1.2550e-01,  2.7324e-01,  ...,  2.4933e-01,\n",
       "           -1.0440e+00,  2.5170e+00],\n",
       "          [-3.4458e-01, -8.2069e-01, -4.0843e-01,  ..., -7.7839e-01,\n",
       "           -7.3081e-01, -2.8720e-01],\n",
       "          ...,\n",
       "          [-6.4247e-01,  2.9498e-01, -1.6238e+00,  ...,  1.0017e+00,\n",
       "           -4.7254e-01,  3.8370e-01],\n",
       "          [ 1.0751e-01,  5.6388e-01, -1.1467e+00,  ...,  4.9151e-01,\n",
       "            4.4171e-01,  4.7236e-01],\n",
       "          [-5.2674e-01,  6.2729e-01, -7.3631e-01,  ..., -9.5472e-02,\n",
       "           -3.0964e-01, -9.4149e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.2988e-02,  1.8975e-02, -2.9906e-03,  ..., -2.4181e-03,\n",
       "           -7.7694e-04,  3.6506e-02],\n",
       "          [ 1.0896e+00, -5.7907e-01,  2.7873e-01,  ...,  5.9871e-01,\n",
       "            2.0423e+00, -1.8797e-01],\n",
       "          [ 1.1956e+00, -2.4500e-01,  9.7125e-01,  ...,  7.4841e-01,\n",
       "           -1.6449e-01, -7.1359e-01],\n",
       "          ...,\n",
       "          [-1.2320e+00,  2.2416e+00,  1.4954e+00,  ...,  3.9171e-01,\n",
       "           -3.1156e-01, -1.0705e+00],\n",
       "          [-9.0054e-01,  2.1070e-01, -2.4055e-01,  ..., -2.8735e-01,\n",
       "           -2.5012e-01, -2.8542e-01],\n",
       "          [ 1.7677e-01,  9.9594e-01, -1.2952e-01,  ...,  3.1505e-01,\n",
       "            1.0217e+00, -2.8011e-01]],\n",
       "\n",
       "         [[-6.6889e-02, -4.6806e-02,  1.3993e-02,  ...,  1.3800e-02,\n",
       "           -6.0449e-02, -1.0146e-01],\n",
       "          [-1.2984e-01, -3.9511e-01,  9.2747e-02,  ...,  2.9087e-01,\n",
       "            1.8776e-01, -2.5012e-02],\n",
       "          [ 1.4572e+00, -1.4012e-01,  1.1444e-01,  ...,  2.8305e-01,\n",
       "           -3.2233e-01, -1.2569e-01],\n",
       "          ...,\n",
       "          [ 7.1413e-01, -1.7208e+00,  6.2938e-02,  ..., -6.0423e-01,\n",
       "            3.3152e-01, -1.3289e+00],\n",
       "          [ 8.2656e-02, -8.4585e-02, -1.6153e+00,  ..., -2.1428e-01,\n",
       "           -1.4150e-01,  1.0627e+00],\n",
       "          [ 6.7371e-01, -6.1994e-01, -2.5474e-01,  ...,  3.9961e-01,\n",
       "            4.5265e-01,  4.9732e-01]],\n",
       "\n",
       "         [[-1.5357e-02,  3.5532e-02, -6.0959e-02,  ..., -2.2750e-02,\n",
       "            4.1216e-03,  3.3249e-03],\n",
       "          [-4.9697e-01, -9.3557e-01, -6.3136e-02,  ...,  6.6151e-01,\n",
       "            4.0965e-01, -7.5030e-02],\n",
       "          [-4.4716e-02, -6.6199e-01, -9.2861e-01,  ...,  5.9766e-01,\n",
       "            2.3181e-01, -2.1284e-01],\n",
       "          ...,\n",
       "          [ 9.3537e-01,  2.7058e-01,  1.1165e+00,  ..., -6.2206e-01,\n",
       "            2.9264e-01,  1.3320e+00],\n",
       "          [ 7.5008e-01,  1.0221e+00, -3.0353e-02,  ...,  1.3531e-01,\n",
       "            1.1982e+00,  1.2872e-02],\n",
       "          [-1.1730e+00, -6.0363e-01,  1.8613e-01,  ...,  4.8842e-01,\n",
       "           -8.2275e-02,  3.5773e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5168,  0.5003, -0.8527,  ..., -1.0179, -1.3143,  0.2035],\n",
       "          [ 0.5839,  0.4706, -0.0539,  ...,  0.7804, -0.5336, -0.4840],\n",
       "          [ 0.6194, -0.1866,  0.5777,  ...,  1.4978, -0.3987, -1.0123],\n",
       "          ...,\n",
       "          [ 1.3470,  0.3720, -0.5412,  ...,  1.6907, -0.3261, -0.6066],\n",
       "          [ 1.6338, -0.9301,  0.1403,  ...,  1.6979,  0.9465, -1.1397],\n",
       "          [ 1.0263, -0.0312,  0.4805,  ...,  1.9947, -0.4926, -1.0369]],\n",
       "\n",
       "         [[ 0.8600, -2.0708,  0.1513,  ...,  0.2453, -2.4785, -0.4229],\n",
       "          [ 1.3937, -0.5899,  1.3122,  ...,  1.7829, -0.9209,  0.0461],\n",
       "          [ 1.2642,  1.6078,  0.4370,  ...,  0.8510,  0.5742, -0.4311],\n",
       "          ...,\n",
       "          [-0.2522,  3.1486, -0.0085,  ...,  0.1856,  3.6584, -0.8100],\n",
       "          [ 0.7939,  1.4203,  0.2039,  ...,  0.5636,  2.3544, -1.3126],\n",
       "          [ 0.5796,  1.1935, -0.4128,  ..., -0.0242,  2.9575, -1.5629]],\n",
       "\n",
       "         [[ 1.0033,  0.3818, -0.1770,  ..., -0.8112, -1.4041, -0.3646],\n",
       "          [-0.8060, -0.2143, -1.7062,  ...,  1.3577, -0.0913,  0.3456],\n",
       "          [-0.1113, -0.4196, -1.3489,  ...,  1.2174,  0.0079,  0.0536],\n",
       "          ...,\n",
       "          [-3.3497, -0.2660,  0.2152,  ...,  1.4347,  0.1310,  1.4777],\n",
       "          [-1.0710, -0.9403, -2.2382,  ...,  1.8840, -0.8573,  0.6312],\n",
       "          [ 0.1759, -0.5456, -0.7188,  ...,  1.3544, -0.2407, -0.2945]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2209, -0.5819,  0.4830,  ..., -0.6500,  1.0846,  0.2840],\n",
       "          [-0.4176, -0.2444, -0.1033,  ..., -1.9155, -1.5817,  0.6707],\n",
       "          [-1.1385,  1.7267, -2.5488,  ..., -2.3843, -1.3253,  0.6908],\n",
       "          ...,\n",
       "          [-1.5273,  1.4584, -2.7749,  ..., -1.0319, -2.3548,  1.2913],\n",
       "          [-0.4061,  2.5040, -2.4008,  ..., -1.3577, -1.8418,  1.6940],\n",
       "          [-0.3213,  0.4250, -1.2700,  ..., -3.8195, -0.4979,  1.6445]],\n",
       "\n",
       "         [[ 0.2557,  0.5515,  0.5423,  ...,  0.7245,  0.0758,  0.8386],\n",
       "          [ 0.0373,  1.1293, -0.8812,  ...,  1.3053,  0.1991,  1.0668],\n",
       "          [ 0.1955,  1.5928, -0.9004,  ...,  0.8965, -0.3034, -0.3748],\n",
       "          ...,\n",
       "          [-0.0899,  2.2438, -0.5928,  ...,  0.3604, -1.3797, -0.0256],\n",
       "          [ 1.0178,  2.0922, -0.1509,  ...,  1.3384, -1.0962, -0.1963],\n",
       "          [ 1.6399,  1.9349,  1.2059,  ..., -0.5345, -1.0859,  0.4052]],\n",
       "\n",
       "         [[-0.7103,  0.3011, -1.5822,  ..., -0.4242,  0.2360, -1.3157],\n",
       "          [ 0.0054,  1.0721,  1.2615,  ...,  0.6028, -0.2910,  0.4983],\n",
       "          [-0.3964,  0.6106, -0.1719,  ...,  1.1167, -0.9742,  1.4335],\n",
       "          ...,\n",
       "          [ 1.7506,  0.9744,  1.3645,  ...,  1.5455,  0.3070,  1.9734],\n",
       "          [-0.9912,  0.5391,  1.5399,  ...,  0.9224,  0.0180,  3.2051],\n",
       "          [-0.3301,  0.1262,  2.0273,  ...,  2.3883,  0.8853, -0.5951]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-6.0670e-03,  4.1580e-02, -6.0120e-02,  ...,  5.8650e-02,\n",
       "           -5.0545e-02, -7.4066e-02],\n",
       "          [-1.3468e+00,  1.2899e-01,  1.0814e+00,  ..., -3.7750e-01,\n",
       "           -3.3316e-01, -2.1959e-01],\n",
       "          [-5.5962e-01,  5.0996e-01,  1.2739e+00,  ..., -3.0220e-01,\n",
       "            1.1735e-01,  8.0562e-01],\n",
       "          ...,\n",
       "          [ 4.0354e-01, -1.3779e+00, -1.7089e-01,  ..., -7.0931e-01,\n",
       "           -1.5366e+00,  4.9889e-01],\n",
       "          [-1.0464e-01,  6.3718e-01,  1.1747e+00,  ...,  3.1930e-01,\n",
       "           -1.4733e+00,  2.9720e-01],\n",
       "          [ 4.8980e-01, -3.8611e-02,  1.0899e+00,  ...,  3.5262e-01,\n",
       "           -1.5532e+00, -7.8569e-01]],\n",
       "\n",
       "         [[ 5.0298e-02, -3.1196e-03,  2.3201e-02,  ..., -2.5890e-02,\n",
       "           -1.5499e-02, -2.3228e-02],\n",
       "          [-1.0113e+00,  5.7627e-01,  4.9574e-01,  ..., -3.2675e-01,\n",
       "            1.8657e-01,  8.2123e-01],\n",
       "          [ 1.4849e-01,  7.7403e-01, -1.0155e+00,  ...,  3.1667e-01,\n",
       "           -1.8597e-01,  4.8591e-01],\n",
       "          ...,\n",
       "          [-1.2798e-01, -5.1138e-01,  1.0950e+00,  ...,  3.6580e+00,\n",
       "            2.7944e-02, -6.0400e-01],\n",
       "          [ 5.0271e-01, -1.6136e+00, -1.8023e-01,  ..., -5.1404e-02,\n",
       "            9.7688e-01, -1.7705e-01],\n",
       "          [-5.7576e-01,  2.3451e-01, -5.6928e-02,  ...,  1.7267e-01,\n",
       "            5.6934e-02,  1.5519e+00]],\n",
       "\n",
       "         [[-2.1214e-02,  3.3352e-02, -8.7513e-02,  ..., -8.9315e-03,\n",
       "            3.0822e-02,  3.8786e-02],\n",
       "          [-5.2402e-01, -2.6213e-01, -2.3345e-01,  ...,  3.4806e-01,\n",
       "            1.7069e-01, -2.4915e-04],\n",
       "          [-4.9385e-01,  4.8865e-01, -4.3231e-01,  ...,  7.6064e-01,\n",
       "           -2.9904e-02,  1.8609e-01],\n",
       "          ...,\n",
       "          [-1.5463e-01,  3.1104e+00, -7.4308e-01,  ..., -2.0623e-01,\n",
       "           -7.7929e-01,  9.4195e-01],\n",
       "          [-7.9531e-01,  1.3734e+00, -4.3312e-01,  ..., -4.4867e-01,\n",
       "            1.8048e-01,  6.7478e-02],\n",
       "          [-7.1460e-01,  5.9888e-01,  1.0618e+00,  ...,  5.3553e-01,\n",
       "           -7.6815e-01, -2.0369e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0483e-01,  3.7457e-02, -1.1568e-03,  ..., -4.4699e-02,\n",
       "           -8.8918e-03,  1.7837e-02],\n",
       "          [ 8.6269e-01, -1.4697e-01,  3.6745e-01,  ...,  3.1546e-01,\n",
       "            3.5175e-02, -3.0443e-01],\n",
       "          [ 5.1551e-01,  2.5198e-01,  1.5730e-01,  ...,  1.4892e+00,\n",
       "           -5.0922e-01,  2.0167e+00],\n",
       "          ...,\n",
       "          [-8.4730e-01, -4.3078e-01,  5.2054e-01,  ..., -9.0683e-02,\n",
       "            2.3514e-01, -9.9464e-02],\n",
       "          [-6.5804e-01, -7.2872e-01, -3.5989e-02,  ...,  1.0229e+00,\n",
       "           -7.1774e-01,  9.4541e-01],\n",
       "          [-8.0607e-01, -7.0931e-01,  7.0981e-01,  ...,  9.3562e-02,\n",
       "           -8.5871e-01,  1.3432e-01]],\n",
       "\n",
       "         [[ 9.2671e-02,  1.3452e-02,  5.3226e-02,  ...,  3.1511e-03,\n",
       "            4.3145e-02,  1.1899e-02],\n",
       "          [-1.5642e-01,  1.9026e-01,  7.6596e-01,  ..., -1.3407e-01,\n",
       "            2.6676e-01, -5.0297e-01],\n",
       "          [ 6.1654e-01,  8.3766e-01,  1.0002e+00,  ...,  1.2987e-01,\n",
       "            1.4224e+00, -4.2694e-01],\n",
       "          ...,\n",
       "          [-3.0883e-02,  1.5424e+00,  6.3994e-01,  ..., -7.0803e-01,\n",
       "            2.7368e+00,  1.4347e+00],\n",
       "          [ 1.9046e-01,  2.8000e+00, -1.0230e+00,  ..., -9.5443e-02,\n",
       "            6.7176e-01,  5.6664e-02],\n",
       "          [-2.2475e-01,  9.7459e-01,  2.7916e+00,  ..., -2.6344e-01,\n",
       "            6.6847e-01, -1.8378e+00]],\n",
       "\n",
       "         [[-1.0774e-01,  2.8406e-02, -5.5795e-02,  ..., -8.4050e-02,\n",
       "            6.1122e-02, -6.3834e-03],\n",
       "          [ 2.9483e-01, -4.6036e-01, -5.0067e-01,  ..., -4.2501e-01,\n",
       "            1.4048e+00,  3.5766e-02],\n",
       "          [-7.1402e-01, -6.3282e-01, -6.3516e-01,  ..., -1.0530e+00,\n",
       "            4.5487e-01, -1.2223e+00],\n",
       "          ...,\n",
       "          [-3.1073e-01, -1.3114e-01,  6.1908e-01,  ..., -1.1282e+00,\n",
       "            9.6892e-01,  1.1984e-01],\n",
       "          [-9.2516e-01,  1.1405e-01,  1.4297e-01,  ...,  2.4874e-01,\n",
       "           -2.8435e-01,  3.1334e-01],\n",
       "          [-4.7070e-01, -2.1283e-01,  1.8143e-01,  ..., -6.6503e-01,\n",
       "           -9.3208e-01,  8.6367e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7151, -0.3351, -0.2937,  ...,  0.1779,  0.3182, -0.4845],\n",
       "          [-0.0573, -0.2968, -0.2792,  ...,  1.8097, -0.9933, -0.0485],\n",
       "          [ 0.4551,  0.2350, -0.5202,  ...,  1.4073, -1.1556, -0.5031],\n",
       "          ...,\n",
       "          [ 0.4398,  0.2872, -1.3292,  ...,  1.0791, -0.5067, -0.6926],\n",
       "          [ 1.4281,  0.7992, -0.5960,  ...,  0.2981, -0.7968, -0.0723],\n",
       "          [ 1.4787,  0.0107, -0.4716,  ...,  0.5184, -2.1060, -0.5924]],\n",
       "\n",
       "         [[ 0.1182, -0.0641,  2.3043,  ...,  0.2435,  0.0934, -0.1985],\n",
       "          [ 0.3078, -0.7078, -0.0229,  ..., -0.1684,  0.3255,  0.4997],\n",
       "          [-0.0072, -1.4351, -0.3262,  ..., -0.0116, -0.4237, -1.0236],\n",
       "          ...,\n",
       "          [ 0.0789,  1.0277, -0.1959,  ..., -0.3314, -0.0123,  0.1554],\n",
       "          [-0.1221, -0.4109, -0.2510,  ..., -0.1642,  0.4183, -1.1042],\n",
       "          [ 0.3249, -0.0160, -1.2672,  ...,  0.3571,  0.7415, -0.0222]],\n",
       "\n",
       "         [[-0.1897,  1.0560,  0.4685,  ..., -0.5601,  0.3216, -0.1095],\n",
       "          [-1.2898,  0.1961,  0.3851,  ...,  0.0611, -0.4468, -0.4500],\n",
       "          [-1.2418, -0.5390, -0.3550,  ...,  1.1175,  0.2285, -0.6764],\n",
       "          ...,\n",
       "          [-1.7289, -1.8670, -0.2395,  ...,  0.8597,  0.1823,  0.1264],\n",
       "          [-1.4579, -1.1564,  0.1421,  ...,  1.1056, -0.7289, -0.9327],\n",
       "          [-0.5909,  0.2044, -0.4298,  ...,  1.1715,  0.5954, -0.7546]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.5702,  0.9629, -0.8822,  ..., -0.7408,  0.6916,  0.8577],\n",
       "          [ 1.1006,  1.7073, -1.6259,  ..., -0.9801, -0.5523,  0.2173],\n",
       "          [ 0.6847,  1.8472, -0.7955,  ..., -0.5540, -0.5932,  0.3027],\n",
       "          ...,\n",
       "          [-1.6889,  0.1444,  0.2351,  ..., -0.8126, -1.4681, -0.2635],\n",
       "          [ 0.2845,  1.1499, -0.4750,  ..., -0.8172, -0.8146,  0.3588],\n",
       "          [ 0.0874, -0.2214, -0.0856,  ..., -0.7394, -1.2066,  0.1715]],\n",
       "\n",
       "         [[-0.4207,  0.3802,  0.3173,  ...,  0.7072,  0.0623, -0.0753],\n",
       "          [-0.9885,  1.0626, -0.9565,  ..., -0.0961, -0.5346, -1.2537],\n",
       "          [-0.8144,  1.0409, -0.3393,  ...,  0.7575, -0.7873, -0.3033],\n",
       "          ...,\n",
       "          [ 0.7162,  0.5353,  0.5786,  ...,  1.2553, -0.3931,  0.5719],\n",
       "          [-0.4955,  0.3584, -0.4676,  ...,  0.7423, -0.1553,  0.4724],\n",
       "          [-1.1989,  0.5740, -1.4242,  ..., -0.1654, -0.2418, -1.2209]],\n",
       "\n",
       "         [[-0.7356, -0.0250,  0.4452,  ..., -0.0942,  0.0330, -0.0571],\n",
       "          [ 0.1039, -0.4520,  1.6473,  ...,  0.0384, -0.3122,  0.2989],\n",
       "          [ 0.0984, -1.1736,  1.5161,  ...,  0.2563, -0.7524, -0.1577],\n",
       "          ...,\n",
       "          [ 0.3700,  0.0524,  0.3323,  ..., -0.1997, -1.8872,  0.6791],\n",
       "          [ 0.1144, -0.8560,  1.3444,  ..., -0.9688, -0.0111,  0.6124],\n",
       "          [ 0.3719, -1.1888,  2.9866,  ...,  1.5564,  1.0569,  1.0004]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0627, -0.1041, -0.1861,  ..., -0.2973,  0.2617, -0.1300],\n",
       "          [ 0.9190, -0.4094,  0.9732,  ...,  0.7065, -1.3206,  1.6103],\n",
       "          [-0.3314,  0.7099,  0.8130,  ...,  1.2446, -1.0029,  1.6824],\n",
       "          ...,\n",
       "          [ 0.3073, -0.1798,  2.0175,  ...,  3.8588, -1.2389,  0.9518],\n",
       "          [-1.0282,  0.0810,  1.8490,  ...,  2.1276, -0.6254,  0.2580],\n",
       "          [-2.1301,  0.1848,  0.6389,  ...,  0.8497, -2.1894,  2.4372]],\n",
       "\n",
       "         [[ 0.0701, -0.0366,  0.0433,  ..., -0.0205, -0.1226,  0.1881],\n",
       "          [-0.4828,  0.0397,  0.1133,  ...,  0.6646, -0.4122, -0.4976],\n",
       "          [-0.0560,  0.5185, -0.3796,  ..., -0.0358, -1.7324, -0.5987],\n",
       "          ...,\n",
       "          [ 0.3621, -1.0770,  0.8416,  ..., -1.0863, -1.4621,  1.3165],\n",
       "          [-0.4170, -0.1856, -0.2208,  ...,  0.6679,  0.2648, -0.7330],\n",
       "          [ 0.9327,  0.1231, -0.2568,  ...,  0.0206, -0.5632, -0.0348]],\n",
       "\n",
       "         [[ 0.0102,  0.0407, -0.0427,  ...,  0.0176,  0.0324,  0.0545],\n",
       "          [-0.8474, -0.1339,  0.6198,  ..., -1.1320, -0.1028,  0.0237],\n",
       "          [-0.3179,  0.2617, -0.2293,  ..., -0.3102, -0.2109,  0.9155],\n",
       "          ...,\n",
       "          [-1.1459,  0.6247, -0.4677,  ...,  0.4716,  0.2258,  1.9537],\n",
       "          [ 0.3159, -0.4951,  0.3948,  ...,  0.0583,  0.3305,  2.0492],\n",
       "          [ 0.5957, -0.2422, -0.1601,  ...,  0.0871,  0.6242,  0.0631]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0194, -0.0276,  0.0886,  ...,  0.0796, -0.0209,  0.0248],\n",
       "          [-0.7218,  0.9741,  0.7868,  ..., -0.1377, -0.3252, -1.0529],\n",
       "          [ 0.0102,  0.0130,  0.1943,  ...,  1.0051,  0.9481, -0.4571],\n",
       "          ...,\n",
       "          [-1.2697,  1.1965,  1.8222,  ...,  1.2815,  1.1525, -0.2608],\n",
       "          [-0.9059, -0.1876, -0.2131,  ...,  0.1001,  0.5176, -0.7554],\n",
       "          [-0.2481,  0.0416, -0.7926,  ...,  0.2645, -0.6107, -0.3649]],\n",
       "\n",
       "         [[-0.1515, -0.0920,  0.0492,  ..., -0.0616,  0.0336, -0.0914],\n",
       "          [ 0.1947,  0.3574,  0.4865,  ..., -0.0827, -0.0695,  0.1024],\n",
       "          [ 0.0617, -0.4696,  0.1419,  ..., -0.5913, -0.3143,  0.7776],\n",
       "          ...,\n",
       "          [-0.4784,  1.0185, -0.0705,  ...,  0.2748, -0.4973,  1.3698],\n",
       "          [-0.8326,  0.6881,  0.1242,  ..., -0.5708,  0.6708,  0.8386],\n",
       "          [-1.0543, -0.0815,  0.9794,  ...,  0.3561,  0.6065,  0.8012]],\n",
       "\n",
       "         [[ 0.1127, -0.1414,  0.0995,  ..., -0.1078,  0.0248, -0.1947],\n",
       "          [ 0.3453, -0.7535,  0.9195,  ...,  0.1146, -0.0401,  0.5830],\n",
       "          [-0.6160, -0.7786,  1.2499,  ..., -1.0763,  0.0126, -0.6472],\n",
       "          ...,\n",
       "          [-1.0815,  0.2212,  0.6810,  ..., -1.4694, -0.5813,  0.5124],\n",
       "          [-0.5673, -0.7975, -0.1831,  ...,  0.2839,  0.3034,  0.0535],\n",
       "          [-0.9700,  0.6699, -0.1582,  ...,  0.8679, -0.3234,  1.0039]]]],\n",
       "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dab32b-d2f5-499b-949b-0535ae7a7a9d",
   "metadata": {},
   "source": [
    "你发现了吗？每次更换模型都需要更换导入的对象和代码，这样就非常麻烦，因此Huggingface又封装了全新的类`AutoClasses`："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932dba6a-1fc1-448d-8dd2-e06b0c8faf94",
   "metadata": {},
   "source": [
    "> **AutoClasses**\n",
    "\n",
    "可以通过模型的名字直接定位到使用的模型，是一个通用于大部分模型的功能类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e97d443-353b-4539-a775-24b1d69d94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "PATH = r\"HuggingfaceModels/\"\n",
    "\n",
    "# 对于BERT\n",
    "bert_model = AutoModel.from_pretrained(os.path.join(PATH,'bert-base-chinese'))\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(os.path.join(PATH,'bert-base-chinese'))\n",
    "\n",
    "# 对于GPT-2\n",
    "gpt2_model = AutoModel.from_pretrained(os.path.join(PATH,'gpt2'))\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(os.path.join(PATH,'gpt2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953baad1-db01-41a4-9e53-a47812371b1d",
   "metadata": {},
   "source": [
    "只需要修改模型的名字，就能够实现模型的调用，这比使用Models具体的类方便很多。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c624e9f-c8b0-4951-a67e-fbd9cacb56ca",
   "metadata": {},
   "source": [
    "### 3.4.2 词嵌入工具与词嵌入模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f65d6-1201-4467-8a7c-ef15c5b131f5",
   "metadata": {},
   "source": [
    "**词嵌入**（Word Embedding）是自然语言处理（NLP）中的一种技术，用于将文本中的词汇或子词转换为低维向量表示。词嵌入的核心思想是将文本数据转化为模型可以理解和处理的数字表示，这种表示保留了词汇之间的语义关系。\n",
    "\n",
    "在 Hugging Face 的 Transformers 库中，词嵌入工具主要负责以下任务：\n",
    "\n",
    "1. **将离散的文本数据映射为连续的向量表示**：\n",
    "   - 自然语言中的词汇是离散的符号，例如“猫”或“狗”，这些符号本身并没有数量上的意义。通过词嵌入工具，词汇会被映射到一个低维的向量空间中，这些向量保留了语义信息。例如，语义相似的词汇会在向量空间中彼此靠近。\n",
    "\n",
    "2. **初始化模型输入**：\n",
    "   - 在使用深度学习模型（如 Transformer 模型）进行任务时，文本输入首先会通过分词器（Tokenizer）被分解成 token（子词或词汇），接着这些 token 会被映射到相应的词嵌入向量中。这个过程是模型理解输入文本的第一步。\n",
    "   - 词嵌入向量不仅保留了词汇的语义信息，还为模型提供了丰富的上下文信息，使得模型可以在更高的层次上处理文本数据。\n",
    "\n",
    "3. **提供丰富的语义和上下文表示**：\n",
    "   - 通过词嵌入，模型能够捕捉到词汇之间的复杂关系，例如同义词、反义词、类比等。对于 Transformer 模型而言，这些向量表示是后续处理的基础，模型通过多层的注意力机制来进一步处理和理解这些向量表示。\n",
    "\n",
    "在大规模预训练模型（如 BERT、GPT、RoBERTa）中，词嵌入工具与模型架构紧密结合。模型的整个推理过程实际上是从词嵌入开始的：\n",
    "\n",
    "1. **输入处理和词嵌入生成**：\n",
    "   - 当文本输入到大模型时，首先会通过 Tokenizer 将文本拆分为若干个 token，并将这些 token 映射为词汇表中的索引。这些索引会被送入嵌入层（Embedding Layer），生成对应的词嵌入向量。这些向量包含了词汇的语义信息，是模型后续处理的基础。\n",
    "   - 举例来说，在 BERT 模型中，嵌入层会将每个 token 的索引映射为一个固定维度的向量（例如 768 维度），这些向量会作为 BERT 模型的初始输入。\n",
    "\n",
    "2. **上下文相关性**：\n",
    "   - Transformer 模型的一个核心特点是通过自注意力机制（Self-Attention）捕捉序列中不同词汇的上下文关系。词嵌入工具生成的向量为这种上下文相关性提供了基础。\n",
    "   - 例如，在句子“我喜欢苹果”中，“苹果”的词嵌入不仅代表这个词本身，还会通过注意力机制捕捉到与“喜欢”和“我”的关系，从而产生一个上下文相关的表示。\n",
    "\n",
    "3. **训练和微调过程中的更新**：\n",
    "   - 在预训练模型的微调过程中，词嵌入也会被更新，以适应特定任务的数据。例如，在情感分类任务中，词嵌入可能会被微调，以更好地区分表示积极和消极情感的词汇。\n",
    "   - 这种更新使得词嵌入不仅包含通用的语义信息，还能够适应具体的任务需求，从而提高模型在特定任务上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b306df0-f538-4756-9ce9-83c3d96b86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9940f73b-d9e0-48ed-ab85-8b17aa3d3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                label, content = parts\n",
    "                data.append(content) #只要content，不要label\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6611b260-4cef-4e48-b2cd-68ff3203e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "file_path = r\"DLdata/cnews_train_sampled_2000.txt\"\n",
    "\n",
    "# 读取数据\n",
    "data = read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5bf82a3-a3be-48e7-bebb-08d294e19e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 samples: ['新浪正在视频直播尼克斯vs魔术 魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？(新体)[视频直播室] [视频直播室-教育网专用] [图文直播室]', '弗老大同意终止合同 高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。北京队助理教练袁超对新华社说，“弗朗西斯下午来到首钢体育馆，告诉球队，他已经决定离开了。”33岁的弗朗西斯在上一轮对阵江苏队的比赛中，没有能出场，他在中场休息时间无故离开了更衣室。在赛后的新闻发布会上，闵鹿蕾确认了弗朗西斯中场离开的消息，并且说“这是我第一次看到有球员在比赛期间离开的。”闵鹿蕾的一番话，更加加剧了弗朗西斯离开北京队的可能性，而且他在25号缺席了球队的训练，原因是要和家里人度过圣诞节，他在接受采访时候表示：“我没有无故不训练，我给教练打过招呼了，他也答应了。”袁超在接受新华社采访时候，终于说出了今天谈判的进展，“我今天早上和弗朗西斯谈了谈关于他中场离开和圣诞节不训练的事儿，我告诉他，为了球队的利益，我们想让他离开。当时他在会谈中没有给我一个明确的答复。”“但是，当他下午出现在首钢训练馆中的时候，他说他已经准备好要离开了。”袁超说。无论北京俱乐部还是弗朗西斯，都希望双方有个圆满的结局。过去的两周，弗朗西斯一共为北京打了4场比赛，场均3分钟内得到0.5分，0.7个篮板，这和昔日的三次NBA全明星队员相比，确实相差甚远。俱乐部做出这样的决定，或许对双方都有好处。(FRANK)']\n"
     ]
    }
   ],
   "source": [
    "# 查看前2个样本\n",
    "print(f\"First 2 samples: {data[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba30411a-aa62-4c3b-9d5d-95950af05ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "PATH = r\"HuggingfaceModels/\"\n",
    "\n",
    "# 加载预训练的BERT分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(PATH,'bert-base-chinese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16f0a430-cf30-48ec-be46-0e0fd963a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: 新浪正在视频直播尼克斯vs魔术 魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？(新体)[视频直播室] [视频直播室-教育网专用] [图文直播室] \n",
      "\n",
      "\n",
      "Tokens: ['新', '浪', '正', '在', '视', '频', '直', '播', '尼', '克', '斯', 'vs', '魔', '术', '魔', '兽', '小', '斯', '强', '强', '对', '话', '新', '浪', '体', '育', '讯', '12', '月', '31', '日', '8', ':', '00', '，', '新', '浪', '体', '育', '将', '为', '您', '视', '频', '直', '播', '魔', '术', '主', '场', '迎', '战', '尼', '克', '斯', '的', '比', '赛', '。', '摆', '脱', '了', '赛', '季', '初', '的', '低', '迷', '之', '后', '，', '尼', '克', '斯', '打', '出', '14', '胜', '1', '负', '战', '绩', '，', '最', '近', '他', '们', '在', '圣', '诞', '大', '战', '中', '又', '战', '胜', '了', '公', '牛', '，'] \n",
      "\n",
      "\n",
      "Token IDs: [3173, 3857, 3633, 1762, 6228, 7574, 4684, 3064, 2225, 1046, 3172, 8349, 7795, 3318, 7795, 1077, 2207, 3172, 2487, 2487, 2190, 6413, 3173, 3857, 860, 5509, 6380, 8110, 3299, 8176, 3189, 129, 131, 8136, 8024, 3173, 3857, 860, 5509, 2199, 711, 2644, 6228, 7574, 4684, 3064, 7795, 3318, 712, 1767, 6816, 2773, 2225, 1046, 3172, 4638, 3683, 6612, 511, 3030, 5564, 749, 6612, 2108, 1159, 4638, 856, 6837, 722, 1400, 8024, 2225, 1046, 3172, 2802, 1139, 8122, 5526, 122, 6566, 2773, 5327, 8024, 3297, 6818, 800, 812, 1762, 1760, 6414, 1920, 2773, 704, 1348, 2773, 5526, 749, 1062, 4281, 8024]\n"
     ]
    }
   ],
   "source": [
    "# 对每个文本进行分词\n",
    "for text in data:\n",
    "    #将文本输入tokenizer，直接分词\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    #分完词后，直接使用convert_tokens_to_ids进行token编码\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    print(f\"Original Text: {text} \\n\\n\")\n",
    "    print(f\"Tokens: {tokens[:100]} \\n\\n\")\n",
    "    print(f\"Token IDs: {token_ids[:100]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b329a-22f2-47d2-b2d8-791c31adfac4",
   "metadata": {},
   "source": [
    "> 进行批量数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "457454f7-1e11-4183-b434-ecef1ac59d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "def sentence_split(text):\n",
    "    sentence_separators = ['。', '！', '？', '；', '…', '：','”',' ',]\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for i, char in enumerate(text):\n",
    "        if char in sentence_separators:\n",
    "            sentences.append(text[start:i + 1])\n",
    "            start = i + 1\n",
    "    if start < len(text):\n",
    "        sentences.append(text[start:])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d082842e-b0ff-437d-885f-0a5b3c7f9521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新浪正在视频直播尼克斯vs魔术 ',\n",
       " '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。',\n",
       " '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？',\n",
       " '(新体)[视频直播室] ',\n",
       " '[视频直播室-教育网专用] ',\n",
       " '[图文直播室]']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59a8738d-650e-4c39-bc0e-a68ac615b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#句子降维\n",
    "sentence_splited = [sentence_split(sentences) for sentences in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4155514-c644-4981-864e-b1cd79489c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['新浪正在视频直播尼克斯vs魔术 ', '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。', '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。', '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。', '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？', '(新体)[视频直播室] ', '[视频直播室-教育网专用] ', '[图文直播室]']\n"
     ]
    }
   ],
   "source": [
    "for item in sentence_splited:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98bfa1aa-429b-4e26-862d-7d4d506bd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = [item for sublist in sentence_splited for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ab46e4a-1095-464b-bc4e-e41c025f9528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新浪正在视频直播尼克斯vs魔术 ',\n",
       " '魔兽小斯强强对话新浪体育讯12月31日8:00，新浪体育将为您视频直播魔术主场迎战尼克斯的比赛。',\n",
       " '摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '而最近4连胜的魔术也想在这场比赛中一试牛刀，连胜凯尔特人马刺的他们，何惧尼克斯？',\n",
       " '(新体)[视频直播室] ',\n",
       " '[视频直播室-教育网专用] ',\n",
       " '[图文直播室]',\n",
       " '弗老大同意终止合同 ',\n",
       " '高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6d722906-5d1b-4953-b3ff-9fdb03d6b457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617810"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_list.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eed22ea4-5763-448a-a2c5-fa697787f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences_by_length(sentences, min_len, max_len):\n",
    "    \"\"\"\n",
    "    筛选出字数超过指定最小长度的所有句子。\n",
    "\n",
    "    参数：\n",
    "    sentences (list of str): 输入的句子列表。\n",
    "    min_length (int): 最小字数长度。\n",
    "\n",
    "    返回：\n",
    "    List[str]: 筛选后的句子列表。\n",
    "    \"\"\"\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(sentence) > min_len and len(sentence) < max_len]\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2c3cf9d-2cd2-4be4-a119-925a11fb16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选掉过短的句子\n",
    "filtered_data = filter_sentences_by_length(merged_list,50,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d0298f76-dbed-460a-a896-6028699585cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110887"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80799d76-61f9-4c5c-a6e0-fd939dcff4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['摆脱了赛季初的低迷之后，尼克斯打出14胜1负战绩，最近他们在圣诞大战中又战胜了公牛，不过随后一战却再次被热火打败。',\n",
       " '如今尼克斯两胜公牛，两败于凯尔特人和热火，东部四强中只有魔术还没交手，两队在11月3日曾被安排一战，但是因故未能进行，急欲给自己加盖强队标签的尼克斯会在这场迟来的比赛中全力以赴。',\n",
       " '高层确认为球队利益让他离去新浪体育讯北京时间12月27日，来自新华网英文版消息，在经历了两周的效力之后，弗朗西斯决定离开北京队，俱乐部高层对此也做了确认。',\n",
       " '在赛后的新闻发布会上，闵鹿蕾确认了弗朗西斯中场离开的消息，并且说“这是我第一次看到有球员在比赛期间离开的。',\n",
       " '闵鹿蕾的一番话，更加加剧了弗朗西斯离开北京队的可能性，而且他在25号缺席了球队的训练，原因是要和家里人度过圣诞节，他在接受采访时候表示：',\n",
       " '袁超在接受新华社采访时候，终于说出了今天谈判的进展，“我今天早上和弗朗西斯谈了谈关于他中场离开和圣诞节不训练的事儿，我告诉他，为了球队的利益，我们想让他离开。',\n",
       " '过去的两周，弗朗西斯一共为北京打了4场比赛，场均3分钟内得到0.5分，0.7个篮板，这和昔日的三次NBA全明星队员相比，确实相差甚远。',\n",
       " '他让整个世界都不同了新浪体育讯北京时间1月16日(美国当地时间1月15日)消息，休斯敦火箭客场挑战亚特兰大老鹰，火箭克服了种种不利因素，最终以112-106战胜了对手。',\n",
       " '和昨天的怒批裁判不同，今天阿帅开起了记者的玩笑，对《休斯敦纪实报》记者费根说，“你跟队报道比赛，你告诉我(赢球的)原因吧。',\n",
       " '对于今天的比赛，阿德尔曼总结道，“我们过去两年，我告诉他们，应该坚持下去，我们有连续赢得比赛的潜力，我们需要像今晚一样终结比赛，今天大家都很努力，阿隆今天打出了一场很好的比赛，手感很好，在昨晚经历了那样一场比赛后，我为他们今晚的表现骄傲。']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2c605b08-2ef9-4dbe-b338-a1c78e723828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a487843-0d44-4e62-9fc9-cd16479f0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量处理多个文本\n",
    "encoded_inputs = tokenizer(filtered_data, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fcf879-f08f-44e8-89ef-26bff3889bac",
   "metadata": {},
   "source": [
    "> **建立好词汇表后，有哪些功能可以调用**？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be7a2cef-4255-401d-8f95-ac5e6ce7f5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 3030, 5564,  ...,    0,    0,    0],\n",
       "        [ 101, 1963,  791,  ...,    0,    0,    0],\n",
       "        [ 101, 7770, 2231,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1920, 1213,  ...,    0,    0,    0],\n",
       "        [ 101, 3418, 2945,  ...,    0,    0,    0],\n",
       "        [ 101, 3418, 2945,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs['input_ids'] #编辑好的seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8b7a21ea-93a7-45aa-9df4-45d844a3e27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs['attention_mask'] #掩码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a1f58-d1af-48f8-8e02-549d45809af0",
   "metadata": {},
   "source": [
    "在批量处理文本后，除了 `input_ids` 和 `attention_mask`，`tokenizer` 返回的对象中还可以包含其他多个有用的张量或指标，这些数据都可以直接用于模型的输入或分析。以下是一些常见的输出以及它们的功能：\n",
    "\n",
    "1. **`input_ids`**\n",
    "   - 这是最基础的输出，表示每个 token 的 ID，直接对应于模型词汇表中的索引。\n",
    "   - 示例：`[101, 你好, 102]` 可能会映射为 `[101, 12895, 102]`。\n",
    "<br><br>\n",
    "\n",
    "2. **`attention_mask`**\n",
    "   - 表示哪些 token 是实际输入内容，哪些是填充（padding）内容。`1` 表示实际内容，`0` 表示填充。\n",
    "   - 用于告诉模型忽略填充部分的影响，确保模型仅关注实际内容。\n",
    "   - 示例：`[1, 1, 1, 0, 0]` 表示前 3 个 token 是实际内容，后 2 个是填充。\n",
    "\n",
    "**`input_ids`** 和 **`attention_mask`** 是模型推理和训练中最常用的输入。\n",
    "<br><br>\n",
    "\n",
    "3. **`token_type_ids`（或 `segment_ids`）**\n",
    "   - 主要用于区分 BERT 中的不同句子（或段落）。在句子对（如问答、自然语言推理）任务中，`token_type_ids` 用于区分两个句子。\n",
    "   - 一般情况下，第一句的 token 标记为 `0`，第二句的 token 标记为 `1`。\n",
    "   - 示例：`[0, 0, 0, 1, 1, 1]` 表示前 3 个 token 属于第一句话，后 3 个 token 属于第二句话。\n",
    "   \n",
    "**`token_type_ids`** 对于句子对任务（如问答、自然语言推理）非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49582cf6-475b-4adb-beb6-5faa3cb51be0",
   "metadata": {},
   "source": [
    "4. **`special_tokens_mask`**\n",
    "   - 用于标记哪些 token 是特殊符号，例如 `[CLS]`, `[SEP]`, `[PAD]` 等。这些 token 在某些任务中可能需要特别处理。\n",
    "   - 示例：`[1, 0, 0, 1, 0, 0, 1]`，表示位置 1、4 和 7 是特殊符号。\n",
    "     \n",
    "**`special_tokens_mask`** 在处理包含特殊符号的文本时有用。\n",
    "<br><br>\n",
    "\n",
    "5. **`offset_mapping`**\n",
    "   - 主要用于精确映射原始文本和 token 之间的位置关系。对于每个 token，`offset_mapping` 返回一个 `(start, end)` 元组，指示该 token 在原始文本中的起止位置。\n",
    "   - 这在命名实体识别（NER）等任务中非常有用。\n",
    "   - 示例：`[(0, 1), (1, 2), (2, 4)]` 表示第一个 token 对应于原始文本的第 0 到 1 个字符，依此类推。\n",
    "\n",
    "**`offset_mapping`** 特别适用于精确文本对齐任务，如命名实体识别（NER）。\n",
    "<br><br>\n",
    "\n",
    "6. **`overflowing_tokens`**\n",
    "   - 当输入文本过长而被截断时，这个字段会返回被截断的 token。这在需要处理被截断部分的任务中很有用。\n",
    "\n",
    "**`overflowing_tokens`** 和 **`num_truncated_tokens`** 用于处理超长文本输入时的分析。\n",
    "<br><br>\n",
    "\n",
    "7. **`num_truncated_tokens`**\n",
    "   - 表示由于输入文本过长而被截断的 token 数量。这个信息可以帮助你了解文本在被截断时损失了多少内容。\n",
    "<br><br>\n",
    "8. **`length`**\n",
    "   - 表示每个输入序列的实际长度（不包含填充部分）。这个信息在分析输入序列的长度分布时非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d93651ae-f95b-46c4-9297-d19e98fc791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      "tensor([[ 101, 3030, 5564,  ...,    0,    0,    0],\n",
      "        [ 101, 1963,  791,  ...,    0,    0,    0],\n",
      "        [ 101, 7770, 2231,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1920, 1213,  ...,    0,    0,    0],\n",
      "        [ 101, 3418, 2945,  ...,    0,    0,    0],\n",
      "        [ 101, 3418, 2945,  ...,    0,    0,    0]])\n",
      "\n",
      "Attention Mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "\n",
      "Token Type IDs:\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "\n",
      "Special Tokens Mask:\n",
      "None\n",
      "\n",
      "Offset Mapping:\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs:\\n{encoded_inputs['input_ids']}\\n\")\n",
    "print(f\"Attention Mask:\\n{encoded_inputs['attention_mask']}\\n\")\n",
    "print(f\"Token Type IDs:\\n{encoded_inputs.get('token_type_ids')}\\n\")\n",
    "print(f\"Special Tokens Mask:\\n{encoded_inputs.get('special_tokens_mask')}\\n\")\n",
    "print(f\"Offset Mapping:\\n{encoded_inputs.get('offset_mapping')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bca5d4-99d1-419d-a3f4-b70d90818a78",
   "metadata": {},
   "source": [
    "### 3.4.3 全流程自动化的Pipelines工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60869e-0b51-4265-85fb-3c3c9d37338d",
   "metadata": {},
   "source": [
    "> **Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c6970-b30d-4185-8052-fc10f11a2ede",
   "metadata": {},
   "source": [
    "Hugging Face 的 pipeline 功能是一个非常强大且易于使用的高层次 API，它允许用户通过简单的接口来访问和使用预训练的 Transformer 模型。pipeline 将复杂的预处理、模型调用和后处理步骤封装在一起，使得用户可以轻松地应用深度学习模型来完成各种自然语言处理（NLP）和计算机视觉任务，而不需要深入了解模型的底层细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1681a5f-0461-4f79-bb56-81f6f55bd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 创建一个 pipeline，自动加载预训练模型和相应的预处理\n",
    "#nlp = pipeline(\"task-name\")\n",
    "\n",
    "# 对文本进行处理，得到结果\n",
    "#result = nlp(\"Some input text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8a06fdd-ee38-43de-a873-423bbb0cb020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello gpt！: what i do. that will help. I know i was here for a week but, you bet. I mean'},\n",
       " {'generated_text': 'Hello gpt！ ˥\\u3101 ˥\\u3102ㄅ ˥ㄈㄇ'},\n",
       " {'generated_text': 'Hello gpt！！！！！！！！！'},\n",
       " {'generated_text': 'Hello gpt！\\n\\nWe can now update the Google Chrome API, a simple feature that was missing from the prior versions.\\n\\n'},\n",
       " {'generated_text': 'Hello gpt！＂\\n\\n(I really should probably make a post on the Internet about how to read a website.)\\n'}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "#只需要输入模型的名字，以及要执行的功能，就能够直接实现功能的执行\n",
    "generator = pipeline('text-generation', model=os.path.join(PATH,'gpt2'))\n",
    "set_seed(42)\n",
    "generator(\"Hello gpt！\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273ef68-2ec9-4d10-b962-ec52c6bf7a69",
   "metadata": {},
   "source": [
    "**在pipelines中，可以选择的任务有**："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a4876-70f5-4ec5-9630-b50793ee85ce",
   "metadata": {},
   "source": [
    "| 字符串                      | 任务描述                                       |\r\n",
    "|:----------------------------|:---------------------------------------------|\r\n",
    "| sentiment-analysis           | 用于文本情感分类的任务。                      |\r\n",
    "| text-generation              | 文本生成任务，如自动写作或补全文本。           |\r\n",
    "| ner                          | 识别文本中的实体（如人名、地点、组织）。       |\r\n",
    "| question-answering           | 针对给定文本的问题回答任务。                   |\r\n",
    "| fill-mask                    | 填充文本中的掩码（mask）词汇的任务。           |\r\n",
    "| summarization                | 自动文本摘要生成任务。                         |\r\n",
    "| translation_xx_to_yy         | 翻译任务，xx 和 yy 表示不同的语言代码。        |\r\n",
    "| text2text-generation         | 将文本转换为另一种形式或语言的任务。           |\r\n",
    "| zero-shot-classification     | 不带训练的直接分类任务，可以为文本分配多个标签。|\r\n",
    "| conversational               | 对话模型，根据对话的历史回应新的对话输入。     |\r\n",
    "| feature-extraction           | 提取文本的特征向量。                           |\r\n",
    "| text-classification          | 文本分类，也被称为主题分类。                   |\r\n",
    "| token-classification         | 分词层面的分类，如词性标注。                   |\r\n",
    "| table-question-answering     | 对结构化表格数据进行问题回答的任务。           |\r\n",
    "| translation                  | 自动翻译任务，通常需要指定源语言和目标语言。    |\r\n",
    "| automatic-speech-recognition | 自动语音识别，将语音转录为文本。               |\r\n",
    "| image-classification         | 图像分类任务。                                 |\r\n",
    "| object-detection             | 在图像中识别多个物体及其位置。                 |\r\n",
    "| text-to-speech               | 文本转语音任务。                               |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c51d87-9401-4f07-a8b1-781948783f83",
   "metadata": {},
   "source": [
    "**也可以直接调用封装好的pipelines类**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478d504-e6fc-4c90-bd0d-9339e51f323c",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce848654-8aba-45c5-a50d-ca928d9bd5d9",
   "metadata": {},
   "source": [
    "> 直接执行某个定义好的pipeline任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a531464-ac56-4896-9043-f456158913b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at HuggingfaceModels/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'LABEL_0', 'score': 0.9099850654602051}, {'label': 'LABEL_1', 'score': 0.09001489728689194}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n",
    "\n",
    "# 指定模型和分词器\n",
    "model_name = os.path.join(PATH,\"gpt2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 直接实例化TextClassificationPipeline类\n",
    "text_classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True,device=device)\n",
    "\n",
    "# 对单个句子进行分类\n",
    "result = text_classifier(\"I love machine learning!\")\n",
    "\n",
    "# 输出结果\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18150169-4c13-4d1e-aadd-85e336800b26",
   "metadata": {},
   "source": [
    "### 3.4.4 Huggingface中的模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ea1c6-8acd-46ea-a1ae-4090b508ae22",
   "metadata": {},
   "source": [
    "（微调，下节课）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5d64b-ab98-427b-b088-1073eedf04a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
