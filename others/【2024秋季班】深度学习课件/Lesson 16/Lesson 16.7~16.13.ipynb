{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # 1 + (5-1) * (1) = 5\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2) #5 + (2 - 1) * (1 * 1) = 6\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # 6 + (5 - 1) * 2 = 14\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2) #14 + (2 - 1) * (2 * 1) = 16\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x),dim=1)\n",
    "        output = F.softmax(x.view(-1,16*5*5),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,3,227,227)) #假设图像的尺寸为227x227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每一层的感受野的计算公式：\n",
    "#这一层的感受野 = 上一层的感受野 + （这一层的核尺寸-1）*连乘（从最初的一层到上一层的步长）\n",
    "#输入图像的r0 = 1, s0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #大卷积核、较大的步长、较多的通道\n",
    "        self.conv1 = nn.Conv2d(3,96,kernel_size=11, stride=4) #1 + (11-1) * (1) = 11\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3,stride=2) #11 + (3-1) * (1 * 4) = 19\n",
    "        \n",
    "        #卷积核、步长恢复正常大小，进一步扩大通道\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=5, padding=2) #19 + (5-1) * (1 * 4 * 2) = 51\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3,stride=2) #51 + (3-1) * (1 * 4 * 2 * 1) = 67\n",
    "        \n",
    "        #连续的卷积层，疯狂提取特征\n",
    "        self.conv3 = nn.Conv2d(256,384,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(384,384,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(384,256,kernel_size=3,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        #全连接层\n",
    "        self.fc1 = nn.Linear(256*6*6,4096) #这里的上层输入是图像中的全部像素\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,1000) #输出ImageNet的一千个类别\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1,256*6*6) #需要将数据的特征部分“拉平”才能够进入FC层\n",
    "        \n",
    "        x = F.relu(F.dropout(self.fc1(x),0.5)) #dropout：随机让50%的权重为0\n",
    "        x = F.relu(F.dropout(self.fc2(x),0.5)) \n",
    "        output = F.softmax(self.fc3(x),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_receptive_field import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # 1 + (5-1) * (1) = 5\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2) #5 + (2 - 1) * (1 * 1) = 6\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # 6 + (5 - 1) * 2 = 14\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2) #14 + (2 - 1) * (2 * 1) = 16\n",
    "        #self.fc1 = nn.Linear(16*5*5,120)\n",
    "        #self.fc2 = nn.Linear(120,84)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        #x = F.tanh(self.fc1(x))\n",
    "        #output = F.softmax(self.fc2(x),dim=1)\n",
    "        #output = F.softmax(x.view(-1,16*5*5),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet5().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0               [32, 32]        0.5        1.0             1.0 \n",
      "        1               [28, 28]        2.5        1.0             5.0 \n",
      "        2               [14, 14]        3.0        2.0             6.0 \n",
      "        3               [10, 10]        7.0        2.0            14.0 \n",
      "        4                 [5, 5]        8.0        4.0            16.0 \n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "receptive_field_dict = receptive_field(net,(1,32,32)) #输入的数据结构，这里的输入不包括样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#当你的PC上有GPU的时候，receptive_field函数会自动在gpu上运行，因此，你必须把输入这个函数的网络放到gpu上，才可以顺利运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = (Kh * Kw * Cin) * Cout + Cout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3,6,3) #3 * 3 * 3 * 6 + 6 = 168\n",
    "conv2 = nn.Conv2d(6,4,3) #(3 * 3 * 6) * 4 + 4 = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.bias.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.bias.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3 = nn.Conv2d(4,16,5,stride=2,padding=1) #(5 * 5 * 4)*16 + 16 = 1616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3.bias.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4个输入，8个输出，kz = 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(4,8,3) #288 + 8 =296\n",
    "conv1_ = nn.Conv2d(4,8,3,groups=2) #144 + 8 = 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#普通卷积 = (ks^2 * C_in) * C_out\n",
    "#分组卷积 = 1/g * (ks^2 * C_in * C_out)，深度卷积时g = C_in\n",
    "#逐点卷积/1x1卷积 = C_in * C_out\n",
    "#深度可分离卷积 = ks^2 * C_in_depth + C_in_pair * C_out_pair\n",
    "#比例 = 1/C_in_depth + C_out_pair/(ks^2 * C_in_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(4,8,3, bias=False) #(3*3 * 4 * 8) = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_depthwise = nn.Conv2d(4,8,3,groups=4,bias=False) #1/4 * 288 = 72\n",
    "conv1_pairwise = nn.Conv2d(8,8,1,bias=False) #64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4722222222222222"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/4 + 8/(9 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4722222222222222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conv1_depthwise.weight.numel() + conv1_pairwise.weight.numel())/conv1.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021PyTorchDL/WEEK9/72.png?versionId=CAEQFRiBgICvypagxxciIDdhZWI1ODNjOGUzYTQ1YTFhOTNmMGQ3MzdlOGVlMTA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,3,229,229))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(3,6,3)\n",
    "                    ,nn.ReLU(inplace=True)\n",
    "                    ,nn.Conv2d(6,4,3)\n",
    "                    ,nn.ReLU(inplace=True)\n",
    "                    ,nn.MaxPool2d(2)\n",
    "                    ,nn.Conv2d(4,16,5,stride=2,padding=1)\n",
    "                    ,nn.ReLU(inplace=True)\n",
    "                    ,nn.Conv2d(16,3,5,stride=3,padding=2)\n",
    "                    ,nn.ReLU(inplace=True)\n",
    "                    ,nn.MaxPool2d(2)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 9, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data).shape #卷积+池化操作之后得到的特征图尺寸的大小以及特征图的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_receptive_field import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0             [229, 229]        0.5        1.0             1.0 \n",
      "        1             [227, 227]        1.5        1.0             3.0 \n",
      "        2             [227, 227]        1.5        1.0             3.0 \n",
      "        3             [225, 225]        2.5        1.0             5.0 \n",
      "        4             [225, 225]        2.5        1.0             5.0 \n",
      "        5             [112, 112]        3.0        2.0             6.0 \n",
      "        6               [55, 55]        5.0        4.0            14.0 \n",
      "        7               [55, 55]        5.0        4.0            14.0 \n",
      "        8               [19, 19]        5.0       12.0            30.0 \n",
      "        9               [19, 19]        5.0       12.0            30.0 \n",
      "        10                [9, 9]       11.0       24.0            42.0 \n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "rfdict = receptive_field(net,(3,229,229))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021PyTorchDL/WEEK9/7.png?versionId=CAEQFRiBgMD2zKyfxxciIGZhMDQ0Y2UyYTA5ZjQ1NjhhMWNjNDQ1Njg3YTFiODZh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features_ = nn.Sequential(nn.Conv2d(3,64,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(64,64,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(64,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(128,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(128,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(256,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                      )\n",
    "        self.clf_ = nn.Sequential(nn.Dropout(0.5)\n",
    "                                  ,nn.Linear(512*7*7,4096),nn.ReLU(inplace=True)\n",
    "                                  ,nn.Dropout(0.5)\n",
    "                                  ,nn.Linear(4096,4096),nn.ReLU(inplace=True)\n",
    "                                  ,nn.Linear(4096,1000),nn.Softmax(dim=1)\n",
    "                                 )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features_(x) #用特征提取的架构提取特征\n",
    "        x = x.view(-1,512*7*7) #调整数据结构，拉平数据\n",
    "        output = self.clf_(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [10, 512, 7, 7]           --\n",
       "|    └─Conv2d: 2-1                       [10, 64, 224, 224]        1,792\n",
       "|    └─ReLU: 2-2                         [10, 64, 224, 224]        --\n",
       "|    └─Conv2d: 2-3                       [10, 64, 224, 224]        36,928\n",
       "|    └─ReLU: 2-4                         [10, 64, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-5                    [10, 64, 112, 112]        --\n",
       "|    └─Conv2d: 2-6                       [10, 128, 112, 112]       73,856\n",
       "|    └─ReLU: 2-7                         [10, 128, 112, 112]       --\n",
       "|    └─Conv2d: 2-8                       [10, 128, 112, 112]       147,584\n",
       "|    └─ReLU: 2-9                         [10, 128, 112, 112]       --\n",
       "|    └─MaxPool2d: 2-10                   [10, 128, 56, 56]         --\n",
       "|    └─Conv2d: 2-11                      [10, 256, 56, 56]         295,168\n",
       "|    └─ReLU: 2-12                        [10, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-13                      [10, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-14                        [10, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-15                      [10, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-16                        [10, 256, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-17                   [10, 256, 28, 28]         --\n",
       "|    └─Conv2d: 2-18                      [10, 512, 28, 28]         1,180,160\n",
       "|    └─ReLU: 2-19                        [10, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-20                      [10, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-21                        [10, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [10, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-23                        [10, 512, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-24                   [10, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-25                      [10, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-26                        [10, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-27                      [10, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-28                        [10, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-29                      [10, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-30                        [10, 512, 14, 14]         --\n",
       "|    └─MaxPool2d: 2-31                   [10, 512, 7, 7]           --\n",
       "├─Sequential: 1-2                        [10, 1000]                --\n",
       "|    └─Dropout: 2-32                     [10, 25088]               --\n",
       "|    └─Linear: 2-33                      [10, 4096]                102,764,544\n",
       "|    └─ReLU: 2-34                        [10, 4096]                --\n",
       "|    └─Dropout: 2-35                     [10, 4096]                --\n",
       "|    └─Linear: 2-36                      [10, 4096]                16,781,312\n",
       "|    └─ReLU: 2-37                        [10, 4096]                --\n",
       "|    └─Linear: 2-38                      [10, 1000]                4,097,000\n",
       "|    └─Softmax: 2-39                     [10, 1000]                --\n",
       "==========================================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.61\n",
       "==========================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 1084.54\n",
       "Params size (MB): 553.43\n",
       "Estimated Total Size (MB): 1643.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg,input_size=(10,3,224,224),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(10,7,7)\n",
    "\n",
    "gap = nn.AvgPool2d(7)\n",
    "\n",
    "gap(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021PyTorchDL/WEEK9/58.png?versionId=CAEQFRiBgIC0zIWfxxciIGE0ZjkyMzI1ZTE3MzQ3MmQ5NDhiZWFlN2UyMmFiYTQ0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(3,192,5,padding=2),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,160,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(160,96,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "                                    ,nn.Dropout(0.25))\n",
    "        self.block2 = nn.Sequential(nn.Conv2d(96,192,5,padding=2),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "                                    ,nn.Dropout(0.25))\n",
    "        self.block3 = nn.Sequential(nn.Conv2d(192,192,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,10,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.AvgPool2d(7,stride=1)\n",
    "                                    ,nn.Softmax(dim=1))\n",
    "    def forward(self,x):\n",
    "        output = self.block3(self.block2(self.block1(x)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= NiN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data).shape #10个特征图，每个特征图尺寸是1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [10, 96, 15, 15]          --\n",
       "|    └─Conv2d: 2-1                       [10, 192, 32, 32]         14,592\n",
       "|    └─ReLU: 2-2                         [10, 192, 32, 32]         --\n",
       "|    └─Conv2d: 2-3                       [10, 160, 32, 32]         30,880\n",
       "|    └─ReLU: 2-4                         [10, 160, 32, 32]         --\n",
       "|    └─Conv2d: 2-5                       [10, 96, 32, 32]          15,456\n",
       "|    └─ReLU: 2-6                         [10, 96, 32, 32]          --\n",
       "|    └─MaxPool2d: 2-7                    [10, 96, 15, 15]          --\n",
       "|    └─Dropout: 2-8                      [10, 96, 15, 15]          --\n",
       "├─Sequential: 1-2                        [10, 192, 7, 7]           --\n",
       "|    └─Conv2d: 2-9                       [10, 192, 15, 15]         460,992\n",
       "|    └─ReLU: 2-10                        [10, 192, 15, 15]         --\n",
       "|    └─Conv2d: 2-11                      [10, 192, 15, 15]         37,056\n",
       "|    └─ReLU: 2-12                        [10, 192, 15, 15]         --\n",
       "|    └─Conv2d: 2-13                      [10, 192, 15, 15]         37,056\n",
       "|    └─ReLU: 2-14                        [10, 192, 15, 15]         --\n",
       "|    └─MaxPool2d: 2-15                   [10, 192, 7, 7]           --\n",
       "|    └─Dropout: 2-16                     [10, 192, 7, 7]           --\n",
       "├─Sequential: 1-3                        [10, 10, 1, 1]            --\n",
       "|    └─Conv2d: 2-17                      [10, 192, 7, 7]           331,968\n",
       "|    └─ReLU: 2-18                        [10, 192, 7, 7]           --\n",
       "|    └─Conv2d: 2-19                      [10, 192, 7, 7]           37,056\n",
       "|    └─ReLU: 2-20                        [10, 192, 7, 7]           --\n",
       "|    └─Conv2d: 2-21                      [10, 10, 7, 7]            1,930\n",
       "|    └─ReLU: 2-22                        [10, 10, 7, 7]            --\n",
       "|    └─AvgPool2d: 2-23                   [10, 10, 1, 1]            --\n",
       "|    └─Softmax: 2-24                     [10, 10, 1, 1]            --\n",
       "==========================================================================================\n",
       "Total params: 966,986\n",
       "Trainable params: 966,986\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 201.32\n",
       "==========================================================================================\n",
       "Input size (MB): 0.12\n",
       "Forward/backward pass size (MB): 48.61\n",
       "Params size (MB): 3.87\n",
       "Estimated Total Size (MB): 52.60\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net,(10,3,32,32),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
