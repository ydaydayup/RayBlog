{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 13.1 深度学习建模目标与性能评估理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从Lesson 13起，我们讲开始系统介绍深度学习建模理论，以及建模过程中的优化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、在Jupyter初始化过程中自动加载常用包的设置方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在每一节课程的开头，我们都要导入常用包，由于这项工作重复而固定，因此我们也可以通过配置jupyter（准确来说应该是ipython）的startup文件，来使得每次新创建一个ipy文件时，都能够自动加载配置好的包，从而就能免去每节开头导入包的相关操作。（所以说，懒惰是推动技术进步的不竭动力。）相关方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 找到startup文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在当前用户主目录下，找到`.ipython`文件夹，然后进入到`profile_default`文件夹内，并找到`startup`文件夹。此处如果profile_default内没有startup文件夹，自己新建一个即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/8ZXCNOWezrHoaEy.jpg\" alt=\"55\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建start.py文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，在startup文件夹内，创建一个start.py文件。关于创建py文件的方法此前介绍过，此处我们只需先创建一个txt文件，然后将其名称和后缀改为start.py即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/pS81Ht6vDUfd7L4.jpg\" alt=\"56\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/aRSxEuTCOlo9UHV.jpg\" alt=\"57\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入每次初始化时需要执行的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在start.py中输入每次初始化时导入包的代码，相关代码如下："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 随机模块\n",
    "import random\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "# 数学模块\n",
    "import math\n",
    "\n",
    "# 绘图模块\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "\n",
    "# 自定义模块\n",
    "from torchLearning import *\n",
    "\n",
    "# 导入以下包从而使得可以在jupyter中的一个cell输出多个结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意，上述cell是raw模式，不是代码模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用记事本打开.py文件，然后复制上述内容然后保存。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/bXWaUhZTJMG7PQz.jpg\" alt=\"58\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 重启ipy，检测是否生效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后需要重启ipy kernel，此处重启的方法也非常简单，只需在jupyter中先将当前kernel关闭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/ORbHfrPWxASEMvZ.jpg\" alt=\"59\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在最左侧栏中选择文件目录的下一个按钮，查看当前运行的kernel和terminal，找到Lesson 13.1（当前打开的ipy文件），然后点击SHUT DOWN。此时当前页面右上角就会显示为No Kernel，点击选择Python 3，就相当于重启了当前jupyter中的Python kernel。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/VdMP52LoZIjEAD4.jpg\" alt=\"60\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/21/aNnWuFBRtKeZA6y.jpg\" alt=\"61\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，也可以直接点击重启按钮，重启当前jupyter kernel。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/26/AqXGEdvliUw154t.jpg\" alt=\"65\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试初始化配置是否生效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此也验证了初始化设置成功，每次创建jupyter文件时都将自动导入我们设置好的第三方库，即可免去每节开始的导包代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、机器学习目标与模型评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在了解深度学习基本模型的概念与实现方法后，接下来，我们将详细探讨深度学习模型优化的常用方法。从上一课的实验中不难发现，要把一个模型“建好”已是不容易，而要想办法把模型的效果进行提升，如果没有基础理论支持和方法论工具，优化过程无异于盲人摸象。因此，本节课将从建模的根本目标出发，围绕模型优化的基本概念和核心理论进行全面梳理，并在此基础之上介绍相关实践方法，逐渐拨开模型优化面前的迷雾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们经常会对模型的好坏优劣进行评估，Lesson 12中我们也使用准确率、MSE等指标评估建模结果，看起来模型评估是围绕某项指标在进行评估，指标好模型就好，指标不好模型就不好，其实并不完全如此。要了解模型的性能其实并不简单，固然我们会使用某些指标去进行模型评估，但其实指标也只是我们了解模型性能的途径而不是模型性能本身。而要真实、深刻的评判模型性能，就必须首先了解机器学习的建模目标，并在此基础之上熟悉我们判断模型是否能够完成目标的一些方法，当然，只有真实了解的模型性能，我们才能进一步考虑如何提升模型性能。因此，在正式讲解模型优化方法之前，我们需要花些时间讨论机器学习算法的建模目标、机器学习算法为了能够达到目标的一般思路，以及评估模型性能的手段，也就是模型评估指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;无论是机器学习还是传统的统计分析模型，核心使命就是探索数字规律，而有监督学习则是希望在探索数字规律的基础上进一步对未来进行预测，当然，在数字的世界，这个预测未来，也就是预测未来某项事件的某项数值指标，如某地区未来患病人次、具备某种数字特征的图片上的动物是哪一类，此处的未来也并非指绝对意义上的以后的时间，而是在模型训练阶段暂时未接触到的数据。正是因为模型有了在未知标签情况下进行预判的能力，有监督学习才有了存在的价值，但我们知道，基本上所有的模型，都只能从以往的历史经验当中进行学习，也就是在以往的、已经知道的数据集上进行训练（如上述利用已知数据集进行模型训练，如利用过往股票数据训练时间序列模型），这里的核心矛盾在于，在以往的数据中提取出来的经验（也就是模型），怎么证明能够在接下来的数据中也具备一定的预测能力呢？或者说，要怎么训练模型，才能让模型在未知的数据集上也拥有良好的表现呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;目的相同，但在具体的实现方法上，传统的数理统计分析建模和机器学习采用了不同的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，在统计分析领域，我们会假设现在的数据和未来的数据其实都属于某个存在但不可获得的总体，也就是说，现在和未来的数据都是从某个总体中抽样而来的，都是这个总体的样本。而正式因为这些数据属于同一个总体，因此具备某些相同的规律，而现在挖掘到的数据规律也就在某些程度上可以应用到未来的数据当中去，不过呢，不同抽样的样本之间也会有个体之间的区别，另外模型本身也无法完全捕获规律，而这些就是误差的来源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;虽然样本和总体的概念是统计学概念，但样本和总体的概念所假设的前后数据的“局部规律一致性”，却是所有机器学习建模的基础。试想一下，如果获取到的数据前后描绘的不是一件事情，那么模型训练也就毫无价值（比如拿着A股走势预测的时间序列预测某地区下个季度患病人次）。因此，无论是机器学习所强调的从业务角度出发，要确保前后数据描述的一致性，还是统计分析所强调的样本和总体的概念，都是建模的基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在有了假设基础之后，统计分析就会利用一系列的数学方法和数理统计工具去推导总体的基本规律，也就是变量的分布规律和一些统计量的取值，由于这个过程是通过已知的样本去推断未知的总体，因此会有大量的“估计”和“检验”，在确定了总体的基本分布规律之后，才能够进一步使用统计分析模型构建模型（这也就是为什么在数理统计分析领域，构建线性回归模型需要先进行一系列的检验和变换的原因），当然，这些模型都是在总体规律基础之上、根据样本具体的数值进行的建模，我们自然有理由相信这些模型对接下来仍然是从总体中抽样而来的样本还是会具备一定的预测能力，这也就是我们对统计分析模型“信心”的来源。简单来说，就是我们通过样本推断总体的规律，然后结合总体的规律和样本的数值构建模型，由于模型也描绘了总体规律，所以模型对接下来从总体当中抽样而来的数据也会有不错的预测效果，这个过程我们可以通过下图来进行表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/05/KIpJCDyq9VQoliN.jpg\" alt=\"37\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而对于机器学习来说，并没有借助“样本-总体”的基本理论，而是简单的采用了一种后验的方法来判别模型有效性，前面说到，我们假设前后获取的数据拥有规律一致性，但数据彼此之间又略有不同，为了能够在捕捉规律的同时又能考虑到“略有不同”所带来的误差，机器学习会把当前能获取到的数据划分成训练集(trainSet)和测试集(testSet)，在训练集上构建模型，然后带入测试集的数据，观测在测试集上模型预测结果和真实结果之间的差异。这个过程其实就是在模拟获取到真实数据之后模型预测的情况，此前说到，模型能够在未知标签的数据集上进行预测，就是模型的核心价值，此时的测试集就是用于模拟未来的未知标签的数据集。如果模型能够在测试集上有不错的预测效果，我们就“简单粗暴”的认为模型可以在真实的未来获取的未知数据集上有不错的表现。其一般过程可以由下图表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.loli.net/2021/02/05/fGzPxCQ1qoOZuFs.jpg\" alt=\"38\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;虽然对比起数理统计分析，机器学习的证明模型有效性的过程更加“简单”，毕竟只要一次“模拟”成功，我们就认为模型对未来的数据也拥有判别效力，但这种“简单”的处理方式却非常实用，可以说，这是一种经过长期实践被证明的行之有效的方法。这也是为什么机器学习很多时候也被认为是实证类的方法，而在以后的学习中，我们也将了解到，机器学习有很多方法都是“经验总结的结果”。相比数理统计分析，确实没有“那么严谨”，但更易于理解的理论和更通用的方法，却使得机器学习可以在更为广泛的应用场景中发挥作用。（当然，负面影响却是，机器学习在曾经的很长一段时间内并不是主流的算法。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;据此，我们称模型在训练集上误差称为训练误差，在测试集上的误差称为泛化误差，不过毕竟在测试集上进行测试还只是模拟演习，我们采用模型的泛化能力来描述模型在未知数据上的判别能力，当然泛化能力无法准确衡量（未知的数据还未到来，到来的数据都变成了已知数据），我们只能通过模型在训练集和测试集上的表现，判别模型泛化能力，当然，就像此前说的一样，最基本的，我们会通过模型在测试集上的表现来判断模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、手动实现训练集和测试集切分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们开始实践模型评估过程，首先是对训练集和测试集的划分，我们尝试创建一个切分训练集和测试集的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(features, labels, rate=0.7):\n",
    "    \"\"\"\n",
    "    训练集和测试集切分函数\n",
    "    \n",
    "    :param features: 输入的特征张量\n",
    "    :param labels：输入的标签张量\n",
    "    :param rate：训练集占所有数据的比例\n",
    "    :return Xtrain, Xtest, ytrain, ytest：返回特征张量的训练集、测试集，以及标签张量的训练集、测试集 \n",
    "    \"\"\"\n",
    "    num_examples = len(features)                              # 总数据量\n",
    "    indices = list(range(num_examples))                       # 数据集行索引\n",
    "    random.shuffle(indices)                                   # 乱序调整                     \n",
    "    num_train = int(num_examples * rate)                      # 训练集数量 \n",
    "    indices_train = torch.tensor(indices[: num_train])        # 在已经乱序的的indices中挑出前num_train数量的行索引值\n",
    "    indices_test = torch.tensor(indices[num_train: ])         \n",
    "    Xtrain = features[indices_train]                          # 训练集特征\n",
    "    ytrain = labels[indices_train]                            # 训练集标签\n",
    "    Xtest = features[indices_test]                            # 测试集特征\n",
    "    ytest = labels[indices_test]                              # 测试集标签\n",
    "    return Xtrain, Xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> &emsp;&emsp;一般来说，训练集和测试集可以按照8：2或7：3比例进行划分。在进行数据划分的过程中，如果测试集划分数据过多，参与模型训练的数据就会相应减少，而训练数据不足则会导致模型无法正常训练、损失函数无法收敛、模型过拟合等问题，但如果反过来测试集划分数据过少，则无法代表一般数据情况测试模型是否对未知数据也有很好的预测作用。因此，根据经验，我们一般来说会按照8：2或7：3比例进行划分。      \n",
    "&emsp;&emsp;看到这里，相信肯定有小伙伴觉得根据所谓的“经验”来定数据集划分比例不太严谨，有没有一种方法能够“精准”的确定什么划分比例最佳呢？例如通过类似最小二乘法或者梯度下降这类优化算法来计算划分比例？各位同学可以尝试着进行思考，并给出自己的答案。课程中将在下一节介绍参数和超参数时给出详细解答。         \n",
    "&emsp;&emsp;值得一提的是，在机器学习领域，充斥着大量的“经验之谈”或者“约定俗成”的规则，一方面这些经验为建模提供了诸多便捷、也节省了很多算力，但另一方面，通过经验来决定影响模型效果的一些“超参数”取值的不严谨的做法，也被数理统计分析流派所诟病。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.arange(10)                # 创建特征0-9\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.arange(1, 11)             # 创建标签1-10，保持和特征+1的关系\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 6, 4, 5, 8, 3, 0]),\n",
       " tensor([9, 7, 2]),\n",
       " tensor([2, 7, 5, 6, 9, 4, 1]),\n",
       " tensor([10,  8,  3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split(f, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，还是在上一节课的内容上，尝试带入训练集进行建模，利用测试集评估模型建模效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26f6196e570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)   \n",
    "\n",
    "# 生成回归类数据集\n",
    "features, labels = tensorGenReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.5044,  1.0000],\n",
       "        [ 0.6704, -0.3829,  1.0000],\n",
       "        [ 0.0302,  0.3826,  1.0000],\n",
       "        ...,\n",
       "        [-0.9164, -0.6087,  1.0000],\n",
       "        [ 0.7815,  1.2865,  1.0000],\n",
       "        [ 1.4819,  1.1390,  1.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26f6196e570>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420) \n",
    "\n",
    "# 初始化数据\n",
    "features, labels = tensorGenReg()\n",
    "\n",
    "# 切分训练集和测试集\n",
    "Xtrain, Xtest, ytrain, ytest = data_split(features, labels)\n",
    "\n",
    "# 初始化核心参数\n",
    "batch_size = 10                                # 小批的数量\n",
    "lr = 0.03                                      # 学习率\n",
    "num_epochs = 5                                 # 训练过程遍历几次数据\n",
    "w = torch.zeros(3, 1, requires_grad = True)    # 随机设置初始权重\n",
    "\n",
    "# 参与训练的模型方程\n",
    "net = linreg                                   # 使用回归方程\n",
    "loss = MSE_loss                                # 均方误差的一半作为损失函数\n",
    "\n",
    "# 模型训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, Xtrain, ytrain):\n",
    "        l = loss(net(X, w), y)\n",
    "        l.backward()\n",
    "        sgd(w, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0002],\n",
       "        [-1.0002],\n",
       "        [ 0.9996]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型在训练集、测试集上的MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_loss(torch.mm(Xtrain, w), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.9141e-05, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_loss(torch.mm(Xtest, w), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们就完成了一整个从数据集划分，到训练集训练，再到测试集上测试模型性能的一整个流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、Dataset和DataLoader基本使用方法与数据集切分函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们尝试使用PyTorch原生库来实现上述功能，不过这个实现过程略显复杂，首先我们需要了解Dataset和DataLoader的基本使用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Dataset和DataLoader的基本使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random_split随机切分函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，在PyTorch的`torch.utils.data`中，提供了`random_split`函数可用于数据集切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单测试函数功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(12).reshape(4, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x15872bd9b08>,\n",
       " <torch.utils.data.dataset.Subset at 0x15872bd9c48>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_split(t, [2, 2])         # 输入切分的每部分数据集数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据生成结果可知，`random_split`函数其实生成了生成器切分结果的生成器，并不是和此前定义的函数一样，直接切分数据后返回。当然这也符合utils.data模块主要生成映射式和迭代式对象的一般规定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(t, [2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用print函数查看生成器内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 10, 11]) tensor([0, 1, 2])\n",
      "tensor([3, 4, 5]) tensor([6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "for tr, te in random_split(t, [2, 2]):\n",
    "    print(tr, te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset和Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于在大多数调库建模过程中，我们都是先通过创建Dataset的子类并将数据保存为该子类类型，然后再使用DataLoader进行数据载入，因此更为通用的做法是先利用Dataset和DatasetLoader这两个类进行数据的读取、预处理和载入，然后再使用random_split函数进行切分。      \n",
    "&emsp;&emsp;再次强调，Dataset类主要负责数据类的生成，在PyTorch中，所有数据集都是Dataset的子类；而DatasetLoader类则是加载模型训练的接口，二者基本使用流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![49](https://i.loli.net/2021/02/07/LQsueTFV9bDlKx1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建数据类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据此前描述，PyTorch中所有的数据都是Dataset的子类，换而言之就是在使用PyTorch建模训练数据时，需要创建一个和数据集对应的类来表示该数据集，此前我们使用的TensorDataset函数其实就是一个简单的类型转化函数，将数据统一转化为“TensorDataset”类然后带入模型进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = tensorGenReg(bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5846,  0.4064, -0.7022],\n",
       "        [ 0.5943,  0.5927,  0.8111],\n",
       "        [-0.4947,  0.2168,  0.0981],\n",
       "        ...,\n",
       "        [-0.4568, -1.1319, -1.7560],\n",
       "        [-1.3112, -0.9356,  1.5156],\n",
       "        [-1.0726,  0.8814, -1.6092]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x17be64eeb48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而TensorDataset其实使用面较窄，最直接的限制就是该函数只能将张量类型转化为TensorDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a22ab840f41d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "TensorDataset([1,2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Dataset wrapping tensors.\n",
       "\n",
       "Each sample will be retrieved by indexing tensors along the first dimension.\n",
       "\n",
       "Arguments:\n",
       "    *tensors (Tensor): tensors that have the same size of the first dimension.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\users\\asus\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TensorDataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更加通用的数据读取方法则是手动创建一个继承自torch.utils.data.dataset的数据类，用来作为当前数据的表示。例如Lesson 11中的乳腺癌数据，通过如下方式进行读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer as LBC\n",
    "data = LBC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单查看data数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data          # 返回数据集的特征数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target        # 返回数据集的标签数组  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.data)     # 返回数据集总个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，创建一个用于表示该数据集的Dataset的子类。在创建Dataset的子类过程中，必须要重写__getitem__方法和__len__方法，其中__getitem__方法返回输入索引后对应的特征和标签，而__len__方法则返回数据集的总数据个数。当然，在必须要进行的__init__初始化过程中，我们也可输入可代表数据集基本属性的相关内容，包括数据集的特征、标签、大小等等，视情况而定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBCDataset(Dataset):\n",
    "    def __init__(self,data):                       # 创建该类时需要输入sklearn导入的数据集\n",
    "        self.features = data.data                  # features属性返回数据集特征\n",
    "        self.labels = data.target                  # labels属性返回数据集标签\n",
    "        self.lens = len(data.data)                 # lens属性返回数据集大小\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 调用该方法时需要输入index数值，方法最终返回index对应的特征和标签\n",
    "        return self.features[index,:],self.labels[index]    \n",
    "\n",
    "    def __len__(self):\n",
    "        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n",
    "        return self.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LBC()\n",
    "LBC_data = LBCDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第三条数据\n",
    "LBC_data.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "       1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "       4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "       2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "       1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "封装好的数据可以直接进行索引，并且能够返回实体结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，我们可以使用random_split方法对其进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定训练集、测试集大小，此处以7：3划分训练集和测试集\n",
    "num_train = int(LBC_data.lens * 0.7)\n",
    "num_test = LBC_data.lens - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train            # 训练集个数\n",
    "num_test             # 测试集个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBC_train, LBC_test = random_split(LBC_data, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注，此时切分的结果是一个映射式的对象，只有dataset和indices两个属性，其中dataset属性用于查看原数据集对象，indices属性用于查看切分后数据集的每一条数据的index（序号）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        Subset\n",
       "\u001b[1;31mString form:\u001b[0m <torch.utils.data.dataset.Subset object at 0x0000017B8803D648>\n",
       "\u001b[1;31mLength:\u001b[0m      398\n",
       "\u001b[1;31mFile:\u001b[0m        d:\\users\\asus\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Subset of a dataset at specified indices.\n",
       "\n",
       "Arguments:\n",
       "    dataset (Dataset): The whole Dataset\n",
       "    indices (sequence): Indices in the whole set selected for subset\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LBC_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LBCDataset at 0x17b864eee08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过切分结果还原原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset == LBC_data      # 还原原数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原始数据集中查找切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[303,\n",
       " 559,\n",
       " 341,\n",
       " 21,\n",
       " 273,\n",
       " 535,\n",
       " 30,\n",
       " 126,\n",
       " 283,\n",
       " 26,\n",
       " 305,\n",
       " 135,\n",
       " 44,\n",
       " 447,\n",
       " 481,\n",
       " 82,\n",
       " 16,\n",
       " 386,\n",
       " 169,\n",
       " 342,\n",
       " 513,\n",
       " 465,\n",
       " 291,\n",
       " 69,\n",
       " 119,\n",
       " 17,\n",
       " 231,\n",
       " 542,\n",
       " 181,\n",
       " 52,\n",
       " 402,\n",
       " 201,\n",
       " 356,\n",
       " 296,\n",
       " 522,\n",
       " 6,\n",
       " 73,\n",
       " 335,\n",
       " 553,\n",
       " 369,\n",
       " 440,\n",
       " 89,\n",
       " 164,\n",
       " 454,\n",
       " 114,\n",
       " 99,\n",
       " 182,\n",
       " 455,\n",
       " 168,\n",
       " 11,\n",
       " 340,\n",
       " 139,\n",
       " 103,\n",
       " 317,\n",
       " 51,\n",
       " 261,\n",
       " 354,\n",
       " 174,\n",
       " 167,\n",
       " 540,\n",
       " 84,\n",
       " 172,\n",
       " 337,\n",
       " 252,\n",
       " 422,\n",
       " 334,\n",
       " 470,\n",
       " 457,\n",
       " 360,\n",
       " 256,\n",
       " 122,\n",
       " 322,\n",
       " 208,\n",
       " 3,\n",
       " 390,\n",
       " 568,\n",
       " 229,\n",
       " 410,\n",
       " 414,\n",
       " 107,\n",
       " 555,\n",
       " 326,\n",
       " 240,\n",
       " 377,\n",
       " 307,\n",
       " 330,\n",
       " 347,\n",
       " 88,\n",
       " 241,\n",
       " 339,\n",
       " 47,\n",
       " 561,\n",
       " 204,\n",
       " 387,\n",
       " 23,\n",
       " 541,\n",
       " 416,\n",
       " 213,\n",
       " 62,\n",
       " 184,\n",
       " 564,\n",
       " 428,\n",
       " 358,\n",
       " 474,\n",
       " 391,\n",
       " 155,\n",
       " 235,\n",
       " 398,\n",
       " 366,\n",
       " 315,\n",
       " 185,\n",
       " 450,\n",
       " 199,\n",
       " 80,\n",
       " 85,\n",
       " 521,\n",
       " 348,\n",
       " 110,\n",
       " 120,\n",
       " 385,\n",
       " 411,\n",
       " 179,\n",
       " 502,\n",
       " 528,\n",
       " 345,\n",
       " 464,\n",
       " 546,\n",
       " 292,\n",
       " 519,\n",
       " 452,\n",
       " 247,\n",
       " 140,\n",
       " 373,\n",
       " 71,\n",
       " 444,\n",
       " 162,\n",
       " 490,\n",
       " 234,\n",
       " 59,\n",
       " 46,\n",
       " 98,\n",
       " 436,\n",
       " 419,\n",
       " 15,\n",
       " 394,\n",
       " 499,\n",
       " 251,\n",
       " 488,\n",
       " 425,\n",
       " 287,\n",
       " 466,\n",
       " 19,\n",
       " 471,\n",
       " 63,\n",
       " 61,\n",
       " 83,\n",
       " 365,\n",
       " 552,\n",
       " 70,\n",
       " 453,\n",
       " 178,\n",
       " 156,\n",
       " 295,\n",
       " 424,\n",
       " 197,\n",
       " 269,\n",
       " 389,\n",
       " 417,\n",
       " 350,\n",
       " 456,\n",
       " 448,\n",
       " 5,\n",
       " 515,\n",
       " 93,\n",
       " 25,\n",
       " 115,\n",
       " 259,\n",
       " 370,\n",
       " 150,\n",
       " 346,\n",
       " 225,\n",
       " 405,\n",
       " 237,\n",
       " 328,\n",
       " 396,\n",
       " 523,\n",
       " 534,\n",
       " 536,\n",
       " 205,\n",
       " 352,\n",
       " 20,\n",
       " 81,\n",
       " 151,\n",
       " 320,\n",
       " 438,\n",
       " 451,\n",
       " 127,\n",
       " 504,\n",
       " 50,\n",
       " 125,\n",
       " 551,\n",
       " 407,\n",
       " 281,\n",
       " 469,\n",
       " 95,\n",
       " 206,\n",
       " 118,\n",
       " 209,\n",
       " 286,\n",
       " 266,\n",
       " 245,\n",
       " 43,\n",
       " 175,\n",
       " 41,\n",
       " 258,\n",
       " 556,\n",
       " 449,\n",
       " 367,\n",
       " 106,\n",
       " 97,\n",
       " 418,\n",
       " 1,\n",
       " 314,\n",
       " 461,\n",
       " 476,\n",
       " 415,\n",
       " 537,\n",
       " 254,\n",
       " 129,\n",
       " 514,\n",
       " 526,\n",
       " 255,\n",
       " 299,\n",
       " 379,\n",
       " 257,\n",
       " 274,\n",
       " 329,\n",
       " 74,\n",
       " 186,\n",
       " 142,\n",
       " 157,\n",
       " 183,\n",
       " 136,\n",
       " 442,\n",
       " 312,\n",
       " 403,\n",
       " 362,\n",
       " 275,\n",
       " 349,\n",
       " 380,\n",
       " 503,\n",
       " 242,\n",
       " 371,\n",
       " 131,\n",
       " 467,\n",
       " 203,\n",
       " 124,\n",
       " 446,\n",
       " 441,\n",
       " 65,\n",
       " 550,\n",
       " 384,\n",
       " 39,\n",
       " 9,\n",
       " 298,\n",
       " 533,\n",
       " 2,\n",
       " 434,\n",
       " 72,\n",
       " 239,\n",
       " 368,\n",
       " 94,\n",
       " 45,\n",
       " 280,\n",
       " 487,\n",
       " 277,\n",
       " 388,\n",
       " 544,\n",
       " 316,\n",
       " 301,\n",
       " 146,\n",
       " 158,\n",
       " 117,\n",
       " 121,\n",
       " 547,\n",
       " 493,\n",
       " 194,\n",
       " 495,\n",
       " 226,\n",
       " 191,\n",
       " 238,\n",
       " 246,\n",
       " 91,\n",
       " 527,\n",
       " 176,\n",
       " 294,\n",
       " 53,\n",
       " 525,\n",
       " 331,\n",
       " 426,\n",
       " 539,\n",
       " 215,\n",
       " 263,\n",
       " 244,\n",
       " 66,\n",
       " 253,\n",
       " 267,\n",
       " 7,\n",
       " 355,\n",
       " 284,\n",
       " 404,\n",
       " 249,\n",
       " 187,\n",
       " 508,\n",
       " 212,\n",
       " 497,\n",
       " 357,\n",
       " 109,\n",
       " 264,\n",
       " 399,\n",
       " 482,\n",
       " 67,\n",
       " 31,\n",
       " 306,\n",
       " 64,\n",
       " 13,\n",
       " 222,\n",
       " 378,\n",
       " 60,\n",
       " 458,\n",
       " 180,\n",
       " 276,\n",
       " 557,\n",
       " 248,\n",
       " 111,\n",
       " 310,\n",
       " 87,\n",
       " 77,\n",
       " 560,\n",
       " 282,\n",
       " 123,\n",
       " 288,\n",
       " 58,\n",
       " 374,\n",
       " 443,\n",
       " 554,\n",
       " 460,\n",
       " 421,\n",
       " 486,\n",
       " 153,\n",
       " 32,\n",
       " 325,\n",
       " 90,\n",
       " 558,\n",
       " 462,\n",
       " 216,\n",
       " 33,\n",
       " 364,\n",
       " 177,\n",
       " 338,\n",
       " 382,\n",
       " 105,\n",
       " 54,\n",
       " 35,\n",
       " 318,\n",
       " 137,\n",
       " 412,\n",
       " 79,\n",
       " 477,\n",
       " 196,\n",
       " 195,\n",
       " 289,\n",
       " 393,\n",
       " 485,\n",
       " 500,\n",
       " 138,\n",
       " 171,\n",
       " 233,\n",
       " 101,\n",
       " 214,\n",
       " 372,\n",
       " 38,\n",
       " 134,\n",
       " 353,\n",
       " 538,\n",
       " 243,\n",
       " 148,\n",
       " 293,\n",
       " 218,\n",
       " 435,\n",
       " 166,\n",
       " 220,\n",
       " 278,\n",
       " 472,\n",
       " 165,\n",
       " 188,\n",
       " 517,\n",
       " 313]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 475, 64, 490, 496, 136, 123, 300, 175, 342]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.indices[:10]             # 抽取的训练集数据的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，无论是迭代式生成数据还是映射式生成数据，都可以使用print查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n",
      "       5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n",
      "       1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n",
      "       1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n",
      "       1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]), 1)\n"
     ]
    }
   ],
   "source": [
    "for i in LBC_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n",
       "        5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n",
       "        1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n",
       "        1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n",
       "        1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]),\n",
       " 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.__getitem__(384)           # 验证是否是LBC_train的第一条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data[LBC_train.indices][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 还是需要强调，虽然PyTorch的数据表示形式会略显复杂，但这是应对复杂大规模数据计算之必须，面对海量、非结构化数据，我们很难去查看一条条数据，而只能通过一些数据集的特性来探索数据信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后使用DataLoader函数进行数据转化，由一般数据状态转化为“可建模”的状态。所谓“可建模”状态，指的是经过DataLoader处理的数据，不仅包含数据原始的数据信息，还包含数据处理方法信息，如调用几个线程进行训练、分多少批次等，DataLoader常用参数如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size:每次迭代输入多少数据，如果是小批量梯度下降，则输入的数据量就是小批量迭代过程中“小批”的数量      \n",
    "- shuffle:是否需要先打乱顺序然后再进行小批量的切分，一般训练集需要乱序，而测试集乱序没有意义      \n",
    "- num_worker:启动多少线程进行计算      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他更多参数，将随着我们介绍的深入逐步进行介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
       "the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Arguments:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of sample loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
       "        the worker processes after a dataset has been consumed once. This allows to \n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\users\\asus\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(LBC_train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(LBC_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 此处需要注意，对于测试集来说，数据装载并不是一定要进行的，如果测试集只是用于检测模型效果，有时可以不用装载直接带入计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，经过DataLoader处理后的数据也可以使用dataset属性查看原数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x15819156e88>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x15819156e88>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset == LBC_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这里值得一提的是，市面上有很多教材在介绍PyTorch深度学习建模过程中的数据集划分过程，会推荐使用scikit-learn中的train_test_split函数。该函数是可以非常便捷的完成数据集切分，但这种做法只能用于单机运行的数据，并且切分之后还要调用Dataset、DataLoader模块进行数据封装和加载，切分过程看似简单，但其实会额外占用非常多的存储空间和计算资源，当进行超大规模数据训练时，所造成的影响会非常明显（当然，也有可能由于数据规模过大，本地无法运行）。因此，为了更好的适应深度学习真实应用场景，在使用包括数据切分等常用函数时，函数使用优先级是      \n",
    "<center>Pytorch原生函数和类>依据张量及其常用方法手动创建的函数>Scikit-Learn函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.建模及评估过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们尝试通过调库实现完整的数据切分、训练、查看建模结果一整个流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据准备过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "features, labels = tensorGenReg()\n",
    "features = features[:, :-1]                                  # 剔除最后全是1的列\n",
    "\n",
    "# 创建一个针对手动创建数据的数据类\n",
    "class GenData(Dataset):\n",
    "    def __init__(self, features, labels):           # 创建该类时需要输入的数据集\n",
    "        self.features = features                    # features属性返回数据集特征\n",
    "        self.labels = labels                        # labels属性返回数据集标签\n",
    "        self.lens = len(features)                   # lens属性返回数据集大小\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 调用该方法时需要输入index数值，方法最终返回index对应的特征和标签\n",
    "        return self.features[index,:],self.labels[index]    \n",
    "\n",
    "    def __len__(self):\n",
    "        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n",
    "        return self.lens\n",
    "\n",
    "# 实例化对象\n",
    "data = GenData(features, labels)\n",
    "    \n",
    "# 切分数据集\n",
    "num_train = int(data.lens * 0.7)\n",
    "num_test = data.lens - num_train\n",
    "data_train, data_test = random_split(data, [num_train, num_test])\n",
    "\n",
    "# 加载数据\n",
    "train_loader = DataLoader(data_train, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化核心参数\n",
    "batch_size = 10                                # 小批的数量\n",
    "lr = 0.03                                      # 学习率\n",
    "num_epochs = 3                                 # 训练过程遍历几次数据\n",
    "\n",
    "# Stage 1.定义模型\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=1):       # 定义模型的点线结构\n",
    "        super(LR, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):                                    # 定义模型的正向传播规则\n",
    "        out = self.linear(x)             \n",
    "        return out\n",
    "\n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "# Stage 2.定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stage 3.定义优化方法\n",
    "optimizer = optim.SGD(LR_model.parameters(), lr = 0.03)\n",
    "\n",
    "# Stage 4.模型训练与测试\n",
    "def fit(net, criterion, optimizer, batchdata, epochs=3):\n",
    "    for epoch  in range(epochs):\n",
    "        for X, y in batchdata:\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net = LR_model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    batchdata = train_loader,\n",
    "    epochs = num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练模型\n",
    "LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.9997, -0.9996]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0005], requires_grad=True)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型参数\n",
    "list(LR_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型在训练集上表现，首先我们可以通过dataset和indices方法还原训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[705,\n",
       " 223,\n",
       " 553,\n",
       " 386,\n",
       " 731,\n",
       " 423,\n",
       " 867,\n",
       " 435,\n",
       " 673,\n",
       " 469,\n",
       " 545,\n",
       " 3,\n",
       " 11,\n",
       " 603,\n",
       " 906,\n",
       " 522,\n",
       " 812,\n",
       " 661,\n",
       " 119,\n",
       " 244,\n",
       " 154,\n",
       " 543,\n",
       " 717,\n",
       " 842,\n",
       " 894,\n",
       " 49,\n",
       " 986,\n",
       " 825,\n",
       " 512,\n",
       " 155,\n",
       " 652,\n",
       " 178,\n",
       " 785,\n",
       " 479,\n",
       " 930,\n",
       " 385,\n",
       " 277,\n",
       " 787,\n",
       " 900,\n",
       " 871,\n",
       " 965,\n",
       " 431,\n",
       " 711,\n",
       " 671,\n",
       " 566,\n",
       " 870,\n",
       " 715,\n",
       " 443,\n",
       " 557,\n",
       " 209,\n",
       " 562,\n",
       " 666,\n",
       " 375,\n",
       " 913,\n",
       " 340,\n",
       " 899,\n",
       " 755,\n",
       " 968,\n",
       " 315,\n",
       " 684,\n",
       " 162,\n",
       " 843,\n",
       " 980,\n",
       " 838,\n",
       " 294,\n",
       " 582,\n",
       " 493,\n",
       " 593,\n",
       " 883,\n",
       " 125,\n",
       " 770,\n",
       " 793,\n",
       " 525,\n",
       " 914,\n",
       " 151,\n",
       " 319,\n",
       " 390,\n",
       " 994,\n",
       " 266,\n",
       " 100,\n",
       " 467,\n",
       " 212,\n",
       " 177,\n",
       " 738,\n",
       " 929,\n",
       " 341,\n",
       " 233,\n",
       " 882,\n",
       " 31,\n",
       " 22,\n",
       " 145,\n",
       " 491,\n",
       " 747,\n",
       " 243,\n",
       " 615,\n",
       " 211,\n",
       " 451,\n",
       " 571,\n",
       " 769,\n",
       " 416,\n",
       " 692,\n",
       " 985,\n",
       " 239,\n",
       " 182,\n",
       " 854,\n",
       " 694,\n",
       " 972,\n",
       " 998,\n",
       " 561,\n",
       " 328,\n",
       " 374,\n",
       " 485,\n",
       " 10,\n",
       " 772,\n",
       " 283,\n",
       " 313,\n",
       " 775,\n",
       " 488,\n",
       " 297,\n",
       " 193,\n",
       " 506,\n",
       " 253,\n",
       " 311,\n",
       " 886,\n",
       " 783,\n",
       " 759,\n",
       " 539,\n",
       " 917,\n",
       " 959,\n",
       " 258,\n",
       " 322,\n",
       " 461,\n",
       " 323,\n",
       " 380,\n",
       " 809,\n",
       " 613,\n",
       " 881,\n",
       " 307,\n",
       " 548,\n",
       " 740,\n",
       " 554,\n",
       " 241,\n",
       " 702,\n",
       " 419,\n",
       " 441,\n",
       " 564,\n",
       " 798,\n",
       " 997,\n",
       " 544,\n",
       " 931,\n",
       " 542,\n",
       " 373,\n",
       " 503,\n",
       " 518,\n",
       " 962,\n",
       " 595,\n",
       " 703,\n",
       " 861,\n",
       " 24,\n",
       " 459,\n",
       " 746,\n",
       " 909,\n",
       " 183,\n",
       " 165,\n",
       " 697,\n",
       " 8,\n",
       " 895,\n",
       " 745,\n",
       " 949,\n",
       " 245,\n",
       " 398,\n",
       " 298,\n",
       " 15,\n",
       " 777,\n",
       " 911,\n",
       " 815,\n",
       " 816,\n",
       " 851,\n",
       " 255,\n",
       " 447,\n",
       " 334,\n",
       " 483,\n",
       " 105,\n",
       " 12,\n",
       " 993,\n",
       " 310,\n",
       " 104,\n",
       " 811,\n",
       " 516,\n",
       " 57,\n",
       " 317,\n",
       " 802,\n",
       " 351,\n",
       " 265,\n",
       " 62,\n",
       " 48,\n",
       " 72,\n",
       " 66,\n",
       " 864,\n",
       " 494,\n",
       " 331,\n",
       " 121,\n",
       " 343,\n",
       " 354,\n",
       " 630,\n",
       " 417,\n",
       " 573,\n",
       " 126,\n",
       " 829,\n",
       " 113,\n",
       " 709,\n",
       " 938,\n",
       " 273,\n",
       " 780,\n",
       " 271,\n",
       " 430,\n",
       " 434,\n",
       " 844,\n",
       " 336,\n",
       " 215,\n",
       " 541,\n",
       " 890,\n",
       " 462,\n",
       " 822,\n",
       " 957,\n",
       " 220,\n",
       " 161,\n",
       " 892,\n",
       " 576,\n",
       " 259,\n",
       " 517,\n",
       " 166,\n",
       " 686,\n",
       " 133,\n",
       " 556,\n",
       " 391,\n",
       " 304,\n",
       " 89,\n",
       " 108,\n",
       " 463,\n",
       " 131,\n",
       " 527,\n",
       " 320,\n",
       " 691,\n",
       " 565,\n",
       " 482,\n",
       " 988,\n",
       " 84,\n",
       " 6,\n",
       " 267,\n",
       " 642,\n",
       " 979,\n",
       " 604,\n",
       " 174,\n",
       " 832,\n",
       " 226,\n",
       " 260,\n",
       " 718,\n",
       " 685,\n",
       " 464,\n",
       " 173,\n",
       " 262,\n",
       " 805,\n",
       " 928,\n",
       " 316,\n",
       " 134,\n",
       " 499,\n",
       " 74,\n",
       " 970,\n",
       " 110,\n",
       " 751,\n",
       " 619,\n",
       " 742,\n",
       " 222,\n",
       " 91,\n",
       " 454,\n",
       " 501,\n",
       " 495,\n",
       " 327,\n",
       " 839,\n",
       " 377,\n",
       " 546,\n",
       " 608,\n",
       " 623,\n",
       " 371,\n",
       " 172,\n",
       " 818,\n",
       " 186,\n",
       " 36,\n",
       " 477,\n",
       " 934,\n",
       " 252,\n",
       " 723,\n",
       " 648,\n",
       " 305,\n",
       " 602,\n",
       " 794,\n",
       " 360,\n",
       " 41,\n",
       " 65,\n",
       " 728,\n",
       " 263,\n",
       " 833,\n",
       " 590,\n",
       " 874,\n",
       " 81,\n",
       " 763,\n",
       " 408,\n",
       " 677,\n",
       " 195,\n",
       " 803,\n",
       " 876,\n",
       " 474,\n",
       " 180,\n",
       " 418,\n",
       " 335,\n",
       " 654,\n",
       " 958,\n",
       " 0,\n",
       " 664,\n",
       " 69,\n",
       " 973,\n",
       " 632,\n",
       " 476,\n",
       " 486,\n",
       " 40,\n",
       " 238,\n",
       " 14,\n",
       " 160,\n",
       " 797,\n",
       " 75,\n",
       " 213,\n",
       " 942,\n",
       " 170,\n",
       " 329,\n",
       " 207,\n",
       " 189,\n",
       " 9,\n",
       " 1,\n",
       " 662,\n",
       " 978,\n",
       " 596,\n",
       " 727,\n",
       " 625,\n",
       " 362,\n",
       " 112,\n",
       " 175,\n",
       " 655,\n",
       " 164,\n",
       " 448,\n",
       " 44,\n",
       " 92,\n",
       " 163,\n",
       " 961,\n",
       " 368,\n",
       " 205,\n",
       " 20,\n",
       " 406,\n",
       " 32,\n",
       " 432,\n",
       " 943,\n",
       " 990,\n",
       " 504,\n",
       " 372,\n",
       " 230,\n",
       " 308,\n",
       " 567,\n",
       " 224,\n",
       " 237,\n",
       " 817,\n",
       " 45,\n",
       " 85,\n",
       " 227,\n",
       " 393,\n",
       " 923,\n",
       " 23,\n",
       " 526,\n",
       " 440,\n",
       " 559,\n",
       " 669,\n",
       " 199,\n",
       " 389,\n",
       " 324,\n",
       " 79,\n",
       " 330,\n",
       " 261,\n",
       " 394,\n",
       " 792,\n",
       " 251,\n",
       " 872,\n",
       " 446,\n",
       " 43,\n",
       " 889,\n",
       " 147,\n",
       " 455,\n",
       " 299,\n",
       " 756,\n",
       " 130,\n",
       " 784,\n",
       " 856,\n",
       " 752,\n",
       " 865,\n",
       " 146,\n",
       " 348,\n",
       " 198,\n",
       " 975,\n",
       " 306,\n",
       " 150,\n",
       " 635,\n",
       " 388,\n",
       " 719,\n",
       " 919,\n",
       " 855,\n",
       " 609,\n",
       " 560,\n",
       " 249,\n",
       " 184,\n",
       " 910,\n",
       " 487,\n",
       " 383,\n",
       " 629,\n",
       " 468,\n",
       " 587,\n",
       " 891,\n",
       " 887,\n",
       " 877,\n",
       " 218,\n",
       " 601,\n",
       " 618,\n",
       " 710,\n",
       " 64,\n",
       " 93,\n",
       " 497,\n",
       " 50,\n",
       " 515,\n",
       " 158,\n",
       " 478,\n",
       " 291,\n",
       " 405,\n",
       " 425,\n",
       " 902,\n",
       " 584,\n",
       " 983,\n",
       " 309,\n",
       " 690,\n",
       " 964,\n",
       " 696,\n",
       " 791,\n",
       " 781,\n",
       " 302,\n",
       " 471,\n",
       " 605,\n",
       " 879,\n",
       " 139,\n",
       " 749,\n",
       " 863,\n",
       " 612,\n",
       " 936,\n",
       " 761,\n",
       " 535,\n",
       " 868,\n",
       " 94,\n",
       " 465,\n",
       " 256,\n",
       " 824,\n",
       " 925,\n",
       " 806,\n",
       " 437,\n",
       " 875,\n",
       " 922,\n",
       " 643,\n",
       " 438,\n",
       " 153,\n",
       " 633,\n",
       " 611,\n",
       " 132,\n",
       " 225,\n",
       " 235,\n",
       " 771,\n",
       " 399,\n",
       " 862,\n",
       " 955,\n",
       " 880,\n",
       " 558,\n",
       " 21,\n",
       " 428,\n",
       " 735,\n",
       " 760,\n",
       " 149,\n",
       " 433,\n",
       " 927,\n",
       " 141,\n",
       " 577,\n",
       " 300,\n",
       " 58,\n",
       " 788,\n",
       " 750,\n",
       " 592,\n",
       " 286,\n",
       " 743,\n",
       " 641,\n",
       " 674,\n",
       " 276,\n",
       " 628,\n",
       " 528,\n",
       " 744,\n",
       " 903,\n",
       " 202,\n",
       " 935,\n",
       " 776,\n",
       " 695,\n",
       " 420,\n",
       " 849,\n",
       " 621,\n",
       " 508,\n",
       " 569,\n",
       " 290,\n",
       " 638,\n",
       " 937,\n",
       " 296,\n",
       " 429,\n",
       " 76,\n",
       " 704,\n",
       " 232,\n",
       " 529,\n",
       " 402,\n",
       " 98,\n",
       " 5,\n",
       " 924,\n",
       " 248,\n",
       " 570,\n",
       " 475,\n",
       " 858,\n",
       " 850,\n",
       " 848,\n",
       " 284,\n",
       " 649,\n",
       " 301,\n",
       " 410,\n",
       " 61,\n",
       " 915,\n",
       " 144,\n",
       " 103,\n",
       " 95,\n",
       " 4,\n",
       " 873,\n",
       " 384,\n",
       " 114,\n",
       " 963,\n",
       " 810,\n",
       " 639,\n",
       " 240,\n",
       " 912,\n",
       " 680,\n",
       " 281,\n",
       " 325,\n",
       " 442,\n",
       " 807,\n",
       " 774,\n",
       " 159,\n",
       " 514,\n",
       " 733,\n",
       " 370,\n",
       " 450,\n",
       " 821,\n",
       " 458,\n",
       " 916,\n",
       " 35,\n",
       " 350,\n",
       " 60,\n",
       " 367,\n",
       " 660,\n",
       " 326,\n",
       " 90,\n",
       " 580,\n",
       " 599,\n",
       " 179,\n",
       " 426,\n",
       " 449,\n",
       " 732,\n",
       " 379,\n",
       " 378,\n",
       " 991,\n",
       " 246,\n",
       " 714,\n",
       " 701,\n",
       " 18,\n",
       " 651,\n",
       " 80,\n",
       " 411,\n",
       " 143,\n",
       " 688,\n",
       " 682,\n",
       " 492,\n",
       " 34,\n",
       " 656,\n",
       " 905,\n",
       " 353,\n",
       " 953,\n",
       " 614,\n",
       " 407,\n",
       " 395,\n",
       " 83,\n",
       " 33,\n",
       " 115,\n",
       " 574,\n",
       " 231,\n",
       " 257,\n",
       " 537,\n",
       " 59,\n",
       " 157,\n",
       " 169,\n",
       " 616,\n",
       " 347,\n",
       " 288,\n",
       " 210,\n",
       " 956,\n",
       " 888,\n",
       " 646,\n",
       " 918,\n",
       " 667,\n",
       " 721,\n",
       " 647,\n",
       " 939,\n",
       " 707,\n",
       " 634,\n",
       " 896,\n",
       " 285,\n",
       " 181,\n",
       " 547,\n",
       " 626,\n",
       " 700,\n",
       " 52,\n",
       " 337,\n",
       " 699,\n",
       " 148,\n",
       " 38,\n",
       " 357,\n",
       " 234,\n",
       " 70,\n",
       " 117,\n",
       " 509,\n",
       " 945,\n",
       " 201,\n",
       " 893,\n",
       " 219,\n",
       " 767,\n",
       " 987,\n",
       " 800,\n",
       " 345,\n",
       " 208,\n",
       " 26,\n",
       " 530,\n",
       " 342,\n",
       " 397,\n",
       " 828,\n",
       " 200,\n",
       " 540,\n",
       " 736,\n",
       " 489,\n",
       " 445,\n",
       " 396,\n",
       " 693,\n",
       " 773,\n",
       " 971,\n",
       " 39,\n",
       " 381,\n",
       " 708,\n",
       " 600,\n",
       " 555,\n",
       " 524,\n",
       " 274,\n",
       " 51,\n",
       " 579,\n",
       " 365,\n",
       " 866,\n",
       " 523,\n",
       " 55,\n",
       " 921,\n",
       " 729,\n",
       " 116,\n",
       " 898,\n",
       " 473,\n",
       " 481,\n",
       " 847,\n",
       " 364,\n",
       " 197,\n",
       " 96,\n",
       " 268,\n",
       " 933,\n",
       " 878,\n",
       " 764,\n",
       " 228,\n",
       " 152,\n",
       " 904,\n",
       " 617,\n",
       " 678,\n",
       " 779,\n",
       " 167,\n",
       " 196]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.indices            # 返回训练集索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1406,  0.4082],\n",
       "         [ 0.4877,  0.8226],\n",
       "         [-0.2876,  0.8771],\n",
       "         ...,\n",
       "         [ 2.0659,  0.6420],\n",
       "         [-0.5856,  1.1246],\n",
       "         [-0.3630, -1.5988]]),\n",
       " tensor([[ 2.8812e+00],\n",
       "         [ 1.1609e+00],\n",
       "         [-4.6634e-01],\n",
       "         [ 3.9260e-01],\n",
       "         [ 4.7393e+00],\n",
       "         [ 2.6925e-01],\n",
       "         [-4.2701e+00],\n",
       "         [-1.9663e+00],\n",
       "         [ 2.6911e+00],\n",
       "         [-5.3875e-01],\n",
       "         [ 4.0773e+00],\n",
       "         [ 2.5222e+00],\n",
       "         [ 2.1537e+00],\n",
       "         [-1.2974e+00],\n",
       "         [ 1.8957e+00],\n",
       "         [ 2.6746e+00],\n",
       "         [ 1.7926e+00],\n",
       "         [-6.7267e-01],\n",
       "         [-2.1375e+00],\n",
       "         [ 8.8927e-01],\n",
       "         [ 1.2660e+00],\n",
       "         [ 1.8146e+00],\n",
       "         [-1.0775e+00],\n",
       "         [ 1.6035e+00],\n",
       "         [-5.1649e-01],\n",
       "         [ 3.4154e+00],\n",
       "         [-7.7674e-01],\n",
       "         [-6.4668e-01],\n",
       "         [ 3.2620e+00],\n",
       "         [ 2.2912e+00],\n",
       "         [ 4.4171e-01],\n",
       "         [ 6.5147e-01],\n",
       "         [ 1.9962e+00],\n",
       "         [ 5.4784e-01],\n",
       "         [ 3.1184e-01],\n",
       "         [ 3.0202e+00],\n",
       "         [-1.2727e+00],\n",
       "         [ 1.1093e+00],\n",
       "         [ 1.8856e+00],\n",
       "         [ 1.0211e-01],\n",
       "         [ 8.6597e-01],\n",
       "         [ 4.2614e+00],\n",
       "         [ 9.9786e-01],\n",
       "         [ 1.0371e+00],\n",
       "         [-1.2659e+00],\n",
       "         [ 3.6334e-01],\n",
       "         [-8.7369e-01],\n",
       "         [-1.0023e+00],\n",
       "         [ 1.5986e-02],\n",
       "         [-1.3549e+00],\n",
       "         [ 1.9519e+00],\n",
       "         [-1.6662e+00],\n",
       "         [ 2.0054e+00],\n",
       "         [ 4.6805e-01],\n",
       "         [-5.3769e-01],\n",
       "         [-6.7986e-01],\n",
       "         [-1.5948e+00],\n",
       "         [ 9.0539e-01],\n",
       "         [ 7.2145e-01],\n",
       "         [ 1.1697e+00],\n",
       "         [ 6.9970e-01],\n",
       "         [ 3.5498e+00],\n",
       "         [ 1.1663e+00],\n",
       "         [-1.8741e+00],\n",
       "         [-1.9461e+00],\n",
       "         [-2.3179e+00],\n",
       "         [ 2.4091e+00],\n",
       "         [ 2.3969e+00],\n",
       "         [ 1.0725e+00],\n",
       "         [ 4.0926e+00],\n",
       "         [ 1.6870e+00],\n",
       "         [ 4.8257e-01],\n",
       "         [-2.2518e+00],\n",
       "         [-1.9020e+00],\n",
       "         [-2.4596e+00],\n",
       "         [ 7.2653e-01],\n",
       "         [ 3.7745e+00],\n",
       "         [ 3.0499e+00],\n",
       "         [ 9.4167e-01],\n",
       "         [-9.6889e-01],\n",
       "         [ 1.2682e+00],\n",
       "         [-1.1168e+00],\n",
       "         [-8.1794e-01],\n",
       "         [ 1.3749e+00],\n",
       "         [-2.1108e+00],\n",
       "         [-2.7961e-01],\n",
       "         [ 1.6736e-01],\n",
       "         [-3.6319e-01],\n",
       "         [ 3.9396e-01],\n",
       "         [ 7.2161e-01],\n",
       "         [ 3.9930e+00],\n",
       "         [-2.9213e+00],\n",
       "         [ 3.1556e+00],\n",
       "         [ 5.0794e+00],\n",
       "         [-5.0843e-01],\n",
       "         [ 1.1573e+00],\n",
       "         [ 1.6025e+00],\n",
       "         [ 1.8177e+00],\n",
       "         [-1.9363e+00],\n",
       "         [ 6.7235e+00],\n",
       "         [-1.8232e+00],\n",
       "         [ 3.7301e+00],\n",
       "         [ 1.6565e+00],\n",
       "         [ 7.5910e-01],\n",
       "         [ 2.6710e+00],\n",
       "         [ 5.2914e-02],\n",
       "         [-6.5961e-01],\n",
       "         [-1.5193e+00],\n",
       "         [ 3.0065e+00],\n",
       "         [ 1.8763e+00],\n",
       "         [ 1.5046e+00],\n",
       "         [-4.4880e+00],\n",
       "         [ 1.5893e+00],\n",
       "         [ 2.2169e+00],\n",
       "         [ 1.9006e+00],\n",
       "         [ 2.6320e+00],\n",
       "         [ 3.6664e+00],\n",
       "         [ 1.1241e+00],\n",
       "         [-5.0390e-01],\n",
       "         [-1.0509e+00],\n",
       "         [-1.7353e+00],\n",
       "         [-3.7892e+00],\n",
       "         [ 1.4047e+00],\n",
       "         [-1.3924e+00],\n",
       "         [-1.0089e+00],\n",
       "         [-1.8363e+00],\n",
       "         [ 3.5170e+00],\n",
       "         [ 2.4134e+00],\n",
       "         [ 1.9116e+00],\n",
       "         [-1.5671e+00],\n",
       "         [ 2.3054e+00],\n",
       "         [ 9.4353e-01],\n",
       "         [ 7.9625e-01],\n",
       "         [-2.0284e+00],\n",
       "         [-2.2669e+00],\n",
       "         [ 1.6339e+00],\n",
       "         [ 5.4358e+00],\n",
       "         [-3.4310e+00],\n",
       "         [ 8.8180e-01],\n",
       "         [ 2.9254e+00],\n",
       "         [ 1.1914e+00],\n",
       "         [ 1.6843e+00],\n",
       "         [ 6.9422e-01],\n",
       "         [ 7.6011e-01],\n",
       "         [ 1.5915e+00],\n",
       "         [-2.1392e-01],\n",
       "         [ 1.8210e+00],\n",
       "         [ 2.5617e+00],\n",
       "         [-1.7324e+00],\n",
       "         [-1.5756e+00],\n",
       "         [ 1.7446e+00],\n",
       "         [-8.8207e-01],\n",
       "         [ 1.8601e+00],\n",
       "         [ 5.9185e-01],\n",
       "         [ 8.6421e-01],\n",
       "         [ 1.5572e+00],\n",
       "         [ 1.3899e+00],\n",
       "         [-2.2861e-01],\n",
       "         [ 3.1501e-01],\n",
       "         [-6.5917e-01],\n",
       "         [ 7.7462e+00],\n",
       "         [ 2.4150e+00],\n",
       "         [ 3.2429e+00],\n",
       "         [-3.9511e+00],\n",
       "         [ 3.0025e+00],\n",
       "         [ 9.1575e-01],\n",
       "         [-1.0379e+00],\n",
       "         [ 8.3197e-02],\n",
       "         [-3.8346e+00],\n",
       "         [ 1.6517e+00],\n",
       "         [-1.1470e-02],\n",
       "         [-7.2693e-01],\n",
       "         [-2.0237e-01],\n",
       "         [ 1.5242e+00],\n",
       "         [ 1.6763e+00],\n",
       "         [ 2.0960e-01],\n",
       "         [ 2.2128e+00],\n",
       "         [-6.6217e-01],\n",
       "         [-1.5868e+00],\n",
       "         [-4.1893e-01],\n",
       "         [-1.9273e-01],\n",
       "         [ 1.2493e-01],\n",
       "         [ 1.9892e+00],\n",
       "         [-2.8340e+00],\n",
       "         [ 5.0387e+00],\n",
       "         [ 9.3458e-01],\n",
       "         [ 1.0441e+00],\n",
       "         [-2.1085e+00],\n",
       "         [ 1.9241e+00],\n",
       "         [ 1.5465e+00],\n",
       "         [ 2.1352e+00],\n",
       "         [ 2.5638e+00],\n",
       "         [-3.4032e-01],\n",
       "         [ 1.7347e+00],\n",
       "         [-7.0543e-01],\n",
       "         [ 5.0325e-01],\n",
       "         [ 3.9877e-01],\n",
       "         [ 6.6824e-01],\n",
       "         [-1.3222e+00],\n",
       "         [ 2.2578e+00],\n",
       "         [ 1.7206e+00],\n",
       "         [ 1.3991e+00],\n",
       "         [-4.7353e-03],\n",
       "         [ 2.2193e-01],\n",
       "         [ 6.8328e+00],\n",
       "         [ 3.6342e-01],\n",
       "         [ 2.9250e+00],\n",
       "         [ 4.4150e+00],\n",
       "         [-2.7199e+00],\n",
       "         [-9.7183e-01],\n",
       "         [-1.7742e+00],\n",
       "         [ 2.4054e+00],\n",
       "         [-1.0970e+00],\n",
       "         [ 5.1721e-01],\n",
       "         [ 1.4744e+00],\n",
       "         [-4.7041e+00],\n",
       "         [ 1.0712e+00],\n",
       "         [ 3.3911e-01],\n",
       "         [ 3.3633e-01],\n",
       "         [ 8.6733e-01],\n",
       "         [ 1.7156e+00],\n",
       "         [ 2.0910e+00],\n",
       "         [ 2.6042e+00],\n",
       "         [ 6.4937e+00],\n",
       "         [ 2.7733e+00],\n",
       "         [ 3.2009e+00],\n",
       "         [-7.2861e-03],\n",
       "         [ 2.5124e+00],\n",
       "         [ 3.2364e+00],\n",
       "         [ 2.4116e+00],\n",
       "         [ 2.4616e+00],\n",
       "         [-7.1981e-01],\n",
       "         [-1.5344e-01],\n",
       "         [ 1.1304e+00],\n",
       "         [-1.6337e+00],\n",
       "         [-5.3888e-01],\n",
       "         [ 5.0198e-01],\n",
       "         [ 5.3441e+00],\n",
       "         [ 3.6559e+00],\n",
       "         [-2.3262e+00],\n",
       "         [ 2.4050e+00],\n",
       "         [ 2.1535e+00],\n",
       "         [ 1.5110e+00],\n",
       "         [ 6.2725e-01],\n",
       "         [ 8.7893e-01],\n",
       "         [-7.7816e-01],\n",
       "         [ 2.0621e+00],\n",
       "         [ 1.4903e+00],\n",
       "         [ 1.5134e+00],\n",
       "         [-1.4305e+00],\n",
       "         [ 4.9970e+00],\n",
       "         [-1.5162e+00],\n",
       "         [ 2.7393e-01],\n",
       "         [-7.0505e-01],\n",
       "         [ 8.5859e-01],\n",
       "         [ 1.8072e+00],\n",
       "         [ 1.7213e+00],\n",
       "         [ 4.8430e-01],\n",
       "         [ 1.7927e+00],\n",
       "         [ 4.3898e-01],\n",
       "         [ 6.0313e-01],\n",
       "         [ 1.1917e+00],\n",
       "         [ 2.8748e+00],\n",
       "         [-1.2606e+00],\n",
       "         [ 2.3412e-01],\n",
       "         [-1.9060e-01],\n",
       "         [-1.0246e-01],\n",
       "         [-1.6219e-01],\n",
       "         [ 1.4035e+00],\n",
       "         [ 1.4291e-01],\n",
       "         [ 1.4266e+00],\n",
       "         [-1.7263e+00],\n",
       "         [ 1.7153e+00],\n",
       "         [ 1.3111e-01],\n",
       "         [ 1.0459e+00],\n",
       "         [ 3.3548e+00],\n",
       "         [ 2.4855e+00],\n",
       "         [-3.1327e+00],\n",
       "         [ 3.6441e+00],\n",
       "         [ 1.4062e+00],\n",
       "         [ 4.6328e+00],\n",
       "         [-1.0452e-01],\n",
       "         [ 3.8414e+00],\n",
       "         [ 1.9191e+00],\n",
       "         [ 2.9306e+00],\n",
       "         [-2.3284e-02],\n",
       "         [ 1.7792e+00],\n",
       "         [-3.0911e+00],\n",
       "         [ 2.5471e+00],\n",
       "         [-8.1198e-01],\n",
       "         [ 4.1466e+00],\n",
       "         [ 5.0209e-01],\n",
       "         [ 2.8746e-01],\n",
       "         [ 2.1810e-02],\n",
       "         [-1.6500e-01],\n",
       "         [ 8.5011e-01],\n",
       "         [ 1.1998e+00],\n",
       "         [-8.0647e-01],\n",
       "         [ 4.4509e+00],\n",
       "         [ 3.7880e+00],\n",
       "         [-1.6916e+00],\n",
       "         [-2.2862e-01],\n",
       "         [-2.9675e+00],\n",
       "         [ 1.0287e+00],\n",
       "         [ 3.4187e+00],\n",
       "         [ 1.4590e+00],\n",
       "         [ 3.0892e+00],\n",
       "         [-6.4252e+00],\n",
       "         [ 1.4399e-01],\n",
       "         [-9.9272e-01],\n",
       "         [ 8.1486e-01],\n",
       "         [ 5.7064e-01],\n",
       "         [-2.3356e+00],\n",
       "         [ 7.3488e-01],\n",
       "         [ 6.8702e-01],\n",
       "         [-1.7097e+00],\n",
       "         [ 1.8302e-01],\n",
       "         [-3.7694e+00],\n",
       "         [ 4.3121e+00],\n",
       "         [ 1.7848e-01],\n",
       "         [ 4.4569e+00],\n",
       "         [ 4.9279e+00],\n",
       "         [ 1.3840e+00],\n",
       "         [ 8.8273e+00],\n",
       "         [-4.0626e-01],\n",
       "         [ 1.9906e+00],\n",
       "         [ 4.8008e+00],\n",
       "         [-1.4304e+00],\n",
       "         [ 1.3222e+00],\n",
       "         [-6.9922e-01],\n",
       "         [-1.2052e+00],\n",
       "         [ 1.2263e+00],\n",
       "         [ 5.9381e-01],\n",
       "         [-2.4329e+00],\n",
       "         [ 3.0559e+00],\n",
       "         [ 8.6617e-01],\n",
       "         [ 2.3126e+00],\n",
       "         [-7.0499e-01],\n",
       "         [ 1.7381e+00],\n",
       "         [ 8.4304e-01],\n",
       "         [-3.3730e-01],\n",
       "         [ 9.8062e-01],\n",
       "         [ 2.6653e+00],\n",
       "         [ 4.2049e-01],\n",
       "         [ 3.6699e-01],\n",
       "         [ 1.7122e+00],\n",
       "         [-1.0377e+00],\n",
       "         [ 9.4221e-01],\n",
       "         [ 1.2267e+00],\n",
       "         [ 1.1585e+00],\n",
       "         [ 3.8168e+00],\n",
       "         [ 1.2131e+00],\n",
       "         [ 9.7469e-01],\n",
       "         [ 1.7427e+00],\n",
       "         [-3.5092e+00],\n",
       "         [ 1.0112e-01],\n",
       "         [-8.3342e-01],\n",
       "         [ 2.1208e+00],\n",
       "         [ 3.1181e+00],\n",
       "         [ 6.2922e-01],\n",
       "         [ 2.3116e+00],\n",
       "         [ 1.6713e+00],\n",
       "         [ 3.3519e+00],\n",
       "         [-3.6793e-01],\n",
       "         [ 5.2140e-02],\n",
       "         [ 1.5490e+00],\n",
       "         [ 8.5172e-01],\n",
       "         [ 5.4244e-01],\n",
       "         [ 2.4221e+00],\n",
       "         [ 2.8105e+00],\n",
       "         [ 2.8092e+00],\n",
       "         [ 4.8094e+00],\n",
       "         [ 2.7504e+00],\n",
       "         [ 2.2587e+00],\n",
       "         [-1.3794e+00],\n",
       "         [ 6.0516e-01],\n",
       "         [-4.3870e-01],\n",
       "         [ 3.6041e+00],\n",
       "         [ 5.5866e-01],\n",
       "         [ 1.1932e+00],\n",
       "         [-1.1096e+00],\n",
       "         [ 2.3971e+00],\n",
       "         [ 3.9652e+00],\n",
       "         [-1.8367e+00],\n",
       "         [ 1.5493e+00],\n",
       "         [-2.3143e+00],\n",
       "         [ 4.4697e+00],\n",
       "         [ 2.6971e+00],\n",
       "         [ 3.4626e+00],\n",
       "         [ 3.1198e-01],\n",
       "         [-7.9596e-01],\n",
       "         [-1.6286e+00],\n",
       "         [ 1.8111e-01],\n",
       "         [ 3.9815e+00],\n",
       "         [ 1.6974e+00],\n",
       "         [ 1.8691e+00],\n",
       "         [ 5.6497e+00],\n",
       "         [ 2.1229e+00],\n",
       "         [ 3.8641e-01],\n",
       "         [-2.6739e+00],\n",
       "         [-1.0586e+00],\n",
       "         [-2.9422e+00],\n",
       "         [ 1.6760e+00],\n",
       "         [ 7.9146e-01],\n",
       "         [ 1.2535e+00],\n",
       "         [-7.1586e-01],\n",
       "         [-6.4118e-01],\n",
       "         [ 1.8644e+00],\n",
       "         [ 1.3843e+00],\n",
       "         [ 1.1834e+00],\n",
       "         [ 2.8757e+00],\n",
       "         [ 2.1061e+00],\n",
       "         [ 2.2526e+00],\n",
       "         [-1.6306e+00],\n",
       "         [-6.6711e-02],\n",
       "         [-1.8330e+00],\n",
       "         [-1.8786e+00],\n",
       "         [ 5.6773e+00],\n",
       "         [ 2.3563e+00],\n",
       "         [ 2.8694e+00],\n",
       "         [ 2.6306e+00],\n",
       "         [ 2.4647e-01],\n",
       "         [-1.2108e+00],\n",
       "         [ 7.8008e-01],\n",
       "         [-1.3647e+00],\n",
       "         [ 2.5586e-01],\n",
       "         [ 1.1255e+00],\n",
       "         [-5.8606e+00],\n",
       "         [ 2.2118e+00],\n",
       "         [-2.0753e+00],\n",
       "         [ 3.3161e+00],\n",
       "         [ 1.9381e+00],\n",
       "         [-8.0656e-01],\n",
       "         [-7.0011e-01],\n",
       "         [ 3.4721e+00],\n",
       "         [-2.7948e-02],\n",
       "         [-3.7616e-01],\n",
       "         [-8.5114e-02],\n",
       "         [ 1.4098e+00],\n",
       "         [-4.9764e-01],\n",
       "         [ 3.2643e-01],\n",
       "         [ 4.7711e-01],\n",
       "         [ 7.1761e-01],\n",
       "         [-1.7911e-01],\n",
       "         [-5.4960e-01],\n",
       "         [ 8.1802e-01],\n",
       "         [-1.3661e+00],\n",
       "         [-3.8532e-01],\n",
       "         [ 1.1940e+00],\n",
       "         [-2.0732e+00],\n",
       "         [ 8.1742e-01],\n",
       "         [ 1.6445e+00],\n",
       "         [ 1.7321e+00],\n",
       "         [ 3.5990e-01],\n",
       "         [ 2.6915e+00],\n",
       "         [ 4.1157e+00],\n",
       "         [ 2.1573e-01],\n",
       "         [ 1.2171e+00],\n",
       "         [ 3.0525e+00],\n",
       "         [ 3.6246e+00],\n",
       "         [ 2.0945e+00],\n",
       "         [ 4.3091e+00],\n",
       "         [ 1.9449e+00],\n",
       "         [-1.0504e+00],\n",
       "         [ 1.1519e+00],\n",
       "         [ 1.5105e-01],\n",
       "         [ 2.1919e+00],\n",
       "         [ 3.7626e+00],\n",
       "         [-6.1425e-01],\n",
       "         [-1.3267e+00],\n",
       "         [-1.4108e+00],\n",
       "         [ 2.0669e+00],\n",
       "         [ 2.3629e+00],\n",
       "         [ 8.6040e-01],\n",
       "         [ 2.7600e+00],\n",
       "         [-1.0458e+00],\n",
       "         [ 7.3044e-01],\n",
       "         [ 9.0013e-01],\n",
       "         [ 1.8577e+00],\n",
       "         [ 9.8150e-01],\n",
       "         [ 3.1693e+00],\n",
       "         [ 1.9512e+00],\n",
       "         [-3.1256e+00],\n",
       "         [ 1.5968e+00],\n",
       "         [ 3.6419e+00],\n",
       "         [ 5.3889e-01],\n",
       "         [ 2.4483e+00],\n",
       "         [ 1.1025e+00],\n",
       "         [ 2.3732e-01],\n",
       "         [-1.1776e+00],\n",
       "         [-9.9125e-02],\n",
       "         [-6.9393e-01],\n",
       "         [ 1.3601e+00],\n",
       "         [ 6.9394e-01],\n",
       "         [ 2.8519e+00],\n",
       "         [ 2.1246e+00],\n",
       "         [ 1.6196e+00],\n",
       "         [ 1.4330e+00],\n",
       "         [ 1.3193e+00],\n",
       "         [ 1.0180e+00],\n",
       "         [ 1.7028e+00],\n",
       "         [ 2.2425e+00],\n",
       "         [ 1.9775e+00],\n",
       "         [ 3.4202e-01],\n",
       "         [ 3.1959e-01],\n",
       "         [ 5.8470e-01],\n",
       "         [ 4.9745e-01],\n",
       "         [ 1.5406e+00],\n",
       "         [ 2.0881e+00],\n",
       "         [ 1.7777e+00],\n",
       "         [ 2.7809e-01],\n",
       "         [ 2.5457e-01],\n",
       "         [ 5.5151e+00],\n",
       "         [-2.6595e+00],\n",
       "         [ 3.4421e+00],\n",
       "         [-1.2036e+00],\n",
       "         [ 2.8380e+00],\n",
       "         [ 9.9821e-01],\n",
       "         [-1.7089e+00],\n",
       "         [ 3.0332e-01],\n",
       "         [ 6.0842e+00],\n",
       "         [ 7.6670e-02],\n",
       "         [-8.9843e-01],\n",
       "         [-3.2732e-01],\n",
       "         [ 8.2155e-01],\n",
       "         [ 1.1359e+00],\n",
       "         [-3.2338e+00],\n",
       "         [-7.2428e-01],\n",
       "         [-2.4657e+00],\n",
       "         [-3.4385e-01],\n",
       "         [-1.1620e-01],\n",
       "         [ 3.3654e+00],\n",
       "         [-8.8312e-01],\n",
       "         [ 3.4709e+00],\n",
       "         [ 2.4754e+00],\n",
       "         [-1.3757e-01],\n",
       "         [ 3.5336e+00],\n",
       "         [ 4.0680e+00],\n",
       "         [-2.1942e-01],\n",
       "         [ 3.7389e-01],\n",
       "         [ 1.9757e+00],\n",
       "         [ 2.4640e+00],\n",
       "         [-2.5294e-01],\n",
       "         [ 5.7579e+00],\n",
       "         [ 2.0381e+00],\n",
       "         [-2.4351e-01],\n",
       "         [ 7.4645e-01],\n",
       "         [-6.7729e-02],\n",
       "         [-2.5904e+00],\n",
       "         [-6.3067e-01],\n",
       "         [ 7.6736e-01],\n",
       "         [ 6.4015e-01],\n",
       "         [ 3.4789e+00],\n",
       "         [ 4.4446e-01],\n",
       "         [ 1.3295e+00],\n",
       "         [ 3.1151e+00],\n",
       "         [-8.2307e-01],\n",
       "         [ 2.3157e+00],\n",
       "         [ 1.0396e+00],\n",
       "         [ 3.4755e-02],\n",
       "         [-1.1917e+00],\n",
       "         [ 1.2043e+00],\n",
       "         [ 5.0748e-01],\n",
       "         [-7.6323e-01],\n",
       "         [-2.5000e+00],\n",
       "         [-7.3352e-01],\n",
       "         [-7.5109e-02],\n",
       "         [ 5.2873e+00],\n",
       "         [-2.1330e+00],\n",
       "         [ 5.2128e+00],\n",
       "         [ 3.3031e+00],\n",
       "         [ 2.3763e+00],\n",
       "         [ 6.3032e-01],\n",
       "         [ 1.6697e+00],\n",
       "         [ 1.1276e+00],\n",
       "         [ 3.0890e+00],\n",
       "         [-2.1990e-01],\n",
       "         [-3.5529e-01],\n",
       "         [ 6.9230e+00],\n",
       "         [-1.7440e-01],\n",
       "         [ 1.6419e-01],\n",
       "         [-5.9452e-01],\n",
       "         [ 1.3258e+00],\n",
       "         [ 3.1884e+00],\n",
       "         [-1.9177e+00],\n",
       "         [ 5.2811e-01],\n",
       "         [-3.7733e+00],\n",
       "         [ 1.3235e-01],\n",
       "         [ 2.5048e+00],\n",
       "         [ 9.3611e-01],\n",
       "         [-1.0844e-01],\n",
       "         [-2.8358e-01],\n",
       "         [ 2.0780e+00],\n",
       "         [-3.2098e+00],\n",
       "         [ 3.6948e-01],\n",
       "         [ 4.3149e+00],\n",
       "         [ 3.7624e+00],\n",
       "         [-1.5608e+00],\n",
       "         [ 3.0340e+00],\n",
       "         [ 1.0062e+00],\n",
       "         [ 4.3690e-01],\n",
       "         [ 9.8176e-01],\n",
       "         [-3.8987e+00],\n",
       "         [ 1.2651e+00],\n",
       "         [ 3.7858e+00],\n",
       "         [ 5.3320e+00],\n",
       "         [ 2.1431e+00],\n",
       "         [ 1.5674e+00],\n",
       "         [ 2.6858e+00],\n",
       "         [ 7.4243e-01],\n",
       "         [ 3.1524e-02],\n",
       "         [ 3.5721e+00],\n",
       "         [-5.1033e-01],\n",
       "         [-2.4287e+00],\n",
       "         [ 3.4506e+00],\n",
       "         [ 1.8878e+00],\n",
       "         [ 1.3710e+00],\n",
       "         [-4.6554e-01],\n",
       "         [-2.3554e+00],\n",
       "         [ 2.1324e+00],\n",
       "         [ 1.9508e+00],\n",
       "         [ 7.8553e-01],\n",
       "         [ 1.4376e+00],\n",
       "         [ 1.0357e+00],\n",
       "         [ 9.6303e-01],\n",
       "         [ 1.3384e+00],\n",
       "         [-4.2400e-02],\n",
       "         [-7.7679e-01],\n",
       "         [-2.9461e-01],\n",
       "         [ 1.5138e-01],\n",
       "         [ 2.0517e+00],\n",
       "         [-6.3118e-01],\n",
       "         [ 3.6934e+00],\n",
       "         [ 4.2278e+00],\n",
       "         [-4.4525e+00],\n",
       "         [ 2.6555e+00],\n",
       "         [-2.7845e+00],\n",
       "         [ 7.4210e-01],\n",
       "         [-3.8734e-01],\n",
       "         [ 1.0941e+00],\n",
       "         [ 1.9473e-01],\n",
       "         [ 7.3534e-01],\n",
       "         [ 7.5435e-01],\n",
       "         [ 3.3519e+00],\n",
       "         [ 3.7540e+00],\n",
       "         [-3.8653e+00],\n",
       "         [ 4.9497e-01],\n",
       "         [ 1.6451e+00],\n",
       "         [ 4.0058e-01],\n",
       "         [ 2.7319e+00],\n",
       "         [ 5.3213e-01],\n",
       "         [-1.1226e+00],\n",
       "         [ 4.9793e+00],\n",
       "         [ 1.9196e+00],\n",
       "         [ 1.1049e+00],\n",
       "         [ 3.7343e+00],\n",
       "         [-3.4255e-02],\n",
       "         [ 1.0023e+00],\n",
       "         [ 3.2404e+00],\n",
       "         [ 1.5048e+00],\n",
       "         [ 8.3414e-02],\n",
       "         [ 1.4170e+00],\n",
       "         [ 1.6027e+00],\n",
       "         [-9.7046e-01],\n",
       "         [-2.4794e+00],\n",
       "         [ 3.1452e+00],\n",
       "         [ 2.1243e+00],\n",
       "         [ 2.7101e+00],\n",
       "         [-3.7910e-01],\n",
       "         [-3.6719e+00],\n",
       "         [ 2.8805e+00],\n",
       "         [ 1.6280e+00],\n",
       "         [ 1.8819e+00],\n",
       "         [-1.9105e+00],\n",
       "         [ 5.8462e-01],\n",
       "         [ 2.4405e+00],\n",
       "         [ 1.2012e+00],\n",
       "         [-1.3603e-01],\n",
       "         [ 6.2762e-01],\n",
       "         [ 6.6931e-01],\n",
       "         [-2.2384e+00],\n",
       "         [ 3.5429e+00],\n",
       "         [ 6.2927e+00],\n",
       "         [ 5.5378e+00],\n",
       "         [ 1.4511e+00],\n",
       "         [ 1.1424e+00],\n",
       "         [-2.9273e-01],\n",
       "         [-4.1892e-01],\n",
       "         [-4.7119e-01],\n",
       "         [ 4.6752e-01],\n",
       "         [-1.5359e-01],\n",
       "         [ 3.4638e+00],\n",
       "         [ 1.1328e+00],\n",
       "         [-3.0685e-01],\n",
       "         [-1.4199e+00],\n",
       "         [-5.5854e-01],\n",
       "         [-1.0613e+00],\n",
       "         [ 4.4854e+00],\n",
       "         [-1.2929e+00],\n",
       "         [ 1.8795e+00]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices]      # 返回训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1406,  0.4082],\n",
       "        [ 0.4877,  0.8226],\n",
       "        [-0.2876,  0.8771],\n",
       "        ...,\n",
       "        [ 2.0659,  0.6420],\n",
       "        [-0.5856,  1.1246],\n",
       "        [-0.3630, -1.5988]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices][0]      # 返回训练集的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4741e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算训练集MSE\n",
    "F.mse_loss(LR_model(data[data_train.indices][0]), data[data_train.indices][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算测试集MSE\n",
    "F.mse_loss(LR_model(data[data_test.indices][0]), data[data_test.indices][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，即完成了整个从数据集切分到模型训练，再到查看模型在不同数据集上表现的全过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、实用函数补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;结合上述过程，我们可以补充一些实用函数，方便简化后续建模流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据封装、切分和加载函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;该函数可以直接将输入的特征和标签直接进行封装、切分和加载。该函数可以直接处理此前定义的数据生成器创建的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_loader(features, labels, batch_size=10, rate=0.7):\n",
    "    \"\"\"数据封装、切分和加载函数：\n",
    "    \n",
    "    :param features：输入的特征 \n",
    "    :param labels: 数据集标签张量\n",
    "    :param batch_size：数据加载时的每一个小批数据量 \n",
    "    :param rate: 训练集数据占比\n",
    "    :return：加载好的训练集和测试集\n",
    "    \"\"\"\n",
    "    data = GenData(features, labels) \n",
    "    num_train = int(data.lens * 0.7)\n",
    "    num_test = data.lens - num_train\n",
    "    data_train, data_test = random_split(data, [num_train, num_test])\n",
    "    train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
    "    return(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试函数性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17be1691530>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)   \n",
    "\n",
    "# 创建数据集\n",
    "features, labels = tensorGenReg()\n",
    "features = features[:, :-1]  \n",
    "\n",
    "# 进行数据加载\n",
    "train_loader, test_loader = split_loader(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.4463, -0.6221]), tensor([-1.2863]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第一条训练集数据\n",
    "train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset[:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;模型训练函数并不是新的函数，此处正式对其进行定义并写入自定义模块中，方便后续调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, criterion, optimizer, batchdata, epochs=3, cla=False):\n",
    "    \"\"\"模型训练函数\n",
    "    \n",
    "    :param net：待训练的模型 \n",
    "    :param criterion: 损失函数\n",
    "    :param optimizer：优化算法\n",
    "    :param batchdata: 训练数据集\n",
    "    :param cla: 是否是分类问题\n",
    "    :param epochs: 遍历数据次数\n",
    "    \"\"\"\n",
    "    for epoch  in range(epochs):\n",
    "        for X, y in batchdata:\n",
    "            if cla == True:\n",
    "                y = y.flatten().long()          # 如果是分类问题，需要对y进行整数转化\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE计算函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们借助F.mse_loss，定义一个可以直接根据模型输出结果和加载后的数据计算MSE的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_cal(data_loader, net):\n",
    "    \"\"\"mse计算函数\n",
    "    \n",
    "    :param data_loader：加载好的数据\n",
    "    :param net: 模型\n",
    "    :return：根据输入的数据，输出其MSE计算结果\n",
    "    \"\"\"\n",
    "    data = data_loader.dataset                # 还原Dataset类\n",
    "    X = data[:][0]                            # 还原数据的特征\n",
    "    y = data[:][1]                            # 还原数据的标签\n",
    "    yhat = net(X)\n",
    "    return F.mse_loss(yhat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4463, -0.6221],\n",
       "        [-0.4742, -0.2939],\n",
       "        [ 1.9870,  0.1949],\n",
       "        ...,\n",
       "        [-1.6366, -2.1399],\n",
       "        [-1.8178, -1.4618],\n",
       "        [ 0.2646,  2.3555]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能。借助上述建模实验中构建的回归模型，测试函数能否顺利执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17be1691530>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)   \n",
    "\n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "# Stage 2.定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stage 3.定义优化方法\n",
    "optimizer = optim.SGD(LR_model.parameters(), lr = 0.03)\n",
    "\n",
    "# Stage 4.训练模型\n",
    "fit(net = LR_model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    batchdata = train_loader,\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(train_loader, LR_model)           # 计算训练误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8412e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(test_loader, LR_model)            # 计算测试误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和F.mse_loss对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(LR_model(train_loader.dataset[:][0]), train_loader.dataset[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8412e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(LR_model(test_loader.dataset[:][0]), test_loader.dataset[:][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 准确率计算函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;类似的，定义一个分类问题的准确率计算函数，同样要求输入是加载后的数据集和训练完成的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cal(data_loader, net):\n",
    "    \"\"\"准确率\n",
    "    \n",
    "    :param data_loader：加载好的数据\n",
    "    :param net: 模型\n",
    "    :return：根据输入的数据，输出其准确率计算结果\n",
    "    \"\"\"\n",
    "    data = data_loader.dataset                # 还原Dataset类\n",
    "    X = data[:][0]                            # 还原数据的特征\n",
    "    y = data[:][1]                            # 还原数据的标签\n",
    "    zhat = net(X)                             # 默认是分类问题，并且输出结果是未经softmax转化的结果\n",
    "    soft_z = F.softmax(zhat, 1)                  # 进行softmax转化\n",
    "    acc_bool = torch.argmax(soft_z, 1).flatten() == y.flatten()\n",
    "    acc = torch.mean(acc_bool.float())\n",
    "    return acc         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(9).reshape(3, 3).float()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(t, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27a68dfe570>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)   \n",
    "\n",
    "# 创建分类数据集\n",
    "features, labels = tensorGenCla()\n",
    "\n",
    "# 进行数据加载\n",
    "train_loader, test_loader = split_loader(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmaxR(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=3, bias=False):       # 定义模型的点线结构\n",
    "        super(softmaxR, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):                                    # 定义模型的正向传播规则\n",
    "        out = self.linear(x)             \n",
    "        return out\n",
    "\n",
    "# 实例化模型和\n",
    "softmax_model = softmaxR()\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化算法\n",
    "optimizer = optim.SGD(softmax_model.parameters(), lr = lr)\n",
    "\n",
    "# 执行模型训练\n",
    "fit(net = softmax_model, \n",
    "    criterion = criterion, \n",
    "    optimizer = optimizer, \n",
    "    batchdata = train_loader, \n",
    "    epochs = num_epochs, \n",
    "    cla=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8571)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(train_loader, softmax_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8533)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(test_loader, softmax_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，完成本阶段实用函数的添加。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
